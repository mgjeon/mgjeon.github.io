[
  {
    "objectID": "posts/sunpy-paper-implementation/index.html",
    "href": "posts/sunpy-paper-implementation/index.html",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "",
    "text": "import warnings; warnings.simplefilter(\"ignore\")\nimport logging, sunpy; logging.getLogger('sunpy').setLevel(logging.ERROR)\nThe SunPy (The SunPy Community et al. 2020) is a community-developed, free, and open source Python package for solar data analysis (Barnes et al. 2023; Mumford et al. 2020; The SunPy Community et al. 2015).\nIn this post, I will reproduce Figure 1 (see below) of the 2023 SunPy paper (Barnes et al. 2023) using the SunPy ecosystem. This is because one of the most important affiliated packages, pfsspy (Stansby et al. 2020), has been no longer developed since August 2023. The pfsspy package has been forked to sunkit-magex. Also, there are subtle differences in the aiapy package between 2023 and 2025. Therefore, I will basically follow the steps in this code provided by the authors of the 2023 SunPy paper, except that I will use the sunkit-magex package instead of the pfsspy package."
  },
  {
    "objectID": "posts/sunpy-paper-implementation/index.html#version-information",
    "href": "posts/sunpy-paper-implementation/index.html#version-information",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "Version Information",
    "text": "Version Information\n\nimport sys\nprint(\"Python version:\", sys.version)\n\nimport numpy as np\nprint(\"NumPy version:\", np.__version__)\nimport matplotlib\nprint(\"Matplotlib version:\", matplotlib.__version__)\nimport astropy\nprint(\"Astropy version:\", astropy.__version__)\nimport sunpy\nprint(\"SunPy version:\", sunpy.__version__)\nimport aiapy\nprint(\"aiapy version:\", aiapy.__version__)\nimport sunpy_soar\nprint(\"sunpy-soar version:\", sunpy_soar.__version__)\nimport sunkit_magex\nprint(\"sunkit-magex version:\", sunkit_magex.__version__)\n\nPython version: 3.12.11 | packaged by conda-forge | (main, Jun  4 2025, 14:29:09) [MSC v.1943 64 bit (AMD64)]\nNumPy version: 2.2.6\nMatplotlib version: 3.10.5\nAstropy version: 7.1.0\nSunPy version: 7.0.1\naiapy version: 0.10.1\nsunpy-soar version: 1.11.1\nsunkit-magex version: 1.1.0"
  },
  {
    "objectID": "posts/sunpy-paper-implementation/index.html#download-hmi-synoptic-magnetogram-for-cr-2255",
    "href": "posts/sunpy-paper-implementation/index.html#download-hmi-synoptic-magnetogram-for-cr-2255",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "Download HMI Synoptic Magnetogram for CR 2255",
    "text": "Download HMI Synoptic Magnetogram for CR 2255\nThe SunPy paper (2023) said that the left panel of Figure1A shows the SDO/HMI synoptic magnetogram for Carrington rotation (CR) 2255 which began on 2022-03-08.\nLetâ€™s start by checking that CR 2255 actually began on 2022-03-08.\n\nfrom sunpy.coordinates.sun import carrington_rotation_time\n\n\ncarrington_rotation_time(2255)\n\n&lt;Time object: scale='utc' format='iso' value=2022-03-07 11:59:56.657&gt;\n\n\nCR 2255 actually began on 2022-03-07 12:00 UTC, which also can be found in this page.\nWe can download the HMI polar-filled full-CR synoptic magnetogram hmi.synoptic_mr_polfil_720s (Sun 2018) for CR 2255 from JSOC using sunpy.net.Fido.\n\nfrom sunpy.net import Fido, attrs as a\n\n\n# Please replace the following email with your own email address registered with the JSOC.\njsoc_email = ''\n\n\nq = Fido.search(\n    a.Time('2022-03-07T12:00', '2022-03-07T12:00'),\n    a.jsoc.Series('hmi.synoptic_mr_polfil_720s'),\n    a.jsoc.PrimeKey('CAR_ROT', 2255),\n    a.jsoc.Notify(jsoc_email)\n)\n\n\nq\n\nResults from 1 Provider:1 Results from the JSOCClient:JSOCResponse length=1\n\nTELESCOPINSTRUMEWAVELNTHCAR_ROT\nstr7str9float64int64\nSDO/HMIHMI_SIDE16173.02255\n\n\n\n\nf = Fido.fetch(q, path='./data', overwrite=True)\n\n\nprint(f)\n\n['data\\\\hmi.synoptic_mr_polfil_720s.2255.Mr_polfil.fits']\n\n\nWe can load the fits file using sunpy.map.Map.\n\nfrom sunpy.map import Map\n\n\nm_hmi = Map(f)\n\n\nm_hmi.peek()\n\n\n\n\n\n\n\n\nThis is the same HMI synoptic magnetogram as shown in the left panel of Figure 1A in the SunPy paper (2023)."
  },
  {
    "objectID": "posts/sunpy-paper-implementation/index.html#select-location-of-ar",
    "href": "posts/sunpy-paper-implementation/index.html#select-location-of-ar",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "Select Location of AR",
    "text": "Select Location of AR\nWe identify the center of the active region (AR) of interest visually from the HMI synoptic magnetogram.\n\nimport astropy.units as u\nfrom astropy.coordinates import SkyCoord\n\n\nm_hmi.coordinate_frame\n\n&lt;HeliographicCarrington Frame (obstime=2022-03-21T03:51:33.000, rsun=695700.0 km, observer=&lt;HeliographicStonyhurst Coordinate (obstime=2022-03-21T03:51:33.000, rsun=695700.0 km): (lon, lat, radius) in (deg, deg, m)\n    (0., -7.02110576, 1.48994814e+11)&gt;)&gt;\n\n\n\nar_center = SkyCoord(lon=65*u.deg, lat=15*u.deg, frame=m_hmi.coordinate_frame)\n\nWe can plot this coordinate on the HMI map.\n\nimport matplotlib.pyplot as plt\n\n\nfig = plt.figure(figsize=(15, 5))\nax = fig.add_subplot(111, projection=m_hmi)\nm_hmi.plot(axes=ax)\nax.plot_coord(ar_center, marker='X', color='k', markersize=10);\n\n\n\n\n\n\n\n\nThe default obstime of the carrington map is halfway through the carrington rotation.\n\nm_hmi.coordinate_frame.obstime\n\n&lt;Time object: scale='utc' format='isot' value=2022-03-21T03:51:33.000&gt;\n\n\n\ncar_start = carrington_rotation_time(2255)\ncar_end = carrington_rotation_time(2256)\nprint('CR 2255 start   ', car_start)\nprint('CR 2255 end     ', car_end)\ncar_halfway = car_start + (car_end - car_start) / 2\nprint('CR 2255 halfway ', car_halfway)\n\nCR 2255 start    2022-03-07 11:59:56.657\nCR 2255 end      2022-04-03 19:19:29.900\nCR 2255 halfway  2022-03-21 03:39:43.279\n\n\nSince a synoptic map is comprised of observations from many different times, we look up the obstime associated with our selected longitude and use this to correct our original AR coordinate\n\nar_date = carrington_rotation_time(2255, ar_center.lon)\nar_date\n\n&lt;Time object: scale='utc' format='iso' value=2022-03-29 21:04:15.174&gt;\n\n\n\nchange_obstime = lambda x,y: SkyCoord(x.replicate(observer=x.observer.replicate(obstime=y), obstime=y))\n\n\nar_center_corrected = change_obstime(ar_center, ar_date)\nar_center_corrected\n\n&lt;SkyCoord (HeliographicCarrington: obstime=2022-03-29 21:04:15.174, rsun=695700.0 km, observer=&lt;HeliographicStonyhurst Coordinate (obstime=2022-03-29 21:04:15.174, rsun=695700.0 km): (lon, lat, radius) in (deg, deg, m)\n    (0., -7.02110576, 1.48994814e+11)&gt;): (lon, lat) in deg\n    (65., 15.)&gt;"
  },
  {
    "objectID": "posts/sunpy-paper-implementation/index.html#download-euv-data-for-ar",
    "href": "posts/sunpy-paper-implementation/index.html#download-euv-data-for-ar",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "Download EUV data for AR",
    "text": "Download EUV data for AR\nWe will download the EUV data from SDO/AIA, STEREO-A/SECCHI/EUVI, and Solar Orbiter/EUI/FSI.\nFirst, we define the time range of interest.\n\ntr = a.Time(ar_date-2*u.min, ar_date+2*u.min)\ntr\n\n&lt;sunpy.net.attrs.Time(2022-03-29 21:02:15.174, 2022-03-29 21:06:15.174)&gt;\n\n\nWe construct a search query for 171 Ã… EUV data from SDO/AIA and STEREO-A/SECCHI/EUVI. This will search the Virtual Solar Observatory (VSO).\n\naia_or_euvi = ((a.Instrument('AIA') | a.Instrument('EUVI'))\n                & a.Wavelength(171*u.angstrom)\n                & a.Sample(5*u.min))\n\nWe construct a search query for 174 Ã… EUV data from Solar Orbiter/EUI/FSI. This will search the Solar Oriter Archive (SOAR) using the sunpy-soar package.\n\neui = a.Level(2) & a.soar.Product('EUI-FSI174-IMAGE')\n\n\nq = Fido.search(tr, aia_or_euvi | eui)\n\n\nq\n\nResults from 3 Providers:1 Results from the VSOClient:VSOQueryResponseTable length=1\n\nStart TimeEnd TimeSourceInstrumentWavelengthProviderPhysobsWavetypeExtent WidthExtent LengthExtent TypeSize\nAngstromMibyte\nTimeTimestr3str3float64[2]str4str9str6str4str4str8float64\n2022-03-29 21:02:21.0002022-03-29 21:02:22.000SDOAIA171.0 .. 171.0JSOCintensityNARROW40964096FULLDISK64.64844\n1 Results from the VSOClient:VSOQueryResponseTable length=1\n\nStart TimeEnd TimeSourceInstrumentWavelengthProviderPhysobsWavetypeExtent TypeSize\nAngstromMibyte\nTimeTimestr8str6float64[2]str3str9str6str8float64\n2022-03-29 21:03:00.0002022-03-29 21:03:02.000STEREO_ASECCHI171.0 .. 175.0SSCintensityNARROWFULLDISK-0.00098\n1 Results from the SOARClient:QueryResponseTable length=1\n\nInstrumentData productLevelStart timeEnd timeData item IDFilenameFilesizeSOOP NameDetectorWavelength\nMbyte\nstr3str16str2str23str23str43str52float64str31str3float64\nEUIeui-fsi174-imageL22022-03-29 21:04:45.2982022-03-29 21:04:55.298solo_L2_eui-fsi174-image_20220329T210445298solo_L2_eui-fsi174-image_20220329T210445298_V02.fits5.593L_FULL_HRES_HCAD_Eruption-WatchFSI174.0\n\n\n\nNote that Fido returns three results (one for each instrument) and that two out of the three of these are from the VSO and one is from the SOAR.\n\nfiles = Fido.fetch(q, path='./data', overwrite=True)\n\n\nprint(sorted(files))\n\n['data\\\\20220329_210300_n5euA.fts', 'data\\\\aia.lev1.171A_2022_03_29T21_02_21.35Z.image_lev1.fits', 'data\\\\solo_L2_eui-fsi174-image_20220329T210445298_V02.fits']\n\n\n\nm_secchi, m_aia, m_eui = Map(sorted(files))\n\nUsing the metadata provided in each file, we can plot the relative locations of the three spacecraft.\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='polar')\n# Plot the Sun\nax.plot(0, 0, marker='o', markersize=20, label='Sun', color='yellow')\n# Plot the spacecraft locations\nfor m in [m_aia, m_eui, m_secchi]:\n    sat = m.observatory\n    coord = m.observer_coordinate\n    ax.plot(coord.lon.to('rad'), coord.radius.to(u.AU), 'o', label=sat)\nax.set_theta_zero_location('S')\nax.legend();"
  },
  {
    "objectID": "posts/sunpy-paper-implementation/index.html#process-euv-data-for-ar",
    "href": "posts/sunpy-paper-implementation/index.html#process-euv-data-for-ar",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "Process EUV Data for AR",
    "text": "Process EUV Data for AR\nWe prepare the SDO/AIA data from level 1 to level 1.5 using aiapy package by (1) correcting the pointing keywords and (2) also correcting the instrument degradation.\n\nfrom aiapy.calibrate import update_pointing, correct_degradation\nfrom aiapy.calibrate.util import get_pointing_table, get_correction_table\n\n\npointing_table = get_pointing_table('JSOC', time_range=(m_aia.date-12*u.h, m_aia.date+12*u.h))\n\n\npointing_table\n\nQTable length=8\n\nORIGINTELESCOPDATET_STARTT_STOPT_HKVALSVERSIONSC_Y_INRT_BIASSC_Z_INRT_BIASH_CAM1_IMSCALEH_CAM1_X0H_CAM1_Y0H_CAM1_INSTROTH_CAM2_IMSCALEH_CAM2_X0H_CAM2_Y0H_CAM2_INSTROTA_094_IMSCALEA_094_X0A_094_Y0A_094_INSTROTA_131_IMSCALEA_131_X0A_131_Y0A_131_INSTROTA_171_IMSCALEA_171_X0A_171_Y0A_171_INSTROTA_193_IMSCALEA_193_X0A_193_Y0A_193_INSTROTA_211_IMSCALEA_211_X0A_211_Y0A_211_INSTROTA_304_IMSCALEA_304_X0A_304_Y0A_304_INSTROTA_335_IMSCALEA_335_X0A_335_Y0A_335_INSTROTA_1600_IMSCALEA_1600_X0A_1600_Y0A_1600_INSTROTA_1700_IMSCALEA_1700_X0A_1700_Y0A_1700_INSTROTA_4500_IMSCALEA_4500_X0A_4500_Y0A_4500_INSTROTHMI_FSW_AL1_POSITIONHAL1POSHMI_FSW_AL2_POSITIONHAL2POSHMI_AL1_STATUSHAL1STATHMI_AL2_STATUSHAL2STATHMI_ISS_ERRGAINYHIERRGNYHMI_ISS_ERRGAINZHIERRGNZHMI_ISS_ERROFFYHIERROFYHMI_ISS_ERROFFZHIERROFZHMI_ISS_PZTOFFAHIPZTOFAHMI_ISS_PZTOFFBHIPZTOFBHMI_ISS_PZTOFFCHIPZTOFCHMI_ISS_PKT_YCOEF_AHIYCOEFAHMI_ISS_PKT_YCOEF_BHIYCOEFBHMI_ISS_PKT_YCOEF_CHIYCOEFCHMI_ISS_PKT_ZCOEF_AHIZCOEFAHMI_ISS_PKT_ZCOEF_BHIZCOEFBHMI_ISS_PKT_ZCOEF_CHIZCOEFCAIA_IS1_ERRGAINYA1ERRGNYAIA_IS1_ERRGAINZA1ERRGNZAIA_IS1_ERROFFYA1ERROFYAIA_IS1_ERROFFZA1ERROFZAIA_IS1_PZTGAINAA1PZTGNAAIA_IS1_PZTGAINBA1PZTGNBAIA_IS1_PZTGAINCA1PZTGNCAIA_IS1_PZTOFFAA1PZTOFAAIA_IS1_PZTOFFBA1PZTOFBAIA_IS1_PZTOFFCA1PZTOFCAIA_GT1_PKT_YCOEF_AAGT1_YCAAIA_GT1_PKT_YCOEF_BAGT1_YCBAIA_GT1_PKT_YCOEF_CAGT1_YCCAIA_GT1_PKT_ZCOEF_AAGT1_ZCAAIA_GT1_PKT_ZCOEF_BAGT1_ZCBAIA_GT1_PKT_ZCOEF_CAGT1_ZCCAIA_IS2_ERRGAINYA2ERRGNYAIA_IS2_ERRGAINZA2ERRGNZAIA_IS2_ERROFFYA2ERROFYAIA_IS2_ERROFFZA2ERROFZAIA_IS2_PZTGAINAA2PZTGNAAIA_IS2_PZTGAINBA2PZTGNBAIA_IS2_PZTGAINCA2PZTGNCAIA_IS2_PZTOFFAA2PZTOFAAIA_IS2_PZTOFFBA2PZTOFBAIA_IS2_PZTOFFCA2PZTOFCAIA_GT2_PKT_YCOEF_AAGT2_YCAAIA_GT2_PKT_YCOEF_BAGT2_YCBAIA_GT2_PKT_YCOEF_CAGT2_YCCAIA_GT2_PKT_ZCOEF_AAGT2_ZCAAIA_GT2_PKT_ZCOEF_BAGT2_ZCBAIA_GT2_PKT_ZCOEF_CAGT2_ZCCAIA_IS3_ERRGAINYA3ERRGNYAIA_IS3_ERRGAINZA3ERRGNZAIA_IS3_ERROFFYA3ERROFYAIA_IS3_ERROFFZA3ERROFZAIA_IS3_PZTGAINAA3PZTGNAAIA_IS3_PZTGAINBA3PZTGNBAIA_IS3_PZTGAINCA3PZTGNCAIA_IS3_PZTOFFAA3PZTOFAAIA_IS3_PZTOFFBA3PZTOFBAIA_IS3_PZTOFFCA3PZTOFCAIA_GT3_PKT_YCOEF_AAGT3_YCAAIA_GT3_PKT_YCOEF_BAGT3_YCBAIA_GT3_PKT_YCOEF_CAGT3_YCCAIA_GT3_PKT_ZCOEF_AAGT3_ZCAAIA_GT3_PKT_ZCOEF_BAGT3_ZCBAIA_GT3_PKT_ZCOEF_CAGT3_ZCCAIA_IS4_ERRGAINYA4ERRGNYAIA_IS4_ERRGAINZA4ERRGNZAIA_IS4_ERROFFYA4ERROFYAIA_IS4_ERROFFZA4ERROFZAIA_IS4_PZTGAINAA4PZTGNAAIA_IS4_PZTGAINBA4PZTGNBAIA_IS4_PZTGAINCA4PZTGNCAIA_IS4_PZTOFFAA4PZTOFAAIA_IS4_PZTOFFBA4PZTOFBAIA_IS4_PZTOFFCA4PZTOFCAIA_GT4_PKT_YCOEF_AAGT4_YCAAIA_GT4_PKT_YCOEF_BAGT4_YCBAIA_GT4_PKT_YCOEF_CAGT4_YCCAIA_GT4_PKT_ZCOEF_AAGT4_ZCAAIA_GT4_PKT_ZCOEF_BAGT4_ZCBAIA_GT4_PKT_ZCOEF_CAGT4_ZCC\narcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdegarcsec / pixpixpixdeg\nstr12str3str20TimeTimestr20int64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64float64\nSDO/JSOC-SDPSDO2022-03-30T16:51:58Z2022-03-29T12:00:00.0002022-03-29T18:00:00.0002022-03-27T00:00:00Z1-4.9839.3230.504892033.7900392051.580078180.0135040.504862039.6300052048.47998179.9297940.6001092069.8215332009.129517-0.137610.6006982041.7043462041.861694-0.1387950.5994892054.6105962047.3101810.0193270.6007142040.7598882041.9180910.0577890.6007582036.5909422040.4560550.0564330.6001652067.3798832006.143433-0.1316390.6007372040.5375982040.539795-0.1424430.6093732051.8544922046.5614010.0197920.6128982053.2221682044.9229740.0205250.5999452051.9367682048.1933590.02063876.076.044.044.081.081.081.081.0-43.0-43.0-44.0-44.0-37.0-37.066.066.0-16.0-16.0-16.0-16.0-13.0-13.0-20920.0-20920.0-10460.0-10460.0-10460.0-10460.00.00.0-15098.0-15098.0-15098.0-15098.0-85.0-85.0-85.0-85.0-17.0-17.053.053.0-20.0-20.0-19.0-19.0-19.0-19.0-15.0-15.0-17.0-17.032.032.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-85.0-85.0-85.0-85.01.01.038.038.0-18.0-18.0-30.0-30.0-30.0-30.011.011.05.05.0-15.0-15.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-79.0-79.0-78.0-78.06.06.013.013.0-15.0-15.0-22.0-22.0-22.0-22.0-37.0-37.09.09.029.029.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-80.0-80.0-80.0-80.02.02.0-6.0-6.0-15.0-15.0-22.0-22.0-22.0-22.025.025.01.01.0-26.0-26.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0\nSDO/JSOC-SDPSDO2022-03-30T19:47:27Z2022-03-29T15:00:00.0002022-03-29T21:00:00.0002022-03-27T00:00:00Z1-4.9839.3230.504892033.7900392051.580078180.0135040.504862039.6300052048.47998179.9297940.6001092069.9704592009.175171-0.137610.6006982041.6452642041.656616-0.1387950.5994892054.4926762047.2633060.0193270.6007142040.7543952041.9854740.0577890.6007582036.5816652040.4633790.0564330.6001652068.613772006.88269-0.1316390.6007372040.4611822040.399536-0.1424430.6093732051.7543952046.541260.0197920.6128982053.1225592044.9132080.0205250.5999452051.8100592048.1201170.02063876.076.044.044.081.081.081.081.0-43.0-43.0-44.0-44.0-37.0-37.066.066.0-16.0-16.0-16.0-16.0-13.0-13.0-20920.0-20920.0-10460.0-10460.0-10460.0-10460.00.00.0-15098.0-15098.0-15098.0-15098.0-85.0-85.0-85.0-85.0-17.0-17.053.053.0-20.0-20.0-19.0-19.0-19.0-19.0-15.0-15.0-17.0-17.032.032.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-85.0-85.0-85.0-85.01.01.038.038.0-18.0-18.0-30.0-30.0-30.0-30.011.011.05.05.0-15.0-15.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-79.0-79.0-78.0-78.06.06.013.013.0-15.0-15.0-22.0-22.0-22.0-22.0-37.0-37.09.09.029.029.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-80.0-80.0-80.0-80.02.02.0-6.0-6.0-15.0-15.0-22.0-22.0-22.0-22.025.025.01.01.0-26.0-26.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0\nSDO/JSOC-SDPSDO2022-03-30T22:07:31Z2022-03-29T18:00:00.0002022-03-30T00:00:00.0002022-03-27T00:00:00Z1-4.9839.3230.504892033.7900392051.580078180.0135040.504862039.6300052048.47998179.9297940.6001092069.9128422009.273682-0.137610.6006982041.5379642041.681763-0.1387950.5994892054.4951172047.2779540.0193270.6007142040.4499512042.011230.0577890.6007582036.2672122040.5332030.0564330.6001652067.9755862006.063599-0.1316390.6007372040.3422852040.449707-0.1424430.6093732051.7214362046.5028080.0197920.6128982053.0676272044.8846440.0205250.5999452054.7106932067.6726070.02063876.076.044.044.081.081.081.081.0-43.0-43.0-44.0-44.0-37.0-37.066.066.0-16.0-16.0-16.0-16.0-13.0-13.0-20920.0-20920.0-10460.0-10460.0-10460.0-10460.00.00.0-15098.0-15098.0-15098.0-15098.0-85.0-85.0-85.0-85.0-17.0-17.053.053.0-20.0-20.0-19.0-19.0-19.0-19.0-15.0-15.0-17.0-17.032.032.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-85.0-85.0-85.0-85.01.01.038.038.0-18.0-18.0-30.0-30.0-30.0-30.011.011.05.05.0-15.0-15.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-79.0-79.0-78.0-78.06.06.013.013.0-15.0-15.0-22.0-22.0-22.0-22.0-37.0-37.09.09.029.029.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-80.0-80.0-80.0-80.02.02.0-6.0-6.0-15.0-15.0-22.0-22.0-22.0-22.025.025.01.01.0-26.0-26.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0\nSDO/JSOC-SDPSDO2022-03-31T01:40:36Z2022-03-29T21:00:00.0002022-03-30T03:00:00.0002022-03-27T00:00:00Z1-4.9839.3230.504892033.7900392051.580078180.0135040.504862039.6300052048.47998179.9297940.6001092069.8085942009.097412-0.137610.6006982041.291872041.739624-0.1387950.5994892054.4836432047.2253420.0193270.6007142040.0173342041.9810790.0577890.6007582035.7963872040.4809570.0564330.6001652067.68752006.059692-0.1316390.6007372040.3735352040.357666-0.1424430.6093732051.7150882046.3878170.0197920.6128982053.0510252044.7968750.0205250.5999452051.0400392047.5899660.02063876.076.044.044.081.081.081.081.0-43.0-43.0-44.0-44.0-37.0-37.066.066.0-16.0-16.0-16.0-16.0-13.0-13.0-20920.0-20920.0-10460.0-10460.0-10460.0-10460.00.00.0-15098.0-15098.0-15098.0-15098.0-85.0-85.0-85.0-85.0-17.0-17.053.053.0-20.0-20.0-19.0-19.0-19.0-19.0-15.0-15.0-17.0-17.032.032.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-85.0-85.0-85.0-85.01.01.038.038.0-18.0-18.0-30.0-30.0-30.0-30.011.011.05.05.0-15.0-15.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-79.0-79.0-78.0-78.06.06.013.013.0-15.0-15.0-22.0-22.0-22.0-22.0-37.0-37.09.09.029.029.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-80.0-80.0-80.0-80.02.02.0-6.0-6.0-15.0-15.0-22.0-22.0-22.0-22.025.025.01.01.0-26.0-26.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0\nSDO/JSOC-SDPSDO2022-03-31T04:51:55Z2022-03-30T00:00:00.0002022-03-30T06:00:00.0002022-03-27T00:00:00Z1-4.9839.3230.504892033.7900392051.580078180.0135040.504862039.6300052048.47998179.9297940.6001092069.5275882009.48877-0.137610.6006982041.1519782041.793945-0.1387950.5994892054.1889652047.5488280.0193270.6007142039.2766112042.2567140.0577890.6007582033.2718512040.7475590.0564330.6001652068.6059572007.465942-0.1316390.6007372039.6025392040.08252-0.1424430.6093732051.7800292046.5600590.0197920.6128982052.8330082044.9959720.0205250.5999452051.760012048.250.02063876.076.044.044.081.081.081.081.0-43.0-43.0-44.0-44.0-37.0-37.066.066.0-16.0-16.0-16.0-16.0-13.0-13.0-20920.0-20920.0-10460.0-10460.0-10460.0-10460.00.00.0-15098.0-15098.0-15098.0-15098.0-85.0-85.0-85.0-85.0-17.0-17.053.053.0-20.0-20.0-19.0-19.0-19.0-19.0-15.0-15.0-17.0-17.032.032.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-85.0-85.0-85.0-85.01.01.038.038.0-18.0-18.0-30.0-30.0-30.0-30.011.011.05.05.0-15.0-15.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-79.0-79.0-78.0-78.06.06.013.013.0-15.0-15.0-22.0-22.0-22.0-22.0-37.0-37.09.09.029.029.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-80.0-80.0-80.0-80.02.02.0-6.0-6.0-15.0-15.0-22.0-22.0-22.0-22.025.025.01.01.0-26.0-26.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0\nSDO/JSOC-SDPSDO2022-03-31T07:53:59Z2022-03-30T03:00:00.0002022-03-30T09:00:00.0002022-03-27T00:00:00Z1-4.9839.3230.504892033.7900392051.580078180.0135040.504862039.6300052048.47998179.9297940.6001092069.4948732009.120605-0.137610.6006982041.2006842041.945679-0.1387950.5994892054.4343262047.5662840.0193270.6007142039.736452042.1677250.0577890.6007582035.6168212040.6866460.0564330.6001652067.877932006.530029-0.1316390.6007372040.0360112040.598633-0.1424430.6093732051.6467292046.7902830.0197920.6128982053.0126952045.1606450.0205250.5999452050.9199222047.8233640.02063876.076.044.044.081.081.081.081.0-43.0-43.0-44.0-44.0-37.0-37.066.066.0-16.0-16.0-16.0-16.0-13.0-13.0-20920.0-20920.0-10460.0-10460.0-10460.0-10460.00.00.0-15098.0-15098.0-15098.0-15098.0-85.0-85.0-85.0-85.0-17.0-17.053.053.0-20.0-20.0-19.0-19.0-19.0-19.0-15.0-15.0-17.0-17.032.032.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-85.0-85.0-85.0-85.01.01.038.038.0-18.0-18.0-30.0-30.0-30.0-30.011.011.05.05.0-15.0-15.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-79.0-79.0-78.0-78.06.06.013.013.0-15.0-15.0-22.0-22.0-22.0-22.0-37.0-37.09.09.029.029.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-80.0-80.0-80.0-80.02.02.0-6.0-6.0-15.0-15.0-22.0-22.0-22.0-22.025.025.01.01.0-26.0-26.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0\nSDO/JSOC-SDPSDO2022-03-31T10:52:02Z2022-03-30T06:00:00.0002022-03-30T12:00:00.0002022-03-27T00:00:00Z1-4.9839.3230.504892033.7900392051.580078180.0135040.504862039.6300052048.47998179.9297940.6001092069.3942872009.004272-0.137610.6006982041.2562262041.89917-0.1387950.5994892054.354982047.5407710.0193270.6007142039.7774662041.9514160.0577890.6007582035.645022040.4791260.0564330.6001652066.5490722005.698975-0.1316390.6007372040.1077882040.618042-0.1424430.6093732051.7014162046.8031010.0197920.6128982053.0854492045.1665040.0205250.5999452051.7033692048.4199220.02063876.076.044.044.081.081.081.081.0-43.0-43.0-44.0-44.0-37.0-37.066.066.0-16.0-16.0-16.0-16.0-13.0-13.0-20920.0-20920.0-10460.0-10460.0-10460.0-10460.00.00.0-15098.0-15098.0-15098.0-15098.0-85.0-85.0-85.0-85.0-17.0-17.053.053.0-20.0-20.0-19.0-19.0-19.0-19.0-15.0-15.0-17.0-17.032.032.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-85.0-85.0-85.0-85.01.01.038.038.0-18.0-18.0-30.0-30.0-30.0-30.011.011.05.05.0-15.0-15.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-79.0-79.0-78.0-78.06.06.013.013.0-15.0-15.0-22.0-22.0-22.0-22.0-37.0-37.09.09.029.029.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-80.0-80.0-80.0-80.02.02.0-6.0-6.0-15.0-15.0-22.0-22.0-22.0-22.025.025.01.01.0-26.0-26.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0\nSDO/JSOC-SDPSDO2022-03-31T13:41:38Z2022-03-30T09:00:00.0002022-03-30T15:00:00.0002022-03-27T00:00:00Z1-4.9839.3230.504892033.7900392051.580078180.0135040.504862039.6300052048.47998179.9297940.6001092069.4577642008.996338-0.137610.6006982041.4189452041.971558-0.1387950.5994892054.5051272047.4327390.0193270.6007142039.9602052041.8460690.0577890.6007582035.7480472040.3553470.0564330.6001652067.6516112006.154053-0.1316390.6007372040.2333982040.649048-0.1424430.6093732051.8615722046.7789310.0197920.6128982053.2275392045.1586910.0205250.5999452051.8432622048.4199220.02063876.076.044.044.081.081.081.081.0-43.0-43.0-44.0-44.0-37.0-37.066.066.0-16.0-16.0-16.0-16.0-13.0-13.0-20920.0-20920.0-10460.0-10460.0-10460.0-10460.00.00.0-15098.0-15098.0-15098.0-15098.0-85.0-85.0-85.0-85.0-17.0-17.053.053.0-20.0-20.0-19.0-19.0-19.0-19.0-15.0-15.0-17.0-17.032.032.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-85.0-85.0-85.0-85.01.01.038.038.0-18.0-18.0-30.0-30.0-30.0-30.011.011.05.05.0-15.0-15.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-79.0-79.0-78.0-78.06.06.013.013.0-15.0-15.0-22.0-22.0-22.0-22.0-37.0-37.09.09.029.029.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0-80.0-80.0-80.0-80.02.02.0-6.0-6.0-15.0-15.0-22.0-22.0-22.0-22.025.025.01.01.0-26.0-26.02048.02048.013900.013900.00.00.02048.02048.013900.013900.00.00.0\n\n\n\n\ncorrection_table = get_correction_table('JSOC')\n\n\ncorrection_table\n\nQTable length=665\n\nDATEVER_NUMWAVE_STRWAVELNTHT_STARTT_STOPEFFA_P1EFFA_P2EFFA_P3EFF_AREAEFF_WVLN\nAngstromcm2Angstrom\nstr20int64str9float64TimeTimefloat64float64float64float64float64\n2020-11-02T11:14:52Z10131_THICK131.02010-03-24T00:00:00.0002011-02-24T19:00:00.000-0.0003830.00.00.101769131.199997\n2017-12-10T05:05:04Z8131_THICK131.02010-03-24T00:00:00.0002011-02-24T19:00:00.000-0.0003240.00.00.092281131.199997\n2020-07-06T21:54:29Z9131_THICK131.02010-03-24T00:00:00.0002011-02-24T19:00:00.000-0.0003770.00.00.101531131.199997\n2011-09-29T00:00:00Z1131_THICK131.02010-03-24T00:00:00.0002030-04-30T23:59:57.0000.00.00.00.097468131.199997\n2012-01-05T00:00:00Z2131_THICK131.02010-03-24T00:00:00.0002011-02-24T19:00:00.0000.00.00.00.075027131.199997\n2010-11-23T00:00:00Z1131_THICK131.02010-03-24T00:00:00.0002011-03-24T00:00:00.0000.00.00.00.097131.199997\n2012-09-26T00:00:00Z3131_THICK131.02010-03-24T00:00:00.0002011-02-24T19:00:00.0000.00.00.00.075027131.199997\n2011-04-29T00:00:00Z1131_THICK131.02010-03-24T00:00:00.0002012-01-01T00:00:00.0000.00.00.00.097131.199997\n2020-11-02T11:14:52Z10131_THIN131.02010-03-24T00:00:00.0002011-02-24T19:00:00.000-0.0003830.00.01.223503131.199997\n.................................\n2020-11-02T11:14:52Z10335_THICK335.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.006929335.399994\n2020-11-02T11:14:52Z10335_THIN335.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.009789335.399994\n2020-07-06T21:54:47Z9335_THIN335.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.009279335.399994\n2020-11-19T19:00:00Z1094_THICK94.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.19323793.900002\n2020-11-02T11:14:52Z1094_THICK94.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.2026193.900002\n2020-07-06T21:54:28Z994_THICK94.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.21349393.900002\n2020-07-06T21:54:28Z994_THIN94.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.2974493.900002\n2020-11-19T19:00:00Z1094_THIN94.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.2692293.900002\n2020-11-02T11:14:52Z1094_THIN94.02020-06-01T12:00:00.0002030-05-01T00:00:00.0000.00.00.00.28227893.900002\n\n\n\n\nm_aia.peek(vmin=0, vmax=8000)\n\n\n\n\n\n\n\n\n\nm_aia = correct_degradation(update_pointing(m_aia, pointing_table=pointing_table), correction_table=correction_table)\n\n\nm_aia.peek(vmin=0, vmax=8000)\n\n\n\n\n\n\n\n\nThe SDO/AIA and STEREO-A/SECCHI/EUVI data are not been normalized for exposure time, whereas the Solar Orbiter/EUI/FSI data (level 2) are normalized for exposure time.\n\nm_secchi.peek()\n\n\n\n\n\n\n\n\n\nm_eui.peek()\n\n\n\n\n\n\n\n\nWe normalize the SDO/AIA and STEREO-A/SECCHI/EUVI data for exposure time.\n\nm_aia = m_aia / m_aia.exposure_time\nm_secchi = m_secchi / m_secchi.exposure_time\n\n\nm_aia.peek()\n\n\n\n\n\n\n\n\n\nm_secchi.peek()\n\n\n\n\n\n\n\n\nWe can plot the position of the corrected center of the AR on the EUV maps.\n\nfig = plt.figure(figsize=(15, 5))\nfor i, m in enumerate([m_aia, m_eui, m_secchi]):\n    ax = fig.add_subplot(1, 3, i+1, projection=m)\n    m.plot(axes=ax, clip_interval=(1, 99.99)*u.percent)\n    ax.plot_coord(ar_center_corrected, marker='o', color='C3')\n\n\n\n\n\n\n\n\nWe can plot the region of interest on the EUV maps.\n\nar_width = 700*u.arcsec\nar_height = 700*u.arcsec\n\n\nfig = plt.figure(figsize=(15, 5))\nfor i, m in enumerate([m_aia, m_eui, m_secchi]):\n    ax = fig.add_subplot(1, 3, i+1, projection=m)\n    m.plot(axes=ax, clip_interval=(1, 99.99)*u.percent)\n    ar_center_corrected_transformed = ar_center_corrected.transform_to(m.coordinate_frame)\n    blc = SkyCoord(Tx=ar_center_corrected_transformed.Tx-ar_width/2,\n                   Ty=ar_center_corrected_transformed.Ty-ar_height/2,\n                   frame=ar_center_corrected_transformed)\n    m.draw_quadrangle(blc, width=ar_width, height=ar_height, edgecolor='C3', lw=1)\n\n\n\n\n\n\n\n\nWe can rotate the maps such that the y-axis of the images is aligned with the solar north using sunpy.map.Map.rotate.\n\nfig = plt.figure(figsize=(15, 5))\nfor i, m in enumerate([m_aia, m_eui, m_secchi]):\n    ax = fig.add_subplot(1, 3, i+1, projection=m)\n    m_rot = m.rotate(missing=0.0)\n    m_rot.plot(axes=ax, clip_interval=(1, 99.99)*u.percent)\n    ar_center_corrected_transformed = ar_center_corrected.transform_to(m_rot.coordinate_frame)\n    blc = SkyCoord(Tx=ar_center_corrected_transformed.Tx-ar_width/2,\n                   Ty=ar_center_corrected_transformed.Ty-ar_height/2,\n                   frame=ar_center_corrected_transformed)\n    m_rot.draw_quadrangle(blc, width=ar_width, height=ar_height, edgecolor='C3', lw=1)\n\n\n\n\n\n\n\n\nWe can now crop each full disk image to the appropriate region.\n\nm_cutouts = []\nfor m in [m_aia, m_eui, m_secchi]:\n    ar_center_corrected_transformed = ar_center_corrected.transform_to(m.coordinate_frame)\n    blc = SkyCoord(Tx=ar_center_corrected_transformed.Tx-ar_width/2,\n                   Ty=ar_center_corrected_transformed.Ty-ar_height/2,\n                   frame=ar_center_corrected_transformed)\n    # Each map is rotated prior to submapping such that the selection is aligned with the coordinate grid\n    m_rot = m.rotate(missing=0.0)\n    m_cutout = m_rot.submap(blc, width=ar_width, height=ar_height)\n    m_cutouts.append(m_cutout)\n\n\nfig = plt.figure(figsize=(15, 5))\nfor i, m in enumerate(m_cutouts):\n    ax = fig.add_subplot(1, 3, i+1, projection=m)\n    m.plot(axes=ax, clip_interval=(1, 99.99)*u.percent)"
  },
  {
    "objectID": "posts/sunpy-paper-implementation/index.html#calculate-pfss-from-hmi-synoptic-magnetogram",
    "href": "posts/sunpy-paper-implementation/index.html#calculate-pfss-from-hmi-synoptic-magnetogram",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "Calculate PFSS from HMI Synoptic Magnetogram",
    "text": "Calculate PFSS from HMI Synoptic Magnetogram\nWe can calculate a potential field source surface (PFSS) solution from the HMI synoptic magnetogram using sunkit-magex package.\nWe first resample the HMI synoptic map to speed up the calculation of our field extrapolation.\n\nm_hmi.data.shape\n\n(1440, 3600)\n\n\n\nm_hmi_resample = m_hmi.resample((1080, 540)*u.pix)\n\n\nm_hmi_resample.data.shape\n\n(540, 1080)\n\n\n\nfrom sunkit_magex import pfss\n\n\nnr = 70    # number of cells in the radial direction\nrss = 2.5  # radius of the source surface in R_sun\npfss_input = pfss.Input(m_hmi_resample, nr, rss)\n\n\npfss_output = pfss.pfss(pfss_input)\n\nLetâ€™s plot the radial component of the magnetic field at the source surface (2.5 Rs) and the polarity inversion lines (PILs).\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection=pfss_output.source_surface_br)\nim = pfss_output.source_surface_br.plot(axes=ax)\nax.plot_coord(pfss_output.source_surface_pils[0], color='k')\nfig.colorbar(im, ax=ax);"
  },
  {
    "objectID": "posts/sunpy-paper-implementation/index.html#trace-magnetic-field-lines",
    "href": "posts/sunpy-paper-implementation/index.html#trace-magnetic-field-lines",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "Trace Magnetic Field Lines",
    "text": "Trace Magnetic Field Lines\nLetâ€™s trace some field lines through the extrapolated field.\nTo do this, we need to choose a set of seed points from which to trace our field lines. We want to select only the seed points that are within a certain area around the active region. We need to make the following transformations because we want to express our boundaries in terms of the active region boundary as identified by our SDO/AIA cutout.\n\nchange_obstime_frame = lambda x,y: x.replicate_without_data(observer=x.observer.replicate(obstime=y), obstime=y)\n\n\nnew_frame = change_obstime_frame(m_hmi.coordinate_frame, m_cutouts[0].date)\nnew_frame\n\n&lt;HeliographicCarrington Frame (obstime=2022-03-29T21:02:21.350, rsun=695700.0 km, observer=&lt;HeliographicStonyhurst Coordinate (obstime=2022-03-29T21:02:21.350, rsun=695700.0 km): (lon, lat, radius) in (deg, deg, m)\n    (0., -7.02110576, 1.48994814e+11)&gt;)&gt;\n\n\n\nblc_ar_synop = change_obstime(m_cutouts[0].bottom_left_coord.transform_to(new_frame),\n                              m_hmi.date)\ntrc_ar_synop = change_obstime(m_cutouts[0].top_right_coord.transform_to(new_frame),\n                              m_hmi.date)\n\nWe mask all those points that are above -10 G and fall outside of the bounding box defined above.\n\nmasked_pix_y, masked_pix_x = np.where(m_hmi_resample.data &lt; -1e1)\nseeds = m_hmi_resample.pixel_to_world(masked_pix_x*u.pix, masked_pix_y*u.pix).make_3d()\nin_lon = np.logical_and(seeds.lon &gt; blc_ar_synop.lon, seeds.lon &lt; trc_ar_synop.lon)\nin_lat = np.logical_and(seeds.lat &gt; blc_ar_synop.lat, seeds.lat &lt; trc_ar_synop.lat)\nseeds = seeds[np.where(np.logical_and(in_lon, in_lat))]\nseeds\n\n&lt;HeliographicCarrington Coordinate (obstime=2022-03-21T03:51:33.000, rsun=695700.0 km, observer=&lt;HeliographicStonyhurst Coordinate (obstime=2022-03-21T03:51:33.000, rsun=695700.0 km): (lon, lat, radius) in (deg, deg, m)\n    (0., -7.02110576, 1.48994814e+11)&gt;): (lon, lat, radius) in (deg, deg, km)\n    [(48.88333333, -5.63254256, 695700.),\n     (69.55      , -5.63254256, 695700.),\n     (74.88333333, -5.63254256, 695700.), ...,\n     (62.55      , 41.38466759, 695700.),\n     (63.88333333, 41.38466759, 695700.),\n     (71.55      , 41.38466759, 695700.)]&gt;\n\n\nWe can trace field lines from seeds specified above.\n\nds = 0.01\nmax_steps = int(np.ceil(10 * nr / ds))\ntracer = pfss.tracing.PerformanceTracer(step_size=ds, max_steps=max_steps)\nfieldlines = tracer.trace(SkyCoord(seeds), pfss_output)\n\nWe also want to adjust obstime of all coordinates to coincide with AR at disk center. By default, each field line will have the obstime of the map that the field extrapolation was computed from. Additionally, we will choose only the close field lines.\n\nfieldlines.closed_field_lines[0].coords.observer\n\n&lt;HeliographicStonyhurst Coordinate (obstime=2022-03-21T03:51:33.000, rsun=695700.0 km): (lon, lat, radius) in (deg, deg, m)\n    (0., -7.02110576, 1.48994814e+11)&gt;\n\n\n\nfline_coords = [change_obstime(f.coords, m_aia.date) for f in fieldlines.closed_field_lines if f.coords.shape[0]&gt;500]\n\n\nlen(fline_coords)\n\n1762\n\n\n\nfline_coords[0].observer\n\n&lt;HeliographicStonyhurst Coordinate (obstime=2022-03-29T21:02:21.350, rsun=695700.0 km): (lon, lat, radius) in (deg, deg, m)\n    (0., -7.02110576, 1.48994814e+11)&gt;\n\n\nFinally, letâ€™s plot these field lines on top of our EUV images.\n\nfig = plt.figure(figsize=(18, 5))\nfor i, m in enumerate(m_cutouts):\n    ax = fig.add_subplot(1, 3, i+1, projection=m)\n    m.plot(axes=ax, title=f'{m.observatory} {m.detector} {m.wavelength.to_string(format=\"latex\")}')\n    bounds = ax.axis()\n    for c in fline_coords[::5]:\n        ax.plot_coord(c, lw=1, color='C2', alpha=0.75)\n    ax.axis(bounds)"
  },
  {
    "objectID": "posts/sunpy-paper-implementation/index.html#figure-1-from-the-sunpy-paper-2023",
    "href": "posts/sunpy-paper-implementation/index.html#figure-1-from-the-sunpy-paper-2023",
    "title": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025",
    "section": "Figure 1 from the SunPy Paper (2023)",
    "text": "Figure 1 from the SunPy Paper (2023)\nWe can plot Figure 1 from the SunPy paper (2023).\n\nfrom matplotlib.patches import ConnectionPatch\nfrom matplotlib.gridspec import GridSpec\n\n\ndef add_connectors(ax1, ax2, p1, p2, color='k', lw=1):\n    con1 = ConnectionPatch(\n        (0, 1), ax1.wcs.world_to_pixel(p1), 'axes fraction', 'data', axesA=ax2, axesB=ax1,\n        arrowstyle='-', color=color, lw=lw\n    )\n    con2 = ConnectionPatch(\n        (1, 1), ax1.wcs.world_to_pixel(p2), 'axes fraction', 'data', axesA=ax2, axesB=ax1,\n        arrowstyle='-', color=color, lw=lw\n    )\n    ax2.add_artist(con1)\n    ax2.add_artist(con2)\n\nh_w_ratio = 21 / 18\nwidth = 12\nframe_color = 'C3'\nfig = plt.figure(figsize=(width, width*h_w_ratio))\ngs = GridSpec(3, 3, figure=fig)\n# Plot HMI synoptic map\nax = fig.add_subplot(gs[0, :2], projection=m_hmi)\nm_hmi.plot(axes=ax, title='HMI Synoptic Magnetogram (CR 2255)')\nm_hmi.draw_quadrangle(blc_ar_synop, top_right=trc_ar_synop, color=frame_color)\nax.coords[0].grid(color='k')\nax.coords[1].grid(color='k')\n# Plot spacecraft locations\nax = fig.add_subplot(gs[0, 2], projection='polar')\nax.plot(0, 0, marker='o', markersize=15, label='Sun', color='yellow')\nfor m in m_cutouts:\n    sat = m.observatory\n    coord = m.observer_coordinate\n    ax.plot(coord.lon.to('rad'), coord.radius.to(u.AU), 'o', label=sat)\n    ax.text(coord.lon.to_value('rad')*1.15, coord.radius.to_value(u.AU)*0.95, sat)\nax.set_theta_zero_location('S')\nax.set_rlabel_position(225)\nax.set_rlim(0, 1.1)\n# Plot full-disk EUV images\nfull_disk_axes = []\nfor i, m in enumerate([m_aia, m_eui, m_secchi]):\n    ax = fig.add_subplot(gs[1, i], projection=m)\n    m.plot(axes=ax, clip_interval=(1, 99.99)*u.percent, title=f'{m.observatory} {m.detector} {m.wavelength.to_string(format=\"latex\")}')\n    m.draw_quadrangle(m_cutouts[i].bottom_left_coord, top_right=m_cutouts[i].top_right_coord, color=frame_color, lw=1)\n    if i:\n        ax.coords[1].set_axislabel(' ')\n    ax.coords[0].set_axislabel(' ')\n    full_disk_axes.append(ax)\n    ax.coords[1].set_ticklabel(rotation=90)\n# Plot EUV cutouts with field lines\nfor i, m in enumerate(m_cutouts):\n    ax = fig.add_subplot(gs[2, i], projection=m)\n    m.plot(\n        axes=ax,\n        title=False,\n        clip_interval=(1, 99.99)*u.percent,\n    )\n    bounds = ax.axis()\n    for c in fline_coords[::8]:\n        ax.plot_coord(c, lw=1, color='C2', alpha=0.75)\n    ax.axis(bounds)\n    if i:\n        ax.coords[1].set_axislabel(' ')\n    bottom_right = SkyCoord(Tx=m_cutouts[i].top_right_coord.Tx, Ty=m_cutouts[i].bottom_left_coord.Ty, frame=m_cutouts[i].coordinate_frame)\n    add_connectors(full_disk_axes[i], ax, m_cutouts[i].bottom_left_coord, bottom_right, color=frame_color, lw=1)\n    ax.grid(alpha=0)\n    ax.coords[0].set_ticks(direction='in', color=frame_color)\n    ax.coords[1].set_ticks(direction='in', color=frame_color)\n    ax.coords[0].frame.set_color(frame_color)\n    ax.coords[0].frame.set_linewidth(1)\n    ax.coords[1].frame.set_color(frame_color)\n    ax.coords[1].frame.set_linewidth(1)\n    ax.coords[1].set_ticklabel(rotation=90)\n\nplt.subplots_adjust(hspace=0.0)\nplt.show()"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_high_level.html",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_high_level.html",
    "title": "Stable Diffusion Inference with Diffusers (high-level)",
    "section": "",
    "text": "Create an image using Diffusers library.\n\n\n\n!pip install -qq diffusers transformers scipy ftfy accelerate\n\n\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\n'cuda'\n\n\n\nprompt = [\"a photograph of an astronaut riding a horse\"]\n\nheight = 512  # default height of Stable Diffusion\nwidth = 512  # default width of Stable Diffusion\n\nnum_inference_steps = 50  # Number of denoising steps\n\nguidance_scale = 7.5  # Scale for classifier-free guidance\n\ngenerator = torch.manual_seed(256)  # Seed generator to create the inital latent noise\n\nbatch_size = 2\n\n\nfrom diffusers import LMSDiscreteScheduler, StableDiffusionPipeline\n\nscheduler = LMSDiscreteScheduler.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\"\n)\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", scheduler=scheduler\n)\n\n\npipe\n\nStableDiffusionPipeline {\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.20.2\",\n  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPImageProcessor\"\n  ],\n  \"requires_safety_checker\": true,\n  \"safety_checker\": [\n    \"stable_diffusion\",\n    \"StableDiffusionSafetyChecker\"\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"LMSDiscreteScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n\n\n\npipe = pipe.to(device)\n\n\n\n\n\npil_images = pipe(\n    prompt=prompt * batch_size,\n    height=height,\n    width=width,\n    num_inference_steps=num_inference_steps,\n    guidance_scale=guidance_scale,\n    generator=generator,\n).images\n\n\nfor pil_image in pil_images:\n    display(pil_image)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatil et al.Â (2022) Stable Diffusion with ðŸ§¨ Diffusers, https://huggingface.co/blog/stable_diffusion"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_high_level.html#install-and-import-libraries",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_high_level.html#install-and-import-libraries",
    "title": "Stable Diffusion Inference with Diffusers (high-level)",
    "section": "",
    "text": "!pip install -qq diffusers transformers scipy ftfy accelerate\n\n\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\n'cuda'\n\n\n\nprompt = [\"a photograph of an astronaut riding a horse\"]\n\nheight = 512  # default height of Stable Diffusion\nwidth = 512  # default width of Stable Diffusion\n\nnum_inference_steps = 50  # Number of denoising steps\n\nguidance_scale = 7.5  # Scale for classifier-free guidance\n\ngenerator = torch.manual_seed(256)  # Seed generator to create the inital latent noise\n\nbatch_size = 2\n\n\nfrom diffusers import LMSDiscreteScheduler, StableDiffusionPipeline\n\nscheduler = LMSDiscreteScheduler.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\"\n)\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", scheduler=scheduler\n)\n\n\npipe\n\nStableDiffusionPipeline {\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.20.2\",\n  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPImageProcessor\"\n  ],\n  \"requires_safety_checker\": true,\n  \"safety_checker\": [\n    \"stable_diffusion\",\n    \"StableDiffusionSafetyChecker\"\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"LMSDiscreteScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n\n\n\npipe = pipe.to(device)"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_high_level.html#high-level",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_high_level.html#high-level",
    "title": "Stable Diffusion Inference with Diffusers (high-level)",
    "section": "",
    "text": "pil_images = pipe(\n    prompt=prompt * batch_size,\n    height=height,\n    width=width,\n    num_inference_steps=num_inference_steps,\n    guidance_scale=guidance_scale,\n    generator=generator,\n).images\n\n\nfor pil_image in pil_images:\n    display(pil_image)"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_high_level.html#references",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_high_level.html#references",
    "title": "Stable Diffusion Inference with Diffusers (high-level)",
    "section": "",
    "text": "Patil et al.Â (2022) Stable Diffusion with ðŸ§¨ Diffusers, https://huggingface.co/blog/stable_diffusion"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html",
    "href": "posts/solar_eruptions_magnetic_fields/index.html",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "",
    "text": "This post is based on the presentation during the lab meeting on 2023-11-28."
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#heliophysics-2024-decadal-whitepapers",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#heliophysics-2024-decadal-whitepapers",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Heliophysics 2024 Decadal Whitepapers",
    "text": "Heliophysics 2024 Decadal Whitepapers"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#d-storage-release-caspi2023",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#d-storage-release-caspi2023",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "3D Storage & Release (Caspi et al. 2023)",
    "text": "3D Storage & Release (Caspi et al. 2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#solar-eruptions---storage-release-caspi2023",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#solar-eruptions---storage-release-caspi2023",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Solar eruptions - Storage & Release (Caspi et al. 2023)",
    "text": "Solar eruptions - Storage & Release (Caspi et al. 2023)\n\nCoronal mass ejections (CMEs)\nSolar flares\n\neruptive flares : flares with a CME\nconfined flares : flares not associated with a CME"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#the-big-open-questions-caspi2023",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#the-big-open-questions-caspi2023",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "The Big Open Questions (Caspi et al. 2023)",
    "text": "The Big Open Questions (Caspi et al. 2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#d-knowledge-caspi2023",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#d-knowledge-caspi2023",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "3D Knowledge (Caspi et al. 2023)",
    "text": "3D Knowledge (Caspi et al. 2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#solar-magnetic-field-models",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#solar-magnetic-field-models",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Solar magnetic field models",
    "text": "Solar magnetic field models\n\nStatic model (time-independent); \\mathbf{v} = \\mathbf{0}\n\nForce-free field model : initial condition of MHD simulations\n\npros: related with magnetic field observations directly\ncons: cannot explain the forced structures in the photosphere and lower chromosphere and their dynamical evolution\n\nMagnetohydrostatic (MHS) model\n\npros: partly overcome the disadvantage of the force-free field model\ncons: still static model\n\n\nDynamic model (time-dependent); \\mathbf{v} \\neq \\mathbf{0}\n\nMagnetohydrodynamic (MHD) model\n\npros: may provide the best way to study the observed complex magnetic structures and dynamical evolution\ncons: the most difficult, complicated and expensive model\n\n\n\n\nGuo et al. (2017b)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#plasma-beta-in-the-solar-atmosphere",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#plasma-beta-in-the-solar-atmosphere",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Plasma \\beta in the solar atmosphere",
    "text": "Plasma \\beta in the solar atmosphere\n\n\\beta = \\dfrac{p}{\\frac{B^2}{8\\pi}} is the ratio of gas pressure to magnetic pressure (cgs-Gaussian unit)\n\n\n\n\n\n\n\n\n\nGary (2001), Wiegelmann et al. (2017)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#suggested-physical-mechanisms",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#suggested-physical-mechanisms",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Suggested physical mechanisms",
    "text": "Suggested physical mechanisms\n\n\n\n\n\n\n\n\nGreen et al. (2018)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-fields",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-fields",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Magnetic fields",
    "text": "Magnetic fields\n\nFundamental quantities\n\nEnergy\nHelicity\nSurface-calculated quantities\n\nInstabilities\n\nKink instability\nTorus instability\nDouble arc instability\n\nMagnetic topology analysis (magnetic reconnection)\n\nSeparatrices\nQuasi-Separatrix Layers (QSLs)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-energy",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-energy",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Magnetic energy",
    "text": "Magnetic energy\n\nTotal magnetic energy E in a volume V (cgs-Gaussian units)\n\n\nE = \\frac{1}{8\\pi} \\int_{V} B^2 \\rm{d}V\n\n\n\n\n\n\n\n\n\nDeRosa et al. (2009)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#helmholtz-decomposition",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#helmholtz-decomposition",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Helmholtz decomposition",
    "text": "Helmholtz decomposition\n\nMagnetic field\n\n\n\\mathbf{B} = \\mathbf{B}_\\text{p} + \\mathbf{B}_\\text{J}\n\n\nPotential (current-free) field\n\n\n\\mathbf{B}_\\text{p} = \\nabla \\phi\n\n\nNon-potential (current-carrying) component of the magnetic field\n\n\n\\mathbf{B}_\\text{J} = \\mathbf{B} - \\mathbf{B}_\\text{p}\n\n\nCurrent density in MHD (cgs-Gaussian units)\n\n\n\\mathbf{J} = \\frac{1}{4\\pi} \\nabla \\times \\mathbf{B}"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#potential-field",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#potential-field",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Potential field",
    "text": "Potential field\n\nUsually, the potential field \\mathbf{B}_p is computed from the same distribution of normal field of \\mathbf{B} on the boundary of V.\n\n\n(\\mathbf{\\hat{n}} \\cdot \\mathbf{B}_\\text{p})|_{\\partial V} = (\\mathbf{\\hat{n}} \\cdot \\mathbf{B})|_{\\partial V}\n\n\nThen, the potential field \\mathbf{B}_\\text{p} = \\nabla \\phi is calculated by solving the Laplace equation with the Neumann boundary condition.\n\n\n\\begin{cases}\n\\nabla^2 \\phi &= 0\\\\\n(\\mathbf{\\hat{n}} \\cdot \\nabla \\phi)|_{\\partial V} & = (\\mathbf{\\hat{n}} \\cdot \\mathbf{B})|_{\\partial V}\n\\end{cases}\n\n\nWith such a prescription, the potential field is chosen as a reference is uniquely defined and represents the minimal energy state for a given distribution of the normal component of the field on the boundaries.\n\n\nValori et al. (2013)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-free-energy",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-free-energy",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Magnetic free energy",
    "text": "Magnetic free energy\n\nWithout changing the field significantly at the boundaries of the considered volume, the energy that can be converted into kinetic and thermal energies is given by the free enery, i.e., by the difference between the total magnetic energy and the energy of the corresponding current-free (potential) field.\n\n\nE_\\text{free} = E - E_\\text{p}\n\n\nTo use this formula, the magnetic field must be divergence-free (solenoidal).\n\n\n\n\n\n\n\n\n\nValori et al. (2013)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#accuracy-of-magnetic-energy-computations-valori2013",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#accuracy-of-magnetic-energy-computations-valori2013",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Accuracy of magnetic energy computations (Valori et al. 2013)",
    "text": "Accuracy of magnetic energy computations (Valori et al. 2013)\n\nDecomposition of the magnetic energy (Thomsonâ€™s theorem extended by Valori et al. 2013)\n\n\nE = E_\\text{p, s} + E_\\text{J, s} + E_\\text{p, ns} + E_\\text{J, ns} + E_\\text{mix}\n\nE_\\text{p, s} : energy of solenoidal component of the potential field (positive)\nE_\\text{J, s} : energy of solenoidal component of the current-carrying field (positive)\nE_\\text{p, ns} : energy of nonsolenoidal component of the potential field (positive)\nE_\\text{J, ns} : energy of nonsolenoidal component of the current-carrying field (positive)\nE_\\text{mix} : energy corresponding to all cross terms (can be negative)\n\n\\begin{align*}\nE_{\\text{mix}} & = \\frac{1}{4\\pi} \\left( \\int_{V} \\mathbf{B}_\\text{p,s} \\cdot \\nabla \\zeta \\, dV + \\int_{V} \\mathbf{B}_\\text{J,s} \\cdot \\nabla \\psi \\, dV \\right. \\\\\n& \\left. + \\int_{V} \\mathbf{B}_\\text{p,s} \\cdot \\nabla \\psi \\, dV + \\int_{V} \\mathbf{B}_\\text{J,s} \\cdot \\nabla \\zeta \\, dV \\right. \\\\\n& \\left. + \\int_{V} \\nabla \\zeta \\cdot \\nabla \\psi \\, dV + \\int_{V} \\mathbf{B}_\\text{p,s} \\cdot \\mathbf{B}_\\text{J,s} \\, dV \\right)\n\\end{align*}"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#accuracy-of-magnetic-energy-computations-valori2013-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#accuracy-of-magnetic-energy-computations-valori2013-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Accuracy of magnetic energy computations (Valori et al. 2013)",
    "text": "Accuracy of magnetic energy computations (Valori et al. 2013)\n\nFor a perfectly solenoidal field,\n\n\nE = E_\\text{p, s} + E_\\text{J, s}\n\n\nE_\\text{J, s} = E - E_\\text{p, s}\n\n\nThe free energy of the field is the energy of the solenoidal component of its current-carrying part\n\n\nE_\\text{free} = E_\\text{J, s}\n\n\nFor a nonsolenoidal field, \\tilde{E}_\\text{free} even can be negative.\n\n\n\\begin{align*}\n\\tilde{E}_{\\text{free}} & = E - E_\\text{p} \\\\\n& = E - (E_\\text{p, s} + E_\\text{p, ns}) \\\\\n& = E_\\text{J, s} + E_\\text{J, ns} + E_\\text{mix} \\\\\n& = E_\\text{free} + E_\\text{J, ns} + E_\\text{mix} \\\\\n\\end{align*}"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#accuracy-of-magnetic-energy-computations-valori2013-2",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#accuracy-of-magnetic-energy-computations-valori2013-2",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Accuracy of magnetic energy computations (Valori et al. 2013)",
    "text": "Accuracy of magnetic energy computations (Valori et al. 2013)\n\nE_\\text{div} : upper limit of the energy associated with all non-solenoidal components\n\n\nE_\\text{div} = E_\\text{p, ns} + E_\\text{J, ns} + |E_\\text{mix}|\n\n\nAt least (Valori et al. 2016),\n\n\nE_\\text{div} / E &lt; 0.1\n\n\nMore strictly (Thalmann et al. 2019),\n\n\nE_\\text{div} / E \\lesssim 0.05\n\n\nSimpler test (Mastrano et al. 2018) \\nabla \\cdot \\mathbf{B} = 0 \\Rightarrow W_\\text{f1} = W_\\text{f2} (inverse is not true)\n\n\nW_\\text{f1} = \\frac{1}{8\\pi} \\int_V (\\mathbf{B} - \\mathbf{B}_\\text{p})^2 \\rm{d}V\n\n\nW_\\text{f2} = \\frac{1}{8\\pi} \\int_V \\mathbf{B}^2 \\rm{d}V - \\frac{1}{8\\pi} \\int_V \\mathbf{B}_\\text{p}^2 \\rm{d}V"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#how-to-calculate-potential-field-mathbfb_textp-nabla-phi",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#how-to-calculate-potential-field-mathbfb_textp-nabla-phi",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "How to calculate potential field \\mathbf{B}_\\text{p} = \\nabla \\phi",
    "text": "How to calculate potential field \\mathbf{B}_\\text{p} = \\nabla \\phi\n\n\\mathbf{\\hat{n}} \\cdot \\mathbf{B} is given on the all boundaries\n\nSolve Laplace equation directly\n\n\n\n\\begin{cases}\n\\nabla^2 \\phi &= 0\\\\\n(\\mathbf{\\hat{n}} \\cdot \\nabla \\phi)|_{\\partial V} & = (\\mathbf{\\hat{n}} \\cdot \\mathbf{B})|_{\\partial V}\n\\end{cases}\n\n\n\\mathbf{\\hat{n}} \\cdot \\mathbf{B} is given on the only one boundary (usually bottom one)\n\nUse alternative ways such as Greenâ€™s function methods (Sakurai 1982)\n\n\n\n\\phi(\\mathbf{r}) = \\int_{S} \\frac{B_n(\\mathbf{r}')}{2\\pi|\\mathbf{r}-\\mathbf{r'}|} \\rm{d}S\n\n\nIf the reference potential field does not have the same normal components on all boundaries, then the potential field does not satisfy Thomsonâ€™s theorem, and does not represent the state with the minimum energy for a given distribution of magnetic field on the boundaries (Mastrano et al. 2018)."
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-helicity",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-helicity",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Magnetic helicity",
    "text": "Magnetic helicity\n\nClassical magnetic helicity\n\n\n\\mathscr{H} = \\int_V \\mathbf{A} \\cdot \\mathbf{B} \\rm{d}V\n\n\nRelative magnetic helicity (Berger & Field (1984) and Finn & Antonsen (1985))\n\n\nH_V = \\int_V (\\mathbf{A} + \\mathbf{A}_\\text{p}) \\cdot (\\mathbf{B} - \\mathbf{B}_\\text{p}) \\rm{d}V\n\n\n\\mathbf{A} : vector potential of \\mathbf{B} = \\nabla \\times \\mathbf{A}\n\\mathbf{A}_\\text{p} : vector potential of \\mathbf{B}_\\text{p} = \\nabla \\times \\mathbf{A}_\\text{p}\nIn order for H_V to be gauge invariant,\n\n\\mathbf{B} and \\mathbf{B}_\\text{p} are solenoidal (divergence-free)\nreference field \\mathbf{B}_\\text{p} satisfies (\\mathbf{\\hat{n}} \\cdot \\mathbf{B}_\\text{p})|_{\\partial V} = (\\mathbf{\\hat{n}} \\cdot \\mathbf{B})|_{\\partial V}\n\nThe usual choice of the reference field is the electirc current-free (potential) field.\n\n\nValori et al. (2016)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#decomposition-of-the-magnetic-helicity-berger2003",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#decomposition-of-the-magnetic-helicity-berger2003",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Decomposition of the magnetic helicity (Berger 2003)",
    "text": "Decomposition of the magnetic helicity (Berger 2003)\n\nRelative magnetic helicity\n\n\nH_V = \\int_V (\\mathbf{A} + \\mathbf{A}_\\text{p}) \\cdot (\\mathbf{B} - \\mathbf{B}_\\text{p}) \\rm{d}V\n\n\nDecomposition of H_V\n\n\nH_V = H_\\text{J} + H_\\text{PJ}\n\n\nH_\\text{J}: classical magnetic helicity of \\mathbf{B}_\\text{J} = \\mathbf{B} - \\mathbf{B}_\\text{p}\n\n\nH_\\text{J} = \\int_V (\\mathbf{A} - \\mathbf{A}_\\text{p}) \\cdot (\\mathbf{B} - \\mathbf{B}_\\text{p}) \\rm{d}V\n\n\nH_\\text{PJ}: a sorf of multual helicity between \\mathbf{B}_\\text{p} and \\mathbf{B}_\\text{J}\n\n\nH_\\text{PJ} = 2\\int_V \\mathbf{A}_\\text{p} \\cdot (\\mathbf{B} - \\mathbf{B}_\\text{p}) \\rm{d}V"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#reliability-of-magnetic-energy-and-helicity-computations-thalmann2019",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#reliability-of-magnetic-energy-and-helicity-computations-thalmann2019",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Reliability of magnetic energy and helicity computations (Thalmann et al. 2019)",
    "text": "Reliability of magnetic energy and helicity computations (Thalmann et al. 2019)\n\nQuantitative threshold for the divergence-freeness\n\n\nE_\\text{div} / E \\lesssim 0.05\n\nHere, E_\\text{div} = E_\\text{p, ns} + E_\\text{J, ns} + |E_\\text{mix}| is the nonpotential contribution and E is the total magnetic energy."
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#reliability-of-magnetic-energy-and-helicity-computations-thalmann2019-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#reliability-of-magnetic-energy-and-helicity-computations-thalmann2019-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Reliability of magnetic energy and helicity computations (Thalmann et al. 2019)",
    "text": "Reliability of magnetic energy and helicity computations (Thalmann et al. 2019)\n\nNOAA 11158 between February 12 00:00 UT and February 16 00:00 UT\nFree parameters\n\nPreprocessing (Wiegelmann et al. 2006)\n\n(\\mu_1, \\mu_2, \\mu_3, \\mu_4)\n\nNLFFF optimization method of Wiegelmann & Inhester (2010)\n\n(w_f, w_d, w_\\text{hor}, \\nu)\n\n\n(\\mu_1, \\mu_2, w_f, \\nu) = (1, 1, 1, 10^{-3})\n\nSERIES I\n\n(\\mu_3, \\mu_4, w_d, w_\\text{hor}) = (10^{-3}, 10^{-3}, 1, 1)\n\nSERIES II\n\n(\\mu_3, \\mu_4, w_d, w_\\text{hor}) = (10^{-3}, 10^{-3}, 2, \\propto B_\\text{hor})"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#reliability-of-magnetic-energy-and-helicity-computations-thalmann2019-2",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#reliability-of-magnetic-energy-and-helicity-computations-thalmann2019-2",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Reliability of magnetic energy and helicity computations (Thalmann et al. 2019)",
    "text": "Reliability of magnetic energy and helicity computations (Thalmann et al. 2019)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoulomb gauge\n\n\n\\nabla \\cdot \\mathbf{A} = \\nabla \\cdot \\mathbf{A}_\\text{p} = 0\n\n\nDeVore gauge (DeVore 2000)\n\n\nA_z = A_\\text{p, z} = 0"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#how-to-calculate-magnetic-helicity",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#how-to-calculate-magnetic-helicity",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "How to calculate magnetic helicity",
    "text": "How to calculate magnetic helicity\n\n\n\n\n\n\n\n\nValori et al. (2016)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#connectivity-based-methods",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#connectivity-based-methods",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Connectivity-based methods",
    "text": "Connectivity-based methods\n\nUse the magnetic connectivity matrix to calculate E_\\text{c} and H_m (Georgoulis et al. 2012)\n\n\n\n\\begin{align*}\nE_\\text{c} & = E_{\\text{c}_\\text{self}} + E_{\\text{c}_\\text{mul}} \\\\\n& = Ad^2 \\sum_{l=1}^{N} \\alpha_l^2 \\Phi_l^{2\\delta} + \\frac{1}{8\\pi}\\sum_{l=1}^{N}\\sum_{m=1, l\\neq m}^{N} \\alpha_l \\mathcal{L}_{lm}^{\\text{arch}}\\Phi_{l}\\Phi_{m}\n\\end{align*}\n\n\n\n\n\\begin{align*}\nH_\\text{m} & = H_{\\text{m}_\\text{self}} + H_{\\text{m}_\\text{mul}} \\\\\n& = 8\\pi d^2 A \\sum_{l=1}^{N} \\alpha_l \\Phi_l^{2\\delta} + \\sum_{l=1}^{N}\\sum_{m=1, l\\neq m}^{N} \\mathcal{L}_{lm}^{\\text{arch}}\\Phi_{l}\\Phi_{m}\n\\end{align*}\n\n\n\n\n\n\n\n\n\n\nTziotziou et al. (2012)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#free-energy-relative-helicity-diagram-of-solar-ars-tziotziou2012",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#free-energy-relative-helicity-diagram-of-solar-ars-tziotziou2012",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Free energy â€“ Relative helicity diagram of solar ARs (Tziotziou et al. 2012)",
    "text": "Free energy â€“ Relative helicity diagram of solar ARs (Tziotziou et al. 2012)\n\nBlue diamonds : Non-flaring ARs\nRed squares/asterisks : M-/X-class flaring ARs\n\n\n\n\n\n\n\n\n\n\nThreshold for relative magnetic helicity H_\\text{V}  (denoted as |H_m| in this diagram)\n\n\n|H_\\text{V}| \\sim 2 \\times 10^{42} \\text{ Mx}^2\n\n\nThreshold for free magnetic energy E_\\text{free}  (denoted as E_\\text{c} in this diagram)\n\n\nE_\\text{free} \\sim 4 \\times 10^{31} \\text{ erg}\n\n\nScaling relation (Tziotziou et al. 2014)\n\n\n|H_V| \\propto E_\\text{free}^{0.84 \\pm 0.05}"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#relative-magnetic-helicity-as-a-diagnostic-of-solar-eruptivity-pariat2017",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#relative-magnetic-helicity-as-a-diagnostic-of-solar-eruptivity-pariat2017",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Relative magnetic helicity as a diagnostic of solar eruptivity (Pariat et al. 2017)",
    "text": "Relative magnetic helicity as a diagnostic of solar eruptivity (Pariat et al. 2017)\n\n\n\n\n\n\n\n\n\n3D visco-resistive MHD simulations\n\nND : no arcade\nWD : weak arcade\nMD : medium arcade\nSD : strong arcade\n\n\n\n\n\nfrom t = 0 to t=200\n\nt &lt; 30 : emerging flux rope rises in the convection zone\nt \\in [30, 120] : pre-eruptive phase\nt \\in [120, 150] : eruptive phase\nt  &gt; 150 : post-eruptive phase"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#relative-magnetic-helicity-as-a-diagnostic-of-solar-eruptivity-pariat2017-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#relative-magnetic-helicity-as-a-diagnostic-of-solar-eruptivity-pariat2017-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Relative magnetic helicity as a diagnostic of solar eruptivity (Pariat et al. 2017)",
    "text": "Relative magnetic helicity as a diagnostic of solar eruptivity (Pariat et al. 2017)\n\nH_V = H_\\text{J} + H_\\text{PJ}\n\n\nE = E_\\text{free} + E_\\text{p}\n\nHere, E = E_\\text{mag} and E_\\text{inj} = E_\\text{mag} - E_\\text{mag}(t=0)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#relative-magnetic-helicity-as-a-diagnostic-of-solar-eruptivity-pariat2017-2",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#relative-magnetic-helicity-as-a-diagnostic-of-solar-eruptivity-pariat2017-2",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Relative magnetic helicity as a diagnostic of solar eruptivity (Pariat et al. 2017)",
    "text": "Relative magnetic helicity as a diagnostic of solar eruptivity (Pariat et al. 2017)\n\nH_V = H_\\text{J} + H_\\text{PJ}\n\n\nE = E_\\text{free} + E_\\text{p}\n\nHere, E = E_\\text{mag} and E_\\text{inj} = E_\\text{mag} - E_\\text{mag}(t=0)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#changes-of-magnetic-energy-and-helicity-in-solar-ars-from-major-flares-liu2023",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#changes-of-magnetic-energy-and-helicity-in-solar-ars-from-major-flares-liu2023",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Changes of Magnetic Energy and Helicity in Solar ARs from Major Flares (Liu et al. 2023)",
    "text": "Changes of Magnetic Energy and Helicity in Solar ARs from Major Flares (Liu et al. 2023)\n\nHere, H = H_V"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---sharp-parameters",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---sharp-parameters",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Surface-calculated quantities - SHARP parameters",
    "text": "Surface-calculated quantities - SHARP parameters\n\nSOLAR FLARE PREDICTION USING SDO/HMI VECTOR MAGNETIC FIELD DATA WITH A MACHINE-LEARNING ALGORITHM (Bobra et al. 2015)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---mathbfv-or-mathbfe",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---mathbfv-or-mathbfe",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Surface-calculated quantities - \\mathbf{v} or \\mathbf{E}",
    "text": "Surface-calculated quantities - \\mathbf{v} or \\mathbf{E}\n\n\\mathbf{v} : DAVE4VM (differential affine velocity estimator for vector magnetograms) (Schuck 2008)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---mathbfv-or-mathbfe-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---mathbfv-or-mathbfe-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Surface-calculated quantities - \\mathbf{v} or \\mathbf{E}",
    "text": "Surface-calculated quantities - \\mathbf{v} or \\mathbf{E}\n\n\\mathbf{E} : PDFI_SS (Fisher et al. 2020)\n\nPDFI : poloidalâ€“toroidal decomposition (PTD) plus Doppler plus Fourier local correlation tracking (FLCT) plus ideal\nSS : spherical staggered"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---mathbfv-or-mathbfe-2",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---mathbfv-or-mathbfe-2",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Surface-calculated quantities - \\mathbf{v} or \\mathbf{E}",
    "text": "Surface-calculated quantities - \\mathbf{v} or \\mathbf{E}\n\nDAVE4VM vs PDFI_SS (Wang et al. 2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---flux-of-quantities",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---flux-of-quantities",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Surface-calculated quantities - Flux of quantities",
    "text": "Surface-calculated quantities - Flux of quantities\n\nMagnetic energy (Poynting) flux (Schuck 2006; Guo et al. 2017b; Liu et al. 2023)\n\n\n\\left.\\frac{dE}{dt}\\right|_{S} = \\frac{1}{4\\pi}\\int_{S}B_t^2V_{\\perp n}\\rm{d}S - \\frac{1}{4\\pi}\\int_{S}(\\mathbf{B}_t \\cdot \\mathbf{V}_{\\perp t})B_n \\rm{d}S\n\n\nFlux of magnetic helicity (Berger 1984; Chae 2001; Liu et al. 2023)\n\n\n\\left.\\frac{dH}{dt}\\right|_{S} = 2\\int_{S}(\\mathbf{A}_p \\cdot \\mathbf{B}_t)\\rm{d}S - 2\\int_{S}(\\mathbf{A}_p \\cdot \\mathbf{V}_{\\perp t})B_n \\rm{d}S"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---flux-of-quantities-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---flux-of-quantities-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Surface-calculated quantities - Flux of quantities",
    "text": "Surface-calculated quantities - Flux of quantities\n\nOn short timescales (~1 hr) after eruptive flares, there are decreases in both the coronal magnetic energy, E, and helicity H; and their photospheric fluxes, dE/dt and dH/dt. (Liu et al. 2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---flux-of-quantities-2",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---flux-of-quantities-2",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Surface-calculated quantities - Flux of quantities",
    "text": "Surface-calculated quantities - Flux of quantities\n\nFluxes of topological quantities (Alielden et al. 2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---flux-of-quantities-3",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#surface-calculated-quantities---flux-of-quantities-3",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Surface-calculated quantities - Flux of quantities",
    "text": "Surface-calculated quantities - Flux of quantities\n\nFluxes of topological quantities (Alielden et al. 2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-flux-rope-mfr",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-flux-rope-mfr",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Magnetic flux rope (MFR)",
    "text": "Magnetic flux rope (MFR)\n\nMagnetic flux rope (MFR) can be defined as a coherent group of magnetic field lines winding an axis with more than one turn (Liu et al. 2016; Duan et al. 2019).\nMagnetic flux rope of the Titovâ€“DÃ©moulin semi-analytical NLFFF model (Titov et al. 1999; Guo et al. 2017a)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#kink-instability-ki",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#kink-instability-ki",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Kink instability (KI)",
    "text": "Kink instability (KI)\n\nMagnetic twist number T_\\text{w} for a given (closed) field line (Berger et al. 2006; Jing et al. 2018; Duan et al. 2019)\n\n\nT_\\text{w} = \\int_L \\frac{(\\nabla \\times \\mathbf{B}) \\cdot \\mathbf{B}}{4 \\pi B^2} \\rm{d}l\n\n\nIf the magnetic field is force-free, i.e., \\nabla \\times \\mathbf{B} = \\alpha \\mathbf{B},\n\n\nT_\\text{w} = \\frac{1}{4\\pi} \\int_L \\alpha \\rm{d}l\n\n\nKI parameter - There is a critical value to determine whether MFR is eruptive or not.\n\n\n|T_\\text{w}| &gt; |T_\\text{w}|_\\text{crit}\n\n\nT_\\text{w} is not identical to the classical winding number of field lines about a common axis, the parameter often used in the analysis of the helical KI. Nevertheless, accroding to Liu et al.â€™s (2016) analysis, the magnetic field line that possesses the extremum value (maximum or minimum) of |T_\\text{w}| in a MFR can be reliably regarded as the rope axis, and T_\\text{w} computed in the vicinity of the axis approaches the winding number. (Duan et al. 2019)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#identification-of-mfrs-duan2019",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#identification-of-mfrs-duan2019",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Identification of MFRs (Duan et al. 2019)",
    "text": "Identification of MFRs (Duan et al. 2019)\n\nMFRs generally exist prior to major solar flares. With a rigorous definition, over 90% of the studied events have well-defined MFRs in the flare site, i.e., a coherent group of magnetic field lines with twists above one turn and the field line possessing the peak value of twist being the rope axis. The other 10% of events also have MFR-like structures as their magnetic twist numbers are very close to one. Most of the MFRs have corresponding filaments or filament channels as seen in SDO/AIA 304 Ã… observations. (Duan et al. 2019)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#identification-of-mfrs-duan2019-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#identification-of-mfrs-duan2019-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Identification of MFRs (Duan et al. 2019)",
    "text": "Identification of MFRs (Duan et al. 2019)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#torus-instability-ti",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#torus-instability-ti",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Torus instability (TI)",
    "text": "Torus instability (TI)\n\nDecay index n (Kliem et al. 2006; Jing et al. 2018; Duan et al. 2019)\n\n\nn = - \\frac{\\partial \\log (B_\\text{ext})}{\\partial \\log (h)}\n\n\nB_\\text{ext} : external strapping field stabilizing the MFR (usually potential field)\nh : vertical height locally, radial distance globally, or oblique height\nTI parameter - There is a critical value to determine whether MFR is eruptive or not.\n\n\nn &gt; n_\\text{crit}"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#torus-instability-ti-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#torus-instability-ti-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Torus instability (TI)",
    "text": "Torus instability (TI)\n\nIllustration of calculating the decay index n at the apex of the MFR axis (Duan et al. 2019)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#ti-parameter---ki-parameter-diagram",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#ti-parameter---ki-parameter-diagram",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "TI Parameter - KI Parameter diagram",
    "text": "TI Parameter - KI Parameter diagram\n\nLaboratory experiment designed to study the Sun-like line-tied MFRs (Myers et al. 2015)\n\n\n\n\nVideo"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#ti-parameter---ki-parameter-diagram-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#ti-parameter---ki-parameter-diagram-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "TI Parameter - KI Parameter diagram",
    "text": "TI Parameter - KI Parameter diagram\n\nLaboratory experiment designed to study the Sun-like line-tied MFRs (Myers et al. 2015)\n\n\n\n\n\n\n\n\n\n\nPotential field decay index n\n\n\nn(z) = - \\frac{z}{|\\mathbf{B}_\\text{pot}|}\\frac{\\partial |\\mathbf{B}_\\text{pot}|}{\\partial z}\n\n\nEdge safety factor q_a : inverse of the edge magnetic twist \\iota_a\n\n\nq_a = \\frac{2\\pi}{\\iota_a} = \\left.\\frac{\\rm{d}\\Phi_\\text{T}}{\\rm{d}\\psi_\\text{P}}\\right|_{r=a} \\approx \\frac{2\\pi a}{L}\\frac{B_\\text{Ta}}{B_\\text{Pa}}"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#ti-parameter---ki-parameter-diagram-2",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#ti-parameter---ki-parameter-diagram-2",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "TI Parameter - KI Parameter diagram",
    "text": "TI Parameter - KI Parameter diagram\n\nStatistical Analysis of Torus and Kink Instabilities in Solar Eruptions (Jing et al. 2018)\n\nBlack : confined flare\nColor : ejective flare\n\n\n\n\n\n\n\n\n\n\n\n\nT_\\text{w} appears to play little role in discriminating between confined and ejective events\n\n\nThe events with n \\gtrsim 0.8 are all ejective, and all confined events have n \\lesssim 0.8. However, n \\gtrsim 0.8 is not a necessary condition for eruption because some events with n \\lesssim 0.8 also erupted."
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#ti-parameter---ki-parameter-diagram-3",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#ti-parameter---ki-parameter-diagram-3",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "TI Parameter - KI Parameter diagram",
    "text": "TI Parameter - KI Parameter diagram\n\nA Study of Pre-flare Solar Coronal Magnetic Fields: Magnetic Flux Ropes (Duan et al. 2019)\n\nGreen : non-MFR event (|T_\\text{w}|_\\text{max} &lt; 1)\n\n\n\n\n\n\n\n\n\n\nIt clearly shows lower limits for TI and KI thresholds, which are n_\\text{crit}=1.3 and |T_\\text{w}|_\\text{crit}=2, respectively, as all the events above n_\\text{crit} and nearly 90% of the events above |T_\\text{w}|_\\text{crit}| erupted. Furthermore, by such criterion, over 70% of the events can be discriminated between eruptive and confined flares, and KI seems to play a nearly equally important role as TI in discriminating between the two types of flares. More than half of the events with both parameters are below the lower limits, and 29% are eruptive. These events might be triggered by magnetic reconnection rather than MHD instabilities."
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#tether-cutting-reconnection",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#tether-cutting-reconnection",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Tether-cutting reconnection",
    "text": "Tether-cutting reconnection\n\nTether-cutting reconnection scenario proposed by Moore et al. (2001) explains the eruption of the sigmoidal field often observed before solar eruptions. (Ishiguro et al. 2017)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#tether-cutting-reconnection-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#tether-cutting-reconnection-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Tether-cutting reconnection",
    "text": "Tether-cutting reconnection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChen et al. (2014)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#double-arc-instability-ishiguro2017",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#double-arc-instability-ishiguro2017",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Double arc instability (Ishiguro et al. 2017)",
    "text": "Double arc instability (Ishiguro et al. 2017)\n\nThe tether-cutting scenario proposes that the internal reconnection proceeds in the core of the sheared magnetic field in the pre-eruptive phase, and it may form a double arc flux rope (sigmoidal field) that carries an electric current (Ishiguro et al. 2017).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIshiguro et al. (2017), Kusano et al. (2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#double-arc-instability",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#double-arc-instability",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Double arc instability",
    "text": "Double arc instability\n\nDAI parameter \\kappa (Ishiguro et al. 2017; Muhamad et al. 2018; Kusano et al. 2020)\n\n\n\\kappa = T_\\text{w} \\frac{\\Phi_\\text{rec}}{\\Phi_\\text{over}}\n\n\nT_\\text{w} : magnetic twist of the DA\n\\Phi_\\text{rec} : magnetic flux within DA\n\\Phi_\\text{over} : magnetic flux overlying DA\n\n\nThere is a threshold.\n\n\n\\kappa &gt; \\kappa_0"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#a-physics-based-method-that-can-predict-imminent-large-solar-flares-kusano2020",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#a-physics-based-method-that-can-predict-imminent-large-solar-flares-kusano2020",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "A physics-based method that can predict imminent large solar flares (Kusano et al. 2020)",
    "text": "A physics-based method that can predict imminent large solar flares (Kusano et al. 2020)\n\n\\kappa is evaluated by\n\n\n\\kappa = \\left|\\frac{\\int_\\text{rec} T_\\text{w}\\rm{d}\\Phi}{\\Phi_{\\text{over}}}\\right|\n\nwhere the integral is taken over the magnetic flux subject to the trigger-reconnection which forms the DA.\n\nIf the DA is formed by the magnetic reconnection of magnetic fluxes rooted near the PIL, then \\kappa can be calculated by the area integral over the reconnection-region S_\\text{rec} on the photosphere: \n\\kappa = \\left|\\frac{\\int_{S_\\text{rec}} \\tau\\rm{d}S}{\\Phi_{\\text{over}}}\\right|\n\n\nwhere\n\n\\tau = T_\\text{w}|B_z|\n\nis defined as the magnetic twist flux density with the vertical magnetic field B_z."
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#kappa-scheme-kusano2020",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#kappa-scheme-kusano2020",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "\\kappa-scheme (Kusano et al. 2020)",
    "text": "\\kappa-scheme (Kusano et al. 2020)\n\ncalculate T_\\text{w}\ncalculate \\tau = T_\\text{w} |B_z|\ncalculate B_{\\text{np}} = |\\mathbf{B}_{\\text{h}} - \\mathbf{B}_\\text{p}|\nidentify multiple High Free-Energy Regions (HiFERs) using the condition B_\\text{np} &gt; B_0 = 1000 \\text{ G}\nsort the HiFERs by the size (largest size is the fisrt HiFER). S_{H, i} is the area of the i-th HiFER\nselect one point in PIL within HiFER\nconsider hypothetical reconnection region as a circle with r\ncalculate unsigned magnetic flux of each pole\nfor area with small unsigned magnetic flux, calculate \\int_{S_\\text{rec}}  \\tau \\rm{d}S\nidentify magnetic field lines rooted on the hypothetical reconnection region (predicted trigger-reconnection region)\nidentify strongest sheared field line among them, which is defined by field line that reaches farthest from the reconnection region\ncalculate \\Phi_{\\text{over}} for all flux crossing over the strongest sheared field line\ncalculate \\kappa = \\left| \\frac{\\int_{S_\\text{rec}}  \\tau \\rm{d}S}{\\Phi_{\\text{over}}} \\right|\nsince \\kappa depends on r (radius of reconnection region), we can find the minimum r while satisfying \\kappa &gt; \\kappa_0 = 0.1\nThe minium r is the critical length scale r_c\nfor each point with r_c, calculate the area of the footprint of the overlying field within the HiFER S_r\ncalculate the first level of releasable energy E_r = \\displaystyle \\frac{S_r ^{1/2}}{8\\pi}  \\int_{S_r} B^2_{\\text{np}} \\rm{d} S, which is the mininum energy of the flare driven by a DAI\ncalculate the second level of releasable energy for i-th HiFER E_{H, i} = \\displaystyle \\frac{S_{H, i} ^{1/2}}{8\\pi}  \\int_{S_{H, i}} B^2_{\\text{np}} \\rm{d} S\ncalculate the total free energy of an AR E_{\\text{AR}} = \\displaystyle \\sum_i E_{H, i}"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#kappa-scheme-kusano2020-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#kappa-scheme-kusano2020-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "\\kappa-scheme (Kusano et al. 2020)",
    "text": "\\kappa-scheme (Kusano et al. 2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#a-physics-based-method-that-can-predict-imminent-large-solar-flares-kusano2020-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#a-physics-based-method-that-can-predict-imminent-large-solar-flares-kusano2020-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "A physics-based method that can predict imminent large solar flares (Kusano et al. 2020)",
    "text": "A physics-based method that can predict imminent large solar flares (Kusano et al. 2020)\n\nIf any point on a PIL satisfies the conditions r_c &lt; 1 \\text{ Mm} and E_r &gt; 4 \\times 10^{31} \\text{ erg}, an X-class flare usually occurs.\n\n\n\n\n\n\n\n\n\n\n\nVideo"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-topology-analysis",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#magnetic-topology-analysis",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Magnetic topology analysis",
    "text": "Magnetic topology analysis\n\nThe random or user-defined tracing of magnetic field lines does not guarantee that key features of the magnetic field will be identified.\n\n\n\n\n\n\n\n\n\nMagnetic reconnection, responsible for changing both the topology and geometry of a magnetic field, is a typical example of a phenomenon whose occurrence is strongly associated with the geometry of the magnetic field.\nIn particular, magnetic reconnection is linked to the formation of intense field-aligned current sheets, that are induced by the existence of gradients of the magnetic field, following AmpÃ¨reâ€™s equation (\\mu_0 \\mathbf{J} = \\nabla \\times \\mathbf{B}).\nThese currents develop preferentially in specific locations of the magnetic field, that is in regions where the connectivity of the magnetic field is discontinuous.\nThe aim of the magnetic topology is to determine the locations of such regions.\n\n\nPariat (2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#separatrices",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#separatrices",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Separatrices",
    "text": "Separatrices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet us consider a field line which links the footpoint \\mathbf{r}_1 of coordinate (x_1, y_1) of the plane P_1 to the footpoint \\mathbf{r}_2, of coordinate (X_2, Y_2) of the plane P_2.\nTwo mappings exist that associate a footpoint on one plane to the other: the mapping \\Pi_{12} from P_1 to P_2: \\mathbf{r}_1(x_1, y_1) \\mapsto \\mathbf{r}_2(X_2, Y_2); and the inverse mapping \\Pi_{21} from P_2 to P_1: \\mathbf{r}_2(X_2, Y_2) \\mapsto \\mathbf{r}_1(x_1, y_1).\nA separatrix is present when the mapping contains a discontinuity, i.e.Â where the function \\Pi_{12} (or \\Pi_{21}) is discontinuous.\n\n\nLongcope et al. (2008), Pariat et al. (2012), Pariat (2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#separatrices---regions-of-magnetic-field-discontinuity",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#separatrices---regions-of-magnetic-field-discontinuity",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Separatrices - Regions of magnetic field discontinuity",
    "text": "Separatrices - Regions of magnetic field discontinuity\n\nNull points \\mathbf{x}_\\text{NP}\n\n\n\\mathbf{B}(\\mathbf{x}_\\text{NP}) = \\mathbf{0}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLongcope (2005), Jiang et al. (2017), Mason et al. (2019), Pariat (2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#separatrices---regions-of-magnetic-field-discontinuity-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#separatrices---regions-of-magnetic-field-discontinuity-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Separatrices - Regions of magnetic field discontinuity",
    "text": "Separatrices - Regions of magnetic field discontinuity\n\nBald patches (BPs)\n\nRegions where some field lines touch the boundary tangentially\n\n\n\n\\mathbf{x}_\\text{BP} \\in \\partial V \\quad \\text{with } \\partial V \\text{ a line-tying boundary}\n\n\nB_n (\\mathbf{x}_\\text{BP}) = 0\n\n\n(\\mathbf{B} \\cdot \\nabla B_n)(\\mathbf{x}_\\text{BP}) &gt; 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLongcope (2005), Jiang et al. (2017), Mason et al. (2019), Pariat (2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#separatrices---regions-of-magnetic-field-discontinuity-2",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#separatrices---regions-of-magnetic-field-discontinuity-2",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Separatrices - Regions of magnetic field discontinuity",
    "text": "Separatrices - Regions of magnetic field discontinuity\n\nSeparators\n\n1D topological structures and are found at the intersection of two separatrix surfaces.\nSeparators can be found to connect two 3D magnetic null points.\n\n\n\n\n\n\n\n\n\n\nLongcope (2005), Jiang et al. (2017), Mason et al. (2019), Pariat (2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#quasi-separatrix-layers-qsls",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#quasi-separatrix-layers-qsls",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Quasi-Separatrix Layers (QSLs)",
    "text": "Quasi-Separatrix Layers (QSLs)\n\nNumerous solar flares, however, have not been associated with separatrices, i.e.Â with magnetic-field connectivity discontinuities. This has led to the generalization of the concept of separatrices to Quasi-Separatrix Layers (QSLs). QSLs were introduced in DÃ©moulin et al. (1996) and are defined as regions where the mapping of the field lines, while still continuous (unlike seperatrices), possesses very strong gradients.\nQSLs are 3D magnetic volumes of high squashing factor Q, in which the magnetic connectivity varies strongly.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPariat (2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#squashing-factor-q",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#squashing-factor-q",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "Squashing factor Q",
    "text": "Squashing factor Q\n\n\n\n\n\n\n\n\nMappings\n\n\\Pi_{12} : \\mathbf{r}_1(x_1, y_1) \\mapsto \\mathbf{r}_2(X_2, Y_2)\n\\Pi_{21} : \\mathbf{r}_2(X_2, Y_2) \\mapsto \\mathbf{r}_1(x_1, y_1).\n\nJacobian matrices associated with the mappings\n\n\nD_{12} = \\frac{d\\mathbf{r}_2}{d\\mathbf{r}_1} = \\begin{pmatrix}\n\\displaystyle  \\frac{\\partial X_2}{\\partial x_1} & \\displaystyle \\frac{\\partial X_2}{\\partial y_1} \\\\\n\\\\\n\\displaystyle  \\frac{\\partial Y_2}{\\partial x_1} & \\displaystyle \\frac{\\partial Y_2}{\\partial y_1}\n\\end{pmatrix}\n\\quad \\quad\nD_{21} = \\frac{d\\mathbf{r}_1}{d\\mathbf{r}_2} = \\begin{pmatrix}\n\\displaystyle  \\frac{\\partial x_1}{\\partial X_2} & \\displaystyle \\frac{\\partial x_1}{\\partial Y_2} \\\\\n\\\\\n\\displaystyle  \\frac{\\partial y_1}{\\partial X_2} & \\displaystyle \\frac{\\partial y_1}{\\partial Y_2}\n\\end{pmatrix}\n\n\nNorms of the Jacobian matrices\n\n\nN_{12} = \\sqrt{\\left( \\frac{\\partial X_2}{\\partial x_1} \\right)^2 + \\left( \\frac{\\partial X_2}{\\partial y_1} \\right)^2 + \\left( \\frac{\\partial Y_2}{\\partial x_1} \\right)^2 + \\left( \\frac{\\partial Y_2}{\\partial y_1} \\right)^2}\n\n\nN_{21} = \\sqrt{\\left( \\frac{\\partial x_1}{\\partial X_2} \\right)^2 + \\left( \\frac{\\partial x_1}{\\partial Y_2} \\right)^2 + \\left( \\frac{\\partial y_1}{\\partial X_2} \\right)^2 + \\left( \\frac{\\partial y_1}{\\partial Y_2} \\right)^2}.\n\n\nDeterminants of the Jacobian matrices\n\n\n\\Delta_{12} = \\text{det}(D_{12})\n\\quad \\quad\n\\Delta_{21} = \\text{det}(D_{21})\n\n\nSquashing factor (or squashing degree) Q for a field line\n\n\nQ = \\frac{N_{12}^2}{|\\Delta_{12}|} = \\frac{N_{21}^2}{|\\Delta_{21}|}\n\n\nPariat (2020)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#qsl-reconnection",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#qsl-reconnection",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "QSL reconnection",
    "text": "QSL reconnection\n\nQSLs are preferential sites for electric current build-up and magnetic reconnection.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZhao et al. (2016), Yang et al. (2020), Pariat (2020), Cheng et al. (2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#qsl-reconnection-1",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#qsl-reconnection-1",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "QSL reconnection",
    "text": "QSL reconnection\n\nQSLs have been associated with flare ribbons in a large number of events.\n\n\n\n\n\n\n\n\n\nZhao et al. (2016), Yang et al. (2020), Pariat (2020), Cheng et al. (2023)"
  },
  {
    "objectID": "posts/solar_eruptions_magnetic_fields/index.html#fastqsl-zhang2022",
    "href": "posts/solar_eruptions_magnetic_fields/index.html#fastqsl-zhang2022",
    "title": "Solar Eruptions & Magnetic Fields",
    "section": "FastQSL (Zhang et al. 2022)",
    "text": "FastQSL (Zhang et al. 2022)\n\n\n\n\n\n\n\n\nComputation time : 107s for 900 x 540 x 360 grid data"
  },
  {
    "objectID": "posts/sharps_01/index.html",
    "href": "posts/sharps_01/index.html",
    "title": "SHARP Data Guide (1)",
    "section": "",
    "text": "import warnings; warnings.filterwarnings(\"ignore\")\nThe Solar Dynamics Observatory (SDO, Pesnell et al. 2012) / Helioseismic and Magnetic Imager (HMI, Schou et al. 2012) have produced a wealth of data for the Sun, particularly the magnetic field on the solar surface (photosphere). The Space-Weather HMI Active Region Patches (SHARPs, Bobra et al. 2014) are a set of data products derived from the HMI data, which have been used extensively in solar physics and space weather research. The information for the SHARP data is available on this JSOC page.\nThis post focuses on how to download the SHARP CEA data from the JSOC."
  },
  {
    "objectID": "posts/sharps_01/index.html#sharp-data-product-on-jsoc",
    "href": "posts/sharps_01/index.html#sharp-data-product-on-jsoc",
    "title": "SHARP Data Guide (1)",
    "section": "SHARP Data Product on JSOC",
    "text": "SHARP Data Product on JSOC\nAll SDO data are available from the Standford Joint Science Operations Center (JSOC), which employs the Data Record Management System (DRMS) to manage the data. The data can be accessed through Python using the SunPyâ€™s drms package.\nWe can establish a connection to the JSOC by creating a drms.Client instance.\n\nimport drms\nc = drms.Client()\n\n\nFor each dataseries, there are several records identified by one or more prime keywords.\nFor each record, there are several keywords that describe the data and segments that contains actual data.\nUsers can export the record as a FITS file whose header contains keywords and data array contains segments.\n\n\n\n\nJSOC Dataseries Name\nDescription\n\n\n\n\nhmi.sharp_*\nSHARP data products\n\n\n\n\nc.series('hmi.sharp_')\n\n['hmi.sharp_720s',\n 'hmi.sharp_720s_dconS',\n 'hmi.sharp_720s_nrt',\n 'hmi.sharp_cea_720s',\n 'hmi.sharp_cea_720s_dconS',\n 'hmi.sharp_cea_720s_nrt']\n\n\nHere, _nrt indicates the near-real-time (NRT) data series with preliminary calibration, whereas the absence of _nrt indicates the definitive data series.\nAlso, _720s indicates that the data series are obtained with a 720s (12m) cadence."
  },
  {
    "objectID": "posts/sharps_01/index.html#sharp-vs-sharp-cea",
    "href": "posts/sharps_01/index.html#sharp-vs-sharp-cea",
    "title": "SHARP Data Guide (1)",
    "section": "SHARP vs SHARP CEA",
    "text": "SHARP vs SHARP CEA\n\nThe SHARP data series hmi.sharp_720s are definitive data with 31 segments in Charge-Coupled Device (CCD) coordinate system. (a direct cutout from the full-disk image)\nThe SHARP CEA data seires hmi.sharp_cea_720s are definitive data with 11 segments in Cylindrical Equal-Area (CEA) coordinate system centered on the patch.\n\n\nimport pandas as pd \npd.set_option('display.max_colwidth', None)  # Remove the limit on column string length\n\n\nsharp = c.info('hmi.sharp_720s')\n\n\nsharp.segments\n\n\n\n\n\n\n\n\ntype\nunits\nprotocol\ndims\nnote\n\n\nname\n\n\n\n\n\n\n\n\n\nmagnetogram\nint\nGauss\nfits\nVARxVAR\nmagnetogram\n\n\nbitmap\nchar\nEnumerated\nfits\nVARxVAR\nMask for the patch\n\n\nDopplergram\nint\nm/s\nfits\nVARxVAR\nDopplergram\n\n\ncontinuum\nint\nDN/s\nfits\nVARxVAR\ncontinuum intensity\n\n\ninclination\nint\ndeg\nfits\nVARxVAR\nInclination\n\n\nazimuth\nint\ndeg\nfits\nVARxVAR\nAzimuth\n\n\nfield\nint\ngauss\nfits\nVARxVAR\nField Strength\n\n\nvlos_mag\nint\ncm/s\nfits\nVARxVAR\nLOS Velocity with Field\n\n\ndop_width\nint\nmA\nfits\nVARxVAR\nDoppler Width\n\n\neta_0\nint\nadimensional\nfits\nVARxVAR\nEta_0\n\n\ndamping\nint\nDoppler width units\nfits\nVARxVAR\nDamping\n\n\nsrc_continuum\nint\ndata units\nfits\nVARxVAR\nContinuum\n\n\nsrc_grad\nint\ndata units\nfits\nVARxVAR\nGradient\n\n\nalpha_mag\nint\nadimensional\nfits\nVARxVAR\nFilling Factor with Field\n\n\nchisq\nint\n\nfits\nVARxVAR\nChisq\n\n\nconv_flag\nchar\n\nfits\nVARxVAR\nflag and index of ME-inversion convergence process\n\n\ninfo_map\nint\n\nfits\nVARxVAR\nupdated quality map\n\n\nconfid_map\nchar\n\nfits\nVARxVAR\nupdated confidence index\n\n\ninclination_err\nint\ndeg\nfits\nVARxVAR\nstd of Inclination_Err\n\n\nazimuth_err\nint\ndeg\nfits\nVARxVAR\nstd of Azimuth_Err\n\n\nfield_err\nint\ngauss\nfits\nVARxVAR\nstd of Field_Err\n\n\nvlos_err\nint\ncm/s\nfits\nVARxVAR\nstd of VLos_Err\n\n\nalpha_err\nint\nadimensional\nfits\nVARxVAR\nstd of Alpha_Err\n\n\nfield_inclination_err\nint\n\nfits\nVARxVAR\ncor.coef of Field_Inclination_Err\n\n\nfield_az_err\nint\n\nfits\nVARxVAR\ncor.coef of Field_azimuth_Err\n\n\ninclin_azimuth_err\nint\n\nfits\nVARxVAR\ncor.coef of Inclination_Azimuth_Err\n\n\nfield_alpha_err\nint\n\nfits\nVARxVAR\ncor.coef of Field_Alpha_Err\n\n\ninclination_alpha_err\nint\n\nfits\nVARxVAR\ncor.coef of Inclination_Alpha_Err\n\n\nazimuth_alpha_err\nint\n\nfits\nVARxVAR\ncor.coef of Azimuth_Alpha_Err\n\n\ndisambig\nchar\nnone\nfits\nVARxVAR\nFlag for 180 degree change in azimuth\n\n\nconf_disambig\nchar\nnone\nfits\nVARxVAR\nConfidence of disambiguation result\n\n\n\n\n\n\n\n\nsharp_cea = c.info('hmi.sharp_cea_720s')\n\n\nsharp_cea.segments\n\n\n\n\n\n\n\n\ntype\nunits\nprotocol\ndims\nnote\n\n\nname\n\n\n\n\n\n\n\n\n\nmagnetogram\nint\nGauss\nfits\nVARxVAR\nLine-of-sight magnetogram in CEA projection\n\n\nbitmap\nchar\nEnumerated\nfits\nVARxVAR\nMask for the patch in CEA coordinates\n\n\nDopplergram\nint\nm/s\nfits\nVARxVAR\nDopplergram in CEA projection\n\n\ncontinuum\nint\nDN/s\nfits\nVARxVAR\nIntensitygram in CEA projection\n\n\nBp\nint\nGauss\nfits\nVARxVAR\nB_phi, positive westward\n\n\nBt\nint\nGauss\nfits\nVARxVAR\nB_theta, positive southward\n\n\nBr\nint\nGauss\nfits\nVARxVAR\nB_r, positive up\n\n\nBp_err\nint\nGauss\nfits\nVARxVAR\nStandard deviation of B_phi\n\n\nBt_err\nint\nGauss\nfits\nVARxVAR\nStandard deviation of B_theta\n\n\nBr_err\nint\nGauss\nfits\nVARxVAR\nStandard deviation of B_r\n\n\nconf_disambig\nchar\nnone\nfits\nVARxVAR\nconfidence of disambiguation result"
  },
  {
    "objectID": "posts/sharps_01/index.html#noaa-ar-to-harp-matching",
    "href": "posts/sharps_01/index.html#noaa-ar-to-harp-matching",
    "title": "SHARP Data Guide (1)",
    "section": "NOAA AR to HARP Matching",
    "text": "NOAA AR to HARP Matching\nA record of the SHARP data series is identified by two prime keywords: HARPNUM (HARP number) and T_REC (observation time). Since HARP is identified independently from the National Oceanic and Atmospheric Administration (NOAA), the HARP number is different from NOAA active region (AR) number. Even one HARP can correspond to zero, one, or more NOAA ARs. There is a file for mapping between HARP numbers and NOAA AR numbers here.\nAlso, the SHARP keywords include those for NOAA AR numbers, which start with NOAA_.\n\nsharp.keywords[sharp.keywords.index.str.startswith('NOAA_')]\n\n\n\n\n\n\n\n\ntype\nrecscope\ndefval\nunits\nnote\nlinkinfo\nis_time\nis_integer\nis_real\nis_numeric\n\n\nname\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNOAA_AR\nint\nvariable\n-2147483648\nnone\nNOAA AR number that best matches this HARP\nNone\nFalse\nTrue\nFalse\nTrue\n\n\nNOAA_NUM\nint\nvariable\n-2147483648\nnone\nNumber of NOAA ARs that match this HARP (0 allowed)\nNone\nFalse\nTrue\nFalse\nTrue\n\n\nNOAA_ARS\nstring\nvariable\n\nnone\nComma-separated list of NOAA ARs matching this HARP\nNone\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\nAs an example, letâ€™s find the HARP number corresponding to the NOAA AR number 12673 which produced the largest solar flare in solar cycle 24.\nTo do this, we need to query keywords HARPNUM and NOAA_AR using the drms.Client.query method. The key argument specifies which keywords to query. We need to use two primary keys: the HARP number (blank in this case) and the time range (2017-09-04T00:00:00 in this case).\n\nresults = c.query('hmi.sharp_720s[][2017-09-04T00:00:00]', key=['HARPNUM', 'NOAA_AR', 'NOAA_ARS', 'NOAA_NUM'])\n\n\nresults\n\n\n\n\n\n\n\n\nHARPNUM\nNOAA_AR\nNOAA_ARS\nNOAA_NUM\n\n\n\n\n0\n7115\n12673\n12673\n1\n\n\n1\n7117\n12674\n12674,12679\n2\n\n\n2\n7118\n0\nMISSING\n0\n\n\n3\n7120\n12675\n12675\n1\n\n\n4\n7121\n0\nMISSING\n0\n\n\n5\n7122\n12677\n12677\n1\n\n\n6\n7123\n12675\n12675,12676\n2\n\n\n\n\n\n\n\nAs you can see, the HARP number for the NOAA AR 12673 is 7115.\nThere are summary images for HARP data here. The following image is the summary image for the HARPs on 2017-09-04T00:00:00.\n\nfrom IPython.display import Image\n\nImage('http://jsoc.stanford.edu/doc/data/hmi/harp/harp_definitive/2017/09/04/harp.2017.09.04_00:00:00_TAI.png')\n\n\n\n\n\n\n\n\nAt this time, the AR 12673 (HARP 7115) is located near the center of the solar disk, with a slight southward shift."
  },
  {
    "objectID": "posts/sharps_01/index.html#sharp-cea-data",
    "href": "posts/sharps_01/index.html#sharp-cea-data",
    "title": "SHARP Data Guide (1)",
    "section": "SHARP CEA Data",
    "text": "SHARP CEA Data\nLetâ€™s now download the SHARP CEA data for the HARP 7115 (NOAA AR 12673) on 2017-09-04T00:00:00.\nThere are basically two ways to download data from the JSOC:\n\nDownload merged FITS files (export), which requires an email address registered here.\nDownload segments (data) and keywords (metadata) separately and merge them as FITS files if needed.\n\n\n# Construct query\nquery = 'hmi.sharp_cea_720s[7115][2017-09-04T00:00:00]'\n\n\n1. Download merged FITS files\n\nfrom pathlib import Path\nsharp_cea_path = Path('./data/export/sharp_cea')\nsharp_cea_path.mkdir(parents=True, exist_ok=True)\n\n\nemail = ''  # A registered email address\nc = drms.Client(email=email)\nr = c.export(query, protocol='fits')\nr.wait()\nif r.status == 0:\n    r.download(sharp_cea_path)\n\nSince this is the SHARP CEA data, there are 11 files (segments) in total.\n\nsharp_cea_list = sorted(sharp_cea_path.glob('*.fits'))\nprint(len(sharp_cea_list))\nfor file in sharp_cea_list:\n    print(file.name)\n\n11\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.bitmap.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.Bp.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.Bp_err.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.Br.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.Br_err.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.Bt.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.Bt_err.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.conf_disambig.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.continuum.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.Dopplergram.fits\nhmi.sharp_cea_720s.7115.20170904_000000_TAI.magnetogram.fits\n\n\nUsing sunpy.map.Map, we can easily read the SHARP CEA data and visualize it. Letâ€™s see the Br component of the magnetic field.\n\nfrom sunpy.map import Map\n\nsharp_cea_br = Map(sharp_cea_path / 'hmi.sharp_cea_720s.7115.20170904_000000_TAI.Br.fits')\nsharp_cea_br.peek()\n\n\n\n\n\n\n\n\nThe below shows the FITS header of this file.\n\nsharp_cea_br.fits_header\n\nSIMPLE  =                    T / file does conform to FITS standard             \nBITPIX  =                   32 / data type of original image                    \nNAXIS   =                    2 / dimension of original image                    \nNAXIS1  =                  688 / length of original image axis                  \nNAXIS2  =                  448 / length of original image axis                  \nBLANK   =          -2147483648                                                  \nBZERO   =                  0.0                                                  \nBSCALE  =                 0.01                                                  \nCHECKSUM= 'ZoJAflG8ZlGAflG5'   / HDU checksum updated 2025-08-01T11:36:33       \nDATASUM = '2018488944'         / data unit checksum updated 2017-10-09T03:05:15 \nDATE    = '2017-10-09T03:04:53.000' / [ISO] HDU creation date                   \nDATE_S  = '2017-09-08T17:19:08.000' / [ISO] Date_time of generating Stokes data \nDATE_B  = '2017-09-10T08:49:19.000' / [ISO] Date_time of generating Bharp data  \nDATE-OBS= '2017-09-03T23:58:42.200' / [ISO] Observation date {DATE__OBS}        \nT_OBS   = '2017.09.04_00:00:04.203_TAI' / [TAI] nominal time                    \nT_REC   = '2017.09.04_00:00:00.000_TAI' / [TAI] Slot time                       \nTRECEPOC= '1993.01.01_00:00:00.000_TAI' / [TAI] Time of origin {T_REC_epoch}    \nTRECSTEP=                720.0 / [seconds] ts_eq step {T_REC_step}              \nTRECUNIT= 'secs    '           / ts_eq unit {T_REC_unit}                        \nCADENCE =                720.0 / [seconds] repetition interval                  \nUSFLUX  =       2.33095666E+22 / [Maxwell] Total unsigned flux                  \nMEANGAM =           60.9712143 / [Degrees] Mean inclination angle, gamma        \nMEANGBT =           108.533112 / [Gauss/Mm] Mean value of the total field gradie\nMEANGBZ =           122.083214 / [Gauss/Mm] Mean value of the vertical field gra\nMEANGBH =           81.9712906 / [Gauss/Mm] Mean value of the horizontal field g\nMEANJZD =         -0.176174253 / [mA/(m^2)] Mean vertical current density       \nTOTUSJZ =     56044520700000.0 / [Amperes] Total unsigned vertical current      \nMEANALP =        -0.0666425973 / [1/Mm] Mean twist parameter, alpha             \nMEANJZH =        -0.0351469964 / [(G^2)/m] Mean current helicity                \nTOTUSJH =           3211.80591 / [(G^2)/m] Total unsigned current helicity      \nABSNJZH =           1280.44019 / [(G^2)/m] Absolute value of the net current hel\nSAVNCPP =     53733652200000.0 / [Amperes] Sum of the Absolute Value of the Net \nMEANPOT =           17168.6914 / [Ergs per cubic centimeter] Mean photospheric e\nTOTPOT  =       8.30700913E+23 / [Ergs per cubic centimeter] Total photospheric \nMEANSHR =           51.6004753 / [Degrees] Mean shear angle for B_total         \nSHRGT45 =           57.4177246 / [Percentage of Total] Area with shear angle gre\nR_VALUE =           4.91179323 / [Maxwell] Unsigned Flux R (Schrijver, 2007)    \nGWILL   =  / [Mm] (MISSING) GWILL (Mason & Hoeksema, 2010)                      \nCTYPE1  = 'CRLN-CEA'           / CRLN                                           \nCTYPE2  = 'CRLT-CEA'           / CRLT                                           \nCRPIX1  =                344.5 / [pixel] X coordinate of patch center with respe\nCRPIX2  =                224.5 / [pixel] Y coordinate of patch center with respe\nCRVAL1  =           118.228928 / [degree] Longitude at center of patch          \nCRVAL2  =          -9.24354935 / [degree] Latitude at center of patch           \nCDELT1  =         0.0299999993 / [degree] Map scale in X direction              \nCDELT2  =         0.0299999993 / [degree] Map scale in Y direction              \nCUNIT1  = 'degree  '           / Degree                                         \nCUNIT2  = 'degree  '           / Degree                                         \nIMCRPIX1=           2040.19434 / [pixel] Location of the Sun center in CCD x dir\nIMCRPIX2=           2050.66919 / [pixel] Location of the Sun center in CCD y dir\nIMCRVAL1=                  0.0 / [arcsec] x origin                              \nIMCRVAL2=                  0.0 / [arcsec] y origin                              \nCROTA2  =                  0.0 / [deg] CROTA2: INST_ROT + SAT_ROT               \nCRDER1  =                  0.0 / [arcsec] CRDER1: estimate of random error in co\nCRDER2  =                  0.0 / [arcsec] CRDER2: estimate of random error in co\nCSYSER1 =  / [arcsec] (MISSING) CSYSER1: estimate of systema                    \nCSYSER2 =  / [arcsec] (MISSING) CSYSER2: estimate of systema                    \nWCSNAME = 'Carrington Heliographic' / WCS system name                           \nDSUN_OBS=   150858023996.63818 / [meters] Distance from SDO to Sun center.      \nDSUN_REF=       149597870691.0 / [meters] Astronomical Unit                     \nRSUN_REF=          696000000.0 / [m] Reference radius of the Sun: 696,000,000.0 \nCRLN_OBS=           115.300667 / [deg] Carrington longitude of the observer     \nCRLT_OBS=           7.24144268 / [deg] Carrington latitude of the observer      \nCAR_ROT =                 2194 / Carrington rotation number of CRLN_OBS         \nOBS_VR  =    2555.889497463884 / [m/s] velocity of the observer in radial direct\nOBS_VW  =   28877.653628739867 / [m/s] velocity of the observer solar           \nOBS_VN  =    611.9685861024672 / [m/s] velocity of the observer solar           \nRSUN_OBS=     951.628662109375 / [arcsec] angular radius of Sun. Corresponds to \nTELESCOP= 'SDO/HMI '           / Telescope                                      \nINSTRUME= 'HMI_COMBINED'       / For HMI: HMI_SIDE1, HMI_FRONT2, or HMI_COMBINED\nWAVELNTH=               6173.0 / [angstrom] Wavelength                          \nCAMERA  =                    3 / Camera                                         \nQUALITY =                    0 / SHARP Quality index                            \nQUAL_S  =                    0 / Level 1p Quality word                          \nQUALLEV1=                    0 / Level 1 quality                                \nBUNIT   = 'Mx/cm^2 '           / Physical Units {BUNIT_006}                     \nORIGIN  = 'SDO/JSOC-SDP'       / Origin                                         \nCONTENT = 'HMI observable'     / Content                                        \nBLD_VERS= 'V9R1X   '           / JSOC                                           \nCALVER64=               204818 / Calibration Version                            \nCODEVER7= '$Id: sharp.c,v 1.38 2015/03/18 00:28:26 xudong Exp $ $Id' / CVS Versi\nHFLID   =                 1022 / HMI_SEQ_ID_FRAMELIST                           \nHCFTID  =                   11 / HMI_SEQ_ID_FOCUS                               \nQLOOK   =                    0 / QLOOK: 0=final data, 1=quick                   \nHARPNUM =                 7115 / HARP ID                                        \nMASK    =                   32 / Lower threshold for membership in this patch   \nARM_QUAL=                    0 / Quality of the mask (bitfield)                 \nARM_NCLN=                    0 / Number of limb pixels reset to quiet (annulus w\nH_MERGE =                    0 / 1 if this HARP merged with an existing region a\nH_FAINT =                    0 / 1 if this HARP had faint contrast at this time \nARM_MODL= '/builtin/hmi.M_Ic_noLimbDark_720s.production' / ARmask parameter: Cla\nARM_EDGE=                  2.5 / ARmask parameter: Width of annulus at limb to p\nARM_BETA= '0.3     '           / ARmask parameter: Mask spatial smoothness      \nLATDTMIN=          -15.9709997 / [degree] Minimum latitude for disk transit     \nLONDTMIN=           -7.3888998 / [degree] Minimum longitude for disk transit    \nLATDTMAX=          -2.51609993 / [degree] Maximum latitude for disk transit     \nLONDTMAX=           13.2454004 / [degree] Maximum longitude for disk transit    \nOMEGA_DT=           13.5587997 / [degree/day] Rotation rate over disk transit   \nNPIX    =               104669 / Number of pixels within the patch              \nSIZE    =           9358.12109 / [mH] Projected area of patch on image in micro \nAREA    =           4898.90918 / [mH] De                                        \nNACR    =                20091 / Number of active pixels in patch               \nSIZE_ACR=           1796.27209 / [mH] Projected area of active pixels on image i\nAREA_ACR=           938.419678 / [mH] De                                        \nMTOT    =           14614653.0 / [weber] Sum of absolute LoS flux within the ide\nMNET    =           2694764.75 / [weber] Net LoS flux within the identified regi\nMPOS_TOT=            8654709.0 / [weber] Absolute value of total positive LoS fl\nMNEG_TOT=            5959944.0 / [weber] Absolute value of total negative LoS fl\nMMEAN   =           25.7455864 / [gauss] Mean of LoS flux density               \nMSTDEV  =           317.047974 / [gauss] Standard deviation of LoS flux density \nMSKEW   =           1.03884447 / Skewness of LoS flux density                   \nMKURT   =           8.83417225 / Kurtosis of LoS flux density                   \nLAT_MIN =           -15.703517 / [degree] Minimum Stonyhurst latitude of pixels \nLON_MIN =          -6.76720762 / [degree] Minimum Stonyhurst longitude of pixels\nLAT_MAX =          -3.89583516 / [degree] Maximum Stonyhurst latitude of pixels \nLON_MAX =           7.71703625 / [degree] Maximum Stonyhurst longitude of pixels\nLAT_FWT =          -9.06213856 / [degree] Stonyhurst latitude of flux           \nLON_FWT =           2.20005369 / [degree] Stonyhurst longitude of flux          \nLATFWTPO=          -9.32380581 / [degree] Stonyhurst latitude of flux {LAT_FWTPO\nLONFWTPO=           2.86910152 / [degree] Stonyhurst longitude of flux {LON_FWTP\nLATFWTNE=          -8.63728142 / [degree] Stonyhurst latitude of flux {LAT_FWTNE\nLONFWTNE=           1.11375129 / [degree] Stonyhurst longitude of flux {LON_FWTN\nT_FRST  = '2017.08.27_10:00:00.000_TAI' / [TAI] First T_REC stored for HARP (inc\nT_FRST1 = '2017.08.28_08:12:00.000_TAI' / [TAI] T_REC of initial HARP detection \nT_LAST1 = '2017.09.10_11:12:00.000_TAI' / [TAI] T_REC of final HARP detection   \nT_LAST  = '2017.09.11_03:48:00.000_TAI' / [TAI] Last T_REC stored for HARP (incl\nN_PATCH =                 1676 / Image slots spanned by HARP (includes pad)     \nN_PATCH1=                 1491 / Image slots spanned by HARP (excludes pad)     \nN_PATCHM=                   85 / Missing images/slots in unpadded HARP interval \nNOAA_AR =                12673 / NOAA AR number that best matches this HARP     \nNOAA_NUM=                    1 / Number of NOAA ARs that match this HARP (0 allo\nNOAA_ARS= '12673   '           / Comma                                          \nINVCODEV= 'vfisvcombine FD10 2013 Apr. 30; uses time-dependent HMI filter &'    \nCONTINUE  'phase maps&'                                                         \nCONTINUE  '' / Version of VFISV code                                            \nINVDOCU =  / (MISSING) Document for VFISV code                                  \nINVITERA=                  200 / Number of iterations of VFISV                  \nINVSTLGT= 'No      '           / Flag for stray light. No means that the stray l\nINVFLPRF= '' / Flag/Comment on filter                                           \nINVPHMAP= '121048472'          / Flag/Comment on phase map                      \nUSFLUXL = 2.04952041124192E+22 / [Maxwell] Total unsigned flux {INVVLAVE}       \nMEANGBL =    39.11368179321289 / [Gauss/Mm] Mean value of the line {INVBLAVE}   \nINVBBAVE=   121.28715632506182 / [gauss] avarage of inverted field strength over\nCMASKL  =               111256 / [number] Number of pixels that contributed to t\nINVNCNVG=             11184843 / Numer of pixels at which ME VFISV converged    \nAMBCODEV= 'disambig_v3 2013 Dec 06' / Version of Disambig code                  \nAMBDOCU =  / (MISSING) Document for Disambig code                               \nAMBGMTRY=                    2 / Flag determining whether to use planar or spher\nAMBPATCH=                    0 / Flag determining whether disambiguation is done\nAMBWEAK =                    2 / Flag determining method for disambiguating weak\nAMBNEROD=                    1 / [pixels] Number of pixels by which to erode map\nAMBNGROW=                    5 / [pixels] Number of pixels by which to grow erod\nAMBNPAD =                  200 / [pixels] Padding to use in potential field calc\nAMBNAP  =                   10 / [pixels] Width of apodizing window in potential\nAMBNTX  =                   30 / Number of tiles to use in x                    \nAMBNTY  =                   30 / Number of tiles to use in y                    \nAMBBTHR0=                200.0 / [G] Transverse field strength threshold at disk\nAMBBTHR1=                400.0 / [G] Transverse field strength threshold at limb\nAMBSEED =                    4 / Input random number seed                       \nAMBNEQ  =                  100 / Number of reconfigurations attempted at each te\nAMBLMBDA=                  1.0 / Weighting factor between divergence and vertica\nAMBTFCT0=                  2.0 / Input factor to scale initial temperature      \nAMBTFCTR=   0.9800000190734863 / Input factor to reduce temperature             \nDATAVALS=               308224 / Data values {DATAVALS_006}                     \nMISSVALS=                    0 / Missing values {MISSVALS_006}                  \nDATAMIN =          -2184.78003 / Minimum value {DATAMIN_006}                    \nDATAMAX =           2745.38989 / Maximum value {DATAMAX_006}                    \nDATAMEDN=           -3.6447506 / Median value {DATAMEDN_006}                    \nDATAMEAN=           4.10086536 / Mean value from pixels within 99% of solar radi\nDATARMS =           254.120453 / RMS {DATARMS_006}                              \nERRGAM  =         0.0170187168 / [Degrees] Error in Mean inclination angle, gamm\nERRTAI  =           20.9685936 / [(G^2)/m] Absolute value of the net current hel\nERRBH   =          0.166585341 / [Gauss/Mm] Error in Mean value of the horizonta\nERRMPOT =           10.9116526 / [Ergs per cubic centimeter] Error in Mean photo\nERRBT   =          0.140896067 / [Gauss/Mm] Error in Mean value of the total fie\nERRTUI  =           20.9685936 / [(G^2)/m] Total unsigned current helicity      \nERRBZ   =          0.103350542 / [Gauss/Mm] Error in Mean value of the vertical \nCMASK   =              36433.0 / [number] Number of pixels that contributed to t\nERRJZ   =         0.0505617075 / [mA/(m^2)] Error in Mean vertical current densi\nERRVF   =        7.0435523E+18 / [Maxwell] Error in Total unsigned flux         \nERRALP  =         0.0010908118 / [1/Mm] Error in Mean twist parameter, alpha    \nERRMIH  =       0.000575570099 / [(G^2)/m] Mean current helicity                \nERRMSHA =       0.000446339604 / [Degrees] Error in Mean shear angle for B_total\nERRUSI  =       244641006000.0 / [Amperes] Error in Total unsigned vertical curr\nDOFFSET =                   50 / [Gauss] Constant value added to the noise mask \nERRTPOT =       5.27956351E+20 / [Ergs per cubic centimeter] Error in Total phot\nERRJHT  =       985371771000.0 / [Amperes] Sum of the Absolute Value of the Net \nRECNUM  =              6009474 / Recnum                                         \nDRMS_ID = 'hmi.sharp_cea_720s:6009474:Br' / DRMS ID                             \nPRIMARYK= 'HARPNUM, T_REC'     / DRMS primary key                               \nLICENSE = 'LICENSE '           / CC0 1.0                                        \nHEADSUM = 'ZAjnaAhkTAhkZAhk'   / Keyword checksum                               \nLONGSTRN= 'OGIP 1.0'           / The HEASARC Long String Convention may be used.\nWAVEUNIT= 'angstrom'                                                            \nCOMMENT FITS (Flexible Image Transport System) format is defined in 'Astronomy  \nCOMMENT   and Astrophysics', volume 376, page 359; bibcode: 2001A&A...376..359H \nCOMMENT   This FITS file may contain long string keyword values that are        \nCOMMENT   continued over multiple keywords.  The HEASARC convention uses the &  \nCOMMENT   character at the end of each substring which is then continued        \nCOMMENT   on the next keyword which has the name CONTINUE.                      \nHISTORY                                                                         \n\n\n\n\n2. Download segments and keywords separately\n\nc = drms.Client()  # No email address needed\n\nAll keywords associated with the query can be obtained using drms.JsocInfoConstants.all.\n\nkeywords = c.query(query, key=drms.JsocInfoConstants.all)\nkeywords\n\n\n\n\n\n\n\n\nDATE\nDATE_S\nDATE_B\nDATE__OBS\nDATE-OBS\nT_OBS\nT_REC\nT_REC_epoch\nT_REC_step\nT_REC_unit\n...\nCMASK\nERRJZ\nERRVF\nERRALP\nERRMIH\nERRMSHA\nERRUSI\nDOFFSET\nERRTPOT\nERRJHT\n\n\n\n\n0\n2017-10-09T03:04:53Z\n2017-09-08T17:19:08Z\n2017-09-10T08:49:19Z\n2017-09-03T23:58:42.20Z\n2017-09-03T23:58:42.20Z\n2017.09.04_00:00:04_TAI\n2017.09.04_00:00:00_TAI\n1993.01.01_00:00:00_TAI\n720.0\nsecs\n...\n36433.0\n0.050562\n7.043552e+18\n0.001091\n0.000576\n0.0\n2.446410e+11\n50\n5.279564e+20\n9.853718e+11\n\n\n\n\n1 rows Ã— 261 columns\n\n\n\nWe can get a list of names of segments using drms.Client.info and then query the keywords and segments using drms.Client.query.\n\nsharp_cea = c.info('hmi.sharp_cea_720s')\nsharp_cea_segments = sorted(sharp_cea.segments.index)\nprint(sharp_cea_segments)\n\n['Bp', 'Bp_err', 'Br', 'Br_err', 'Bt', 'Bt_err', 'Dopplergram', 'bitmap', 'conf_disambig', 'continuum', 'magnetogram']\n\n\n\nkeywords, segments = c.query(query, key=drms.JsocInfoConstants.all, seg=sharp_cea_segments)\n\n\nkeywords\n\n\n\n\n\n\n\n\nDATE\nDATE_S\nDATE_B\nDATE__OBS\nDATE-OBS\nT_OBS\nT_REC\nT_REC_epoch\nT_REC_step\nT_REC_unit\n...\nCMASK\nERRJZ\nERRVF\nERRALP\nERRMIH\nERRMSHA\nERRUSI\nDOFFSET\nERRTPOT\nERRJHT\n\n\n\n\n0\n2017-10-09T03:04:53Z\n2017-09-08T17:19:08Z\n2017-09-10T08:49:19Z\n2017-09-03T23:58:42.20Z\n2017-09-03T23:58:42.20Z\n2017.09.04_00:00:04_TAI\n2017.09.04_00:00:00_TAI\n1993.01.01_00:00:00_TAI\n720.0\nsecs\n...\n36433.0\n0.050562\n7.043552e+18\n0.001091\n0.000576\n0.0\n2.446410e+11\n50\n5.279564e+20\n9.853718e+11\n\n\n\n\n1 rows Ã— 261 columns\n\n\n\n\nsegments\n\n\n\n\n\n\n\n\nBp\nBp_err\nBr\nBr_err\nBt\nBt_err\nDopplergram\nbitmap\nconf_disambig\ncontinuum\nmagnetogram\n\n\n\n\n0\n/SUM98/D978177825/S00000/Bp.fits\n/SUM98/D978177825/S00000/Bp_err.fits\n/SUM98/D978177825/S00000/Br.fits\n/SUM98/D978177825/S00000/Br_err.fits\n/SUM98/D978177825/S00000/Bt.fits\n/SUM98/D978177825/S00000/Bt_err.fits\n/SUM98/D978177825/S00000/Dopplergram.fits\n/SUM98/D978177825/S00000/bitmap.fits\n/SUM98/D978177825/S00000/conf_disambig.fits\n/SUM98/D978177825/S00000/continuum.fits\n/SUM98/D978177825/S00000/magnetogram.fits\n\n\n\n\n\n\n\nUsing the url information for each segment, we can download each file.\n\nt_rec = keywords['T_REC'].item()\nt_rec\n\n'2017.09.04_00:00:00_TAI'\n\n\n\nsegment = segments['Br'].item()\nprint(segment)\n\n/SUM98/D978177825/S00000/Br.fits\n\n\n\nurl = 'http://jsoc.stanford.edu' + segment\nurl\n\n'http://jsoc.stanford.edu/SUM98/D978177825/S00000/Br.fits'\n\n\n\nfrom urllib.request import urlretrieve\nurlretrieve(url, 'Br.fits');\n\n\nfrom astropy.io import fits\nhdul = fits.open('Br.fits')\nhdul.info()\n\nFilename: Br.fits\nNo.    Name      Ver    Type      Cards   Dimensions   Format\n  0  PRIMARY       1 PrimaryHDU       6   ()      \n  1  COMPRESSED_IMAGE    1 CompImageHDU     10   (688, 448)   int32   \n\n\n\nhdul[1].header\n\nSIMPLE  =                    T / file does conform to FITS standard             \nBITPIX  =                   32 / data type of original image                    \nNAXIS   =                    2 / dimension of original image                    \nNAXIS1  =                  688 / length of original image axis                  \nNAXIS2  =                  448 / length of original image axis                  \nBLANK   =          -2147483648                                                  \nBZERO   =                   0.                                                  \nBSCALE  =                 0.01                                                  \nCHECKSUM= 'lBDPo99OlACOl99O'   / HDU checksum updated 2017-10-09T03:05:15       \nDATASUM = '2018488944'         / data unit checksum updated 2017-10-09T03:05:15 \n\n\nAs you can see, the header contains only basic information. However, the data is exactly the same as the one downloaded using the drms.Client.export method.\n\nimport numpy as np\nnp.allclose(hdul[1].data, sharp_cea_br.data)\n\nTrue\n\n\n\nhdul.close()\n\nWe can construct a header from the keywords. Note that there is no DATE-OBS in the keywords, instead DATE__OBS exists. The following note comes from the â€œ4.2.4 JSOC Image Timing Detailsâ€ section of the Guide to SDO Data Analysis.\n\nTECHNICAL NOTE: The JSOC keyword naming convention does not allow for hyphens, and consequently the DATE-OBS keyword is represented as DATE__OBS (with two underscores) within the JSOC. However, upon export to FITS files, this keyword gets converted to DATE-OBS so as to be compliant with the FITS standard. Additionally, note that the keyword DATE_OBS (with one underscore) that was more common during the SOHO era is not used by the JSOC.\n\nI refer to this code for the following code.\n\nfrom sunpy.util import MetaDict\nfrom sunpy.io._fits import header_to_fits\n\nheader = keywords.iloc[0].to_dict()\nheader['DATE_OBS'] = header['DATE__OBS']\nheader = header_to_fits(MetaDict(header))\n\nwith fits.open('Br.fits', 'update') as f:\n    hdr = f[1].header\n    for k, v in header.items():\n        if pd.isna(v):\n            continue\n        hdr[k] = v\n    f.verify('silentfix')\n\n\nsharp_cea_br_sep = Map('Br.fits')\nsharp_cea_br_sep.peek()\n\n\n\n\n\n\n\n\n\nsharp_cea_br_sep.fits_header\n\nSIMPLE  =                    T / file does conform to FITS standard             \nBITPIX  =                   32 / data type of original image                    \nNAXIS   =                    2 / dimension of original image                    \nNAXIS1  =                  688 / length of original image axis                  \nNAXIS2  =                  448 / length of original image axis                  \nBLANK   =          -2147483648                                                  \nBZERO   =                  0.0                                                  \nBSCALE  =                 0.01                                                  \nCHECKSUM= 'U0UHV0S9U0SEU0S9'   / HDU checksum updated 2025-08-01T22:17:03       \nDATASUM = '2018488944'         / data unit checksum updated 2025-08-01T22:17:03 \nDATE    = '2017-10-09T03:04:53Z'                                                \nDATE_S  = '2017-09-08T17:19:08Z'                                                \nDATE_B  = '2017-09-10T08:49:19Z'                                                \nDATE-OBS= '2017-09-03T23:58:42.20Z'                                             \nT_OBS   = '2017.09.04_00:00:04_TAI'                                             \nT_REC   = '2017.09.04_00:00:00_TAI'                                             \nCADENCE =                720.0                                                  \nUSFLUX  =         2.330957E+22                                                  \nMEANGAM =               60.971                                                  \nMEANGBT =              108.533                                                  \nMEANGBZ =              122.083                                                  \nMEANGBH =               81.971                                                  \nMEANJZD =          -0.17617425                                                  \nTOTUSJZ =     56044520000000.0                                                  \nMEANALP =           -0.0666426                                                  \nMEANJZH =            -0.035147                                                  \nTOTUSJH =             3211.806                                                  \nABSNJZH =              1280.44                                                  \nSAVNCPP =     53733650000000.0                                                  \nMEANPOT =             17168.69                                                  \nTOTPOT  =         8.307009E+23                                                  \nMEANSHR =                 51.6                                                  \nSHRGT45 =               57.418                                                  \nR_VALUE =                4.912                                                  \nCTYPE1  = 'CRLN-CEA'                                                            \nCTYPE2  = 'CRLT-CEA'                                                            \nCRPIX1  =                344.5                                                  \nCRPIX2  =                224.5                                                  \nCRVAL1  =           118.228928                                                  \nCRVAL2  =            -9.243549                                                  \nCDELT1  =                 0.03                                                  \nCDELT2  =                 0.03                                                  \nCUNIT1  = 'degree  '                                                            \nCUNIT2  = 'degree  '                                                            \nIMCRPIX1=          2040.194336                                                  \nIMCRPIX2=          2050.669189                                                  \nIMCRVAL1=                  0.0                                                  \nIMCRVAL2=                  0.0                                                  \nCROTA2  =                  0.0                                                  \nWCSNAME = 'Carrington Heliographic'                                             \nDSUN_OBS=      150858023996.64                                                  \nDSUN_REF=         149597870691                                                  \nRSUN_REF=            696000000                                                  \nCRLN_OBS=           115.300667                                                  \nCRLT_OBS=             7.241443                                                  \nCAR_ROT =                 2194                                                  \nOBS_VR  =          2555.889497                                                  \nOBS_VW  =         28877.653629                                                  \nOBS_VN  =           611.968586                                                  \nRSUN_OBS=           951.628662                                                  \nTELESCOP= 'SDO/HMI '                                                            \nINSTRUME= 'HMI_COMBINED'                                                        \nWAVELNTH=               6173.0                                                  \nCAMERA  =                    3                                                  \nQUALITY =                    0                                                  \nQUAL_S  =                    0                                                  \nQUALLEV1=                    0                                                  \nORIGIN  = 'SDO/JSOC-SDP'                                                        \nCONTENT = 'HMI observable'                                                      \nBLD_VERS= 'V9R1X   '                                                            \nCALVER64=               204818                                                  \nHFLID   =                 1022                                                  \nHCFTID  =                   11                                                  \nQLOOK   =                    0                                                  \nHARPNUM =                 7115                                                  \nMASK    =                   32                                                  \nARM_QUAL=                    0                                                  \nARM_NCLN=                    0                                                  \nH_MERGE =                    0                                                  \nH_FAINT =                    0                                                  \nARM_MODL= '/builtin/hmi.M_Ic_noLimbDark_720s.production'                        \nARM_EDGE=                  2.5                                                  \nARM_BETA= '0.3     '                                                            \nLATDTMIN=              -15.971                                                  \nLONDTMIN=              -7.3889                                                  \nLATDTMAX=              -2.5161                                                  \nLONDTMAX=              13.2454                                                  \nOMEGA_DT=              13.5588                                                  \nNPIX    =               104669                                                  \nSIZE    =          9358.121094                                                  \nAREA    =           4898.90918                                                  \nNACR    =                20091                                                  \nSIZE_ACR=          1796.272095                                                  \nAREA_ACR=           938.419678                                                  \nMTOT    =           14614653.0                                                  \nMNET    =           2694764.75                                                  \nMPOS_TOT=            8654709.0                                                  \nMNEG_TOT=            5959944.0                                                  \nMMEAN   =            25.745586                                                  \nMSTDEV  =           317.047974                                                  \nMSKEW   =             1.038844                                                  \nMKURT   =             8.834172                                                  \nLAT_MIN =           -15.703517                                                  \nLON_MIN =            -6.767208                                                  \nLAT_MAX =            -3.895835                                                  \nLON_MAX =             7.717036                                                  \nLAT_FWT =            -9.062139                                                  \nLON_FWT =             2.200054                                                  \nT_FRST  = '2017.08.27_10:00:00_TAI'                                             \nT_FRST1 = '2017.08.28_08:12:00_TAI'                                             \nT_LAST1 = '2017.09.10_11:12:00_TAI'                                             \nT_LAST  = '2017.09.11_03:48:00_TAI'                                             \nN_PATCH =                 1676                                                  \nN_PATCH1=                 1491                                                  \nN_PATCHM=                   85                                                  \nNOAA_AR =                12673                                                  \nNOAA_NUM=                    1                                                  \nNOAA_ARS= '12673   '                                                            \nINVCODEV= 'vfisvcombine FD10 2013 Apr. 30; uses time-dependent HMI filter &'    \nCONTINUE  'phase maps'                                                          \nINVDOCU = 'MISSING '                                                            \nINVITERA=                  200                                                  \nINVSTLGT= 'No      '                                                            \nINVFLPRF= ''                                                                    \nINVPHMAP= '121048472'                                                           \nINVVLAVE=          2.04952E+22                                                  \nUSFLUXL =          2.04952E+22                                                  \nINVBLAVE=               39.114                                                  \nMEANGBL =               39.114                                                  \nINVBBAVE=             121.2872                                                  \nINVNPRCS=               111256                                                  \nCMASKL  =               111256                                                  \nINVNCNVG=             11184843                                                  \nAMBCODEV= 'disambig_v3 2013 Dec 06'                                             \nAMBDOCU = 'MISSING '                                                            \nAMBGMTRY=                    2                                                  \nAMBPATCH=                    0                                                  \nAMBWEAK =                    2                                                  \nAMBNEROD=                    1                                                  \nAMBNGROW=                    5                                                  \nAMBNPAD =                  200                                                  \nAMBNAP  =                   10                                                  \nAMBNTX  =                   30                                                  \nAMBNTY  =                   30                                                  \nAMBBTHR0=                200.0                                                  \nAMBBTHR1=                400.0                                                  \nAMBSEED =                    4                                                  \nAMBNEQ  =                  100                                                  \nAMBLMBDA=                  1.0                                                  \nAMBTFCT0=                  2.0                                                  \nAMBTFCTR=                 0.98                                                  \nERRGAM  =                0.017                                                  \nERRTAI  =               20.969                                                  \nERRBH   =                0.167                                                  \nERRMPOT =             10.91165                                                  \nERRBT   =                0.141                                                  \nERRTUI  =               20.969                                                  \nERRBZ   =                0.103                                                  \nCMASK   =              36433.0                                                  \nERRJZ   =           0.05056171                                                  \nERRVF   =         7.043552E+18                                                  \nERRALP  =           0.00109081                                                  \nERRMIH  =           0.00057557                                                  \nERRMSHA =                  0.0                                                  \nERRUSI  =       244641000000.0                                                  \nDOFFSET =                   50                                                  \nERRTPOT =         5.279564E+20                                                  \nERRJHT  =       985371800000.0                                                  \nDATE_OBS= '2017-09-03T23:58:42.20Z'                                             \nHISTORY                                                                         \nCOMMENT                                                                         \n\n\nThe header is not exactly the same as the one downloaded using the drms.Client.export method, but it is basically the same as you can see."
  },
  {
    "objectID": "posts/pendulum/index.html",
    "href": "posts/pendulum/index.html",
    "title": "A collection of resources on pendulum",
    "section": "",
    "text": "This post contains a collection of resources on pendulum."
  },
  {
    "objectID": "posts/pendulum/index.html#contents",
    "href": "posts/pendulum/index.html#contents",
    "title": "A collection of resources on pendulum",
    "section": "Contents",
    "text": "Contents\n\nDescription\nExperiment\nSimulation\n\nC\nJavaScript\nProcessing\nJulia\nPython\n\nInverted Pendulum"
  },
  {
    "objectID": "posts/pendulum/index.html#c",
    "href": "posts/pendulum/index.html#c",
    "title": "A collection of resources on pendulum",
    "section": "C",
    "text": "C\nThe Double Pendulum\nMichael S. Wheatland\nWebsite\n2014-09-18"
  },
  {
    "objectID": "posts/pendulum/index.html#javascript",
    "href": "posts/pendulum/index.html#javascript",
    "title": "A collection of resources on pendulum",
    "section": "JavaScript",
    "text": "JavaScript\nDouble Pendulum\nmyPhysicsLab\nWebsite"
  },
  {
    "objectID": "posts/pendulum/index.html#processing",
    "href": "posts/pendulum/index.html#processing",
    "title": "A collection of resources on pendulum",
    "section": "Processing",
    "text": "Processing\nCoding Challenge 93: Double Pendulum\nThe Coding Train\nWebsite\n2018-02-14"
  },
  {
    "objectID": "posts/pendulum/index.html#julia",
    "href": "posts/pendulum/index.html#julia",
    "title": "A collection of resources on pendulum",
    "section": "Julia",
    "text": "Julia\nDouble Pendulum Problem\nPlots.jl\nWebsite\n[07x10] How to Solve the Double Pendulum Equations in Julia using DifferentialEquations.jl and Pluto\ndoggo dot jl\nYoutube\n2022-11-21"
  },
  {
    "objectID": "posts/pendulum/index.html#python",
    "href": "posts/pendulum/index.html#python",
    "title": "A collection of resources on pendulum",
    "section": "Python",
    "text": "Python\nThe double pendulum problem\nMatplotlib\nWebsite\nThe double pendulum\nChristian Hill\nWebsite\n2017-07-16\nThe Double-SPRINGED Pendulum in PYTHON\nMr.Â P Solver\nYoutube\n2021-04-06\nThe Double Pendulum in PYTHON\nMr.Â P Solver\nYoutube\n2021-09-07\nModeling a Double Pendulum with Python\nDot Physics\nYoutube\n2021-12-30\nHow to Cheat the Double Pendulum Using Springs Instead of Strings\nDot Physics\nYoutube\n2022-01-04\nHow To Solve and Animate a 3D Double Pendulum in Python\nMr.Â P Solver\nYoutube\n2022-04-04\nModeling the Double Pendulum with Python and sympy\nDot Physics\nYoutube\n2022-11-29\nDouble Pendulum Simulation in Python! || Simulating Physics with Python\nYounes Lab\nYoutube\n2024-01-04"
  },
  {
    "objectID": "posts/field-line-isee-nlfff/index.html",
    "href": "posts/field-line-isee-nlfff/index.html",
    "title": "Visualization of ISEE Nonlinear Force-Free Field of Solar Active Regions in Python",
    "section": "",
    "text": "The database contains the three-dimensional (3D) magnetic fields of solar active regions analyzed by Kusano et al.Â (2020). The 3D magnetic field are extrapolated by the magnetohydrodynamic relaxation method (Inoue et al., 2014) from the vector magnetic field data observed by the Solar Dynamics Observatory (SDO/HMI). In this database, Space weather HMI Active Region Patch data remapped to a Lambert Cylindrical Equal-Area projection (SHARP CEA) are used. For the detailed list and parameters of the sampled data, please refer to Kusano et al.Â (2020)."
  },
  {
    "objectID": "posts/field-line-isee-nlfff/index.html#isee-database-for-nonlinear-force-free-field-of-solar-active-regions",
    "href": "posts/field-line-isee-nlfff/index.html#isee-database-for-nonlinear-force-free-field-of-solar-active-regions",
    "title": "Visualization of ISEE Nonlinear Force-Free Field of Solar Active Regions in Python",
    "section": "",
    "text": "The database contains the three-dimensional (3D) magnetic fields of solar active regions analyzed by Kusano et al.Â (2020). The 3D magnetic field are extrapolated by the magnetohydrodynamic relaxation method (Inoue et al., 2014) from the vector magnetic field data observed by the Solar Dynamics Observatory (SDO/HMI). In this database, Space weather HMI Active Region Patch data remapped to a Lambert Cylindrical Equal-Area projection (SHARP CEA) are used. For the detailed list and parameters of the sampled data, please refer to Kusano et al.Â (2020)."
  },
  {
    "objectID": "posts/field-line-isee-nlfff/index.html#download-a-sample-data",
    "href": "posts/field-line-isee-nlfff/index.html#download-a-sample-data",
    "title": "Visualization of ISEE Nonlinear Force-Free Field of Solar Active Regions in Python",
    "section": "Download a sample data",
    "text": "Download a sample data\nI will use the 3D magnetic field data from NOAA active region 12673 at 2017-09-06 08:36:00. The data size is about 1.5 GB.\n\n# !wget https://hinode.isee.nagoya-u.ac.jp/nlfff_database/v12/12673/20170906/12673_20170906_083600.nc\n\n--2023-11-12 11:45:53--  https://hinode.isee.nagoya-u.ac.jp/nlfff_database/v12/12673/20170906/12673_20170906_083600.nc\nResolving hinode.isee.nagoya-u.ac.jp (hinode.isee.nagoya-u.ac.jp)... 133.47.151.53, 133.47.151.53\nConnecting to hinode.isee.nagoya-u.ac.jp (hinode.isee.nagoya-u.ac.jp)|133.47.151.53|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1626400312 (1.5G) [application/x-netcdf]\nSaving to: â€˜12673_20170906_083600.ncâ€™\n\n12673_20170906_0836 100%[===================&gt;]   1.51G  1.74MB/s    in 5m 11s  \n\n2023-11-12 11:51:04 (4.99 MB/s) - â€˜12673_20170906_083600.ncâ€™ saved [1626400312/1626400312]"
  },
  {
    "objectID": "posts/field-line-isee-nlfff/index.html#a-sample-python-script-load_nlfff.py",
    "href": "posts/field-line-isee-nlfff/index.html#a-sample-python-script-load_nlfff.py",
    "title": "Visualization of ISEE Nonlinear Force-Free Field of Solar Active Regions in Python",
    "section": "A sample Python script load_nlfff.py",
    "text": "A sample Python script load_nlfff.py\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport netCDF4\nimport sys\n\nclass nlfff:\n\n      def __init__(self,filename):\n            self.filename=filename\n\n            nc=netCDF4.Dataset(self.filename,'r')\n            self.NOAA=nc.NOAA\n            self.year_month_day_time=nc.year_month_day_time\n            self.project=nc.project\n            self.production_date=nc.production_date\n            self.version=nc.version\n            self.data_doi=nc.data_doi\n            self.http_link=nc.http_link\n            self.Distributor=nc.Distributor\n            \n            nc_x=nc.variables['x']\n            self.x=nc_x[:]\n            print(nc_x.long_name,' unit:',nc_x.units)\n            nc_y=nc.variables['y']\n            self.y=nc_y[:]\n            print(nc_y.long_name,' unit:',nc_y.units)\n            nc_z=nc.variables['z']\n            self.z=nc_z[:]\n            print(nc_z.long_name,' unit:',nc_z.units)\n            \n            nc_bx=nc.variables['Bx']\n            self.bx=nc_bx[:].transpose(2,1,0)\n            print(nc_bx.long_name,' unit:',nc_bx.units)\n            nc_by=nc.variables['By']\n            self.by=nc_by[:].transpose(2,1,0)\n            print(nc_by.long_name,' unit:',nc_by.units)\n            nc_bz=nc.variables['Bz']\n            self.bz=nc_bz[:].transpose(2,1,0)\n            print(nc_bz.long_name,' unit:',nc_bz.units)\n            \n            nc_bxp=nc.variables['Bx_pot']\n            self.bx_pot=nc_bxp[:].transpose(2,1,0)\n            print(nc_bxp.long_name,' unit:',nc_bxp.units)\n            nc_byp=nc.variables['By_pot']\n            self.by_pot=nc_byp[:].transpose(2,1,0)\n            print(nc_byp.long_name,' unit:',nc_byp.units)\n            nc_bzp=nc.variables['Bz_pot']\n            self.bz_pot=nc_bzp[:].transpose(2,1,0)\n            print(nc_bzp.long_name,' unit:',nc_bzp.units)\n            \n      def info(self):\n            print(f\"NOAA\",self.NOAA)\n            print(f'year_month_day_time',self.year_month_day_time)\n            print(f\"project\",self.project)\n            print(f\"production_date\",self.production_date)\n            print(f\"version\",self.version)\n            print(f\"data_doi\",self.data_doi)\n            print(f\"http_link\",self.http_link)\n            print(f\"Distributor\",self.Distributor)\n\n      def plot(self):\n            xs=12.0\n            ys=4.0\n\n            xmin=min(self.x)\n            xmax=max(self.x)\n            ymin=min(self.y)\n            ymax=max(self.y)\n\n            plt.close()\n            fig=plt.figure(figsize=(xs,ys))\n            ax1=fig.add_axes((0.08,0.35,0.25,0.25*xs/ys*(ymax-ymin)/(xmax-xmin)))\n            ax2=fig.add_axes((0.4,0.35,0.25,0.25*xs/ys*(ymax-ymin)/(xmax-xmin)))\n            ax3=fig.add_axes((0.72,0.35,0.25,0.25*xs/ys*(ymax-ymin)/(xmax-xmin)))\n            cax1=fig.add_axes((0.08,0.15,0.25,0.05))\n            cax2=fig.add_axes((0.4,0.15,0.25,0.05))\n            cax3=fig.add_axes((0.72,0.15,0.25,0.05))\n            \n            vmin=-3000.0 \n            vmax=3000.0\n            \n            im1=ax1.pcolormesh(self.x,self.y,self.bx[:,:,0].transpose(),vmin=vmin,vmax=vmax,cmap='gist_gray',shading='auto')\n            im2=ax2.pcolormesh(self.x,self.y,self.by[:,:,0].transpose(),vmin=vmin,vmax=vmax,cmap='gist_gray',shading='auto')\n            im3=ax3.pcolormesh(self.x,self.y,self.bz[:,:,0].transpose(),vmin=vmin,vmax=vmax,cmap='gist_gray',shading='auto')\n\n            cbar1=plt.colorbar(im1,cax=cax1,orientation='horizontal')\n            cbar2=plt.colorbar(im2,cax=cax2,orientation='horizontal')\n            cbar3=plt.colorbar(im3,cax=cax3,orientation='horizontal')\n            \n            ax1.set_title('Bx [G]')\n            ax1.set_xlabel('x [Mm]')\n            ax1.set_ylabel('y [Mm]')\n            \n            ax2.set_title('By [G]')\n            ax2.set_xlabel('x [Mm]')\n            ax2.set_ylabel('y [Mm]')\n            \n            ax3.set_title('Bz [G]')\n            ax3.set_xlabel('x [Mm]')\n            ax3.set_ylabel('y [Mm]')\n            \n            plt.pause(0.1)\n\n\ndata = nlfff('12673_20170906_083600.nc') \n\nx (westward)  unit: Mm\ny (northward)  unit: Mm\nz (out ot photosphere)  unit: Mm\nBx (westward)  unit: G\nBy (northward)  unit: G\nBz (out of photosphere)  unit: G\nBx_pot (westward)  unit: G\nBy_pot (northward)  unit: G\nBz_pot (out of photosphere)  unit: G\n\n\n\ndata.info()\n\nNOAA 12673\nyear_month_day_time 2017_9_6_83600\nproject ISEE Database for Nonlinear Force-Free Field of Solar Active Region\nproduction_date 2023-03-22\nversion v1.2\ndata_doi 10.34515/DATA.HSC-00000\nhttp_link https://hinode.isee.nagoya-u.ac.jp/nlfff_database/\nDistributor Hinode Science Center, Institute for Space-Earth Environmental Research, Nagoya University\n\n\n\ndata.plot()\n\n\n\n\n\n\n\n\n\nvars(data).keys()\n\ndict_keys(['filename', 'NOAA', 'year_month_day_time', 'project', 'production_date', 'version', 'data_doi', 'http_link', 'Distributor', 'x', 'y', 'z', 'bx', 'by', 'bz', 'bx_pot', 'by_pot', 'bz_pot'])"
  },
  {
    "objectID": "posts/field-line-isee-nlfff/index.html#visualization-script",
    "href": "posts/field-line-isee-nlfff/index.html#visualization-script",
    "title": "Visualization of ISEE Nonlinear Force-Free Field of Solar Active Regions in Python",
    "section": "Visualization script",
    "text": "Visualization script\n\nimport numpy as np\nimport pyvista as pv\nimport k3d\nfrom k3d import matplotlib_color_maps\n\ndef create_coordinates(bounds):\n    xbounds = (bounds[0], bounds[1])\n    ybounds = (bounds[2], bounds[3])\n    zbounds = (bounds[4], bounds[5])\n    meshgrid = np.mgrid[xbounds[0]:xbounds[1]+1, ybounds[0]:ybounds[1]+1, zbounds[0]:zbounds[1]+1]\n    return np.stack(meshgrid, axis=-1).astype(np.float32)\n\n\ndef create_mesh(bx, by, bz):\n    bx, by, bz = map(np.array, (bx, by, bz))\n    Nx, Ny, Nz = bx.shape\n    co_bounds = (0, Nx-1, 0, Ny-1, 0, Nz-1)\n    co_coords = create_coordinates(co_bounds).reshape(-1, 3)\n    co_coord = co_coords.reshape(Nx, Ny, Nz, 3)\n    x = co_coord[..., 0]\n    y = co_coord[..., 1]\n    z = co_coord[..., 2]\n    mesh = pv.StructuredGrid(x, y, z)\n    vectors = np.stack([bx, by, bz], axis=-1).transpose(2, 1, 0, 3).reshape(-1, 3)\n    mesh['vector'] = vectors\n    mesh.active_vectors_name = 'vector'\n    magnitude = np.linalg.norm(vectors, axis=-1)\n    mesh['magnitude'] = magnitude\n    mesh.active_scalars_name = 'magnitude'\n    return mesh\n\n\ndef create_mesh_xyz(x, y, z, bx, by, bz):\n    x, y, z, bx, by, bz = map(np.array, (x, y, z, bx, by, bz))\n    X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n    mesh = pv.StructuredGrid(X, Y, Z)\n    vectors = np.stack([bx, by, bz], axis=-1).transpose(2, 1, 0, 3).reshape(-1, 3)\n    mesh['vector'] = vectors\n    mesh.active_vectors_name = 'vector'\n    magnitude = np.linalg.norm(vectors, axis=-1)\n    mesh['magnitude'] = magnitude\n    mesh.active_scalars_name = 'magnitude'\n    return mesh\n\ndef plot_xy_yz_zx(p, dargs, targs):\n    pl = pv.Plotter()\n    pl.show_bounds()\n    pl.add_mesh(p.meshes[0])\n    pl.add_mesh(p.meshes[1], **dargs)\n    pl.add_mesh(p.meshes[2], **targs)\n    pl.camera_position = 'xy'\n    pl.show()\n\n    pl = pv.Plotter()\n    pl.show_bounds()\n    pl.add_mesh(p.meshes[0])\n    pl.add_mesh(p.meshes[1], **dargs)\n    pl.add_mesh(p.meshes[2], **targs)\n    pl.camera_position = 'yz'\n    pl.show()\n\n    pl = pv.Plotter()\n    pl.show_bounds()\n    pl.add_mesh(p.meshes[0])\n    pl.add_mesh(p.meshes[1], **dargs)\n    pl.add_mesh(p.meshes[2], **targs)\n    pl.camera_position = 'xz'\n    pl.show()\n\n\ndef plot_k3d(p):\n    plot = k3d.plot()\n    plot += k3d.vtk_poly_data(p.meshes[0])\n    plot += k3d.vtk_poly_data(p.meshes[1], color_attribute=('vector-2', -2500, 2500), color_map=matplotlib_color_maps.gray)\n    plot += k3d.vtk_poly_data(p.meshes[2])\n    plot.display()\n\n\nclass plotting:\n    def __init__(self, grid):\n        self.grid = grid\n        x_ind_min, y_ind_min, z_ind_min = 0, 0, 0\n        Nx, Ny, Nz = self.grid.dimensions\n        x_ind_max, y_ind_max, z_ind_max = Nx-1, Ny-1, Nz-1\n\n        self.x_ind_min, self.y_ind_min, self.z_ind_min = x_ind_min, y_ind_min, z_ind_min\n        self.x_ind_max, self.y_ind_max, self.z_ind_max = x_ind_max, y_ind_max, z_ind_max\n        \n        bottom_subset = (x_ind_min, x_ind_max, y_ind_min, y_ind_max, 0, 0)\n        bottom = self.grid.extract_subset(bottom_subset).extract_surface()\n        bottom.active_vectors_name = 'vector'\n        bottom.active_scalars_name = 'magnitude'\n\n        self.bottom = bottom\n\n        self.x_bottom = bottom.points[:, 0].reshape(Nx, Ny)\n        self.y_bottom = bottom.points[:, 1].reshape(Nx, Ny)\n        self.B_bottom = bottom['vector'].reshape(Nx, Ny, 3)\n\n        B = self.grid['vector'].reshape(Nz, Ny, Nx, 3)\n        self.B = B.transpose(2, 1, 0, 3)\n\n    def fieldline(self, window_size=None, title=None, title_fontsize=20, camera_position=None, i_siz=160, j_siz=100, i_resolution=16, j_resolution=16, vmin=-2500, vmax=2500, max_time=1000, tube_size=None):\n        p = pv.Plotter()\n        p.show_bounds()\n        p.add_mesh(self.grid.outline())\n        sargs = dict(\n            title='Bz [G]',\n            title_font_size=15,\n            height=0.25,\n            width=0.05,\n            vertical=True,\n            position_x = 0.05,\n            position_y = 0.05,\n        )\n        dargs = dict(\n            cmap='gray',\n            scalars='vector', \n            component=2, \n            clim=(vmin, vmax), \n            scalar_bar_args=sargs, \n            show_scalar_bar=True, \n            lighting=False\n        )\n        p.add_mesh(self.bottom, **dargs)\n\n        if (i_siz is not None) and (j_siz is not None):\n            i_size = i_siz\n            j_size = j_siz\n        else:\n            i_size = self.grid.bounds[1]-self.grid.bounds[0]\n            j_size = self.grid.bounds[3]-self.grid.bounds[2]\n        seed = pv.Plane(center=(self.grid.center[0], self.grid.center[1], 0), direction=(0,0,1), \n                i_size=i_size, j_size=j_size, \n                i_resolution=i_resolution, j_resolution=j_resolution)\n        strl = self.grid.streamlines_from_source(seed,\n                                                 vectors='vector',\n                                                 max_time=max_time,\n                                                 initial_step_length=0.1,\n                                                 integration_direction='both')\n        \n        targs = dict(\n            lighting=False,\n            color='blue'\n        )\n        if tube_size is not None:\n            p.add_mesh(strl.tube(radius=tube_size), **targs)\n        else:\n            p.add_mesh(strl.tube(radius=i_size/400), **targs)\n        if camera_position is not None:\n             p.camera_position = camera_position\n        if window_size is not None:\n            p.window_size = window_size\n        if title is not None:\n            p.add_title(title, font_size=title_fontsize)\n        return p, dargs, targs\n\n\npv.set_jupyter_backend('static')"
  },
  {
    "objectID": "posts/field-line-isee-nlfff/index.html#nonlinear-force-free-field",
    "href": "posts/field-line-isee-nlfff/index.html#nonlinear-force-free-field",
    "title": "Visualization of ISEE Nonlinear Force-Free Field of Solar Active Regions in Python",
    "section": "Nonlinear force-free field",
    "text": "Nonlinear force-free field\n\ncreate_mesh\n\nmesh = create_mesh(data.bx, data.by, data.bz)\nB = plotting(mesh)\np, dargs, targs = B.fieldline()\np.show()\n\n\n\n\n\n\n\n\n\nplot_xy_yz_zx(p, dargs, targs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_k3d(p)\n\n\n\n\n\n    \n\n\n\ncreate_mesh_xyz\n\nmesh = create_mesh_xyz(data.x, data.y, data.z, data.bx, data.by, data.bz)\nB = plotting(mesh)\np, dargs, targs = B.fieldline()\np.show()\n\n\n\n\n\n\n\n\n\nplot_xy_yz_zx(p, dargs, targs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_k3d(p)"
  },
  {
    "objectID": "posts/field-line-isee-nlfff/index.html#potential-field",
    "href": "posts/field-line-isee-nlfff/index.html#potential-field",
    "title": "Visualization of ISEE Nonlinear Force-Free Field of Solar Active Regions in Python",
    "section": "Potential field",
    "text": "Potential field\n\ncreate_mesh\n\nmesh = create_mesh(data.bx_pot, data.by_pot, data.bz_pot)\nBp = plotting(mesh)\np, dargs, targs = Bp.fieldline()\np.show()\n\n\n\n\n\n\n\n\n\nplot_xy_yz_zx(p, dargs, targs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_k3d(p)\n\n\n\n\n\n    \n\n\n\ncreate_mesh_xyz\n\nmesh = create_mesh_xyz(data.x, data.y, data.z, data.bx_pot, data.by_pot, data.bz_pot)\nBp = plotting(mesh)\np, dargs, targs = Bp.fieldline()\np.show()\n\n\n\n\n\n\n\n\n\nplot_xy_yz_zx(p, dargs, targs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_k3d(p)"
  },
  {
    "objectID": "posts/draw-1d-scalar-function/index.html",
    "href": "posts/draw-1d-scalar-function/index.html",
    "title": "How to Draw 1D Scalar Functions in Python",
    "section": "",
    "text": "If you know the mathematical formula of a 1D scalar function y=f(x), then I believe the best tool for drawing 1D scalar functions is Desmos. However, you can also plot the functions in Python using various visualization libraries. In this post, I will draw 1D scalar functions y=x^2 and y=\\sin(x) using basic features of these libraries. Keep in mind that there are many advanced features not covered here, so for more information, refer to the official document of the respective library."
  },
  {
    "objectID": "posts/draw-1d-scalar-function/index.html#sympy",
    "href": "posts/draw-1d-scalar-function/index.html#sympy",
    "title": "How to Draw 1D Scalar Functions in Python",
    "section": "SymPy",
    "text": "SymPy\n\nSymPy is a Python library for symbolic mathematics.\n\nEven though SymPyâ€™s strength lies in symbolic computations, it can also be used for drawing 1D scalar functions, see FigureÂ 1.\n\nfrom sympy import symbols, sin\nfrom sympy.plotting import plot \n\nx = symbols('x')\n\np1 = plot(x**2, (x, -2, 2), legend=True, show=False)\np2 = plot(sin(x), (x, -5, 5), legend=True, show=False)\np1.extend(p2)\np1.show()\n\n\n\n\n\n\n\nFigureÂ 1: A plot using sympy\n\n\n\n\n\nThe graph depicts y=x^2 for x \\in [-2, 2] and y=\\sin(x) for x \\in [-5, 5]. The purpose of using different ranges for x is to display both graphs in a single figure without one being much smaller than the other. This is because the values of x^2 rapidly increases as |x| increases, while |\\sin(x)| \\leq 1 always."
  },
  {
    "objectID": "posts/draw-1d-scalar-function/index.html#data-generation-using-numpy",
    "href": "posts/draw-1d-scalar-function/index.html#data-generation-using-numpy",
    "title": "How to Draw 1D Scalar Functions in Python",
    "section": "Data generation using NumPy",
    "text": "Data generation using NumPy\n\nNumPy is the fundamental package for scientific computing with Python.\n\nOther visualization libraries usually donâ€™t understand symbolic representation of a function. They just draw (x, y) points in a coordinate plane. Therefore, before you use them, you have to generate (x, y) points using NumPy.\n\nimport numpy as np\n\nx1 = np.linspace(-2, 2, 100)\ny1 = x1**2\n\nx2 = np.linspace(-5, 5, 100)\ny2 = np.sin(x2)\n\nnp.linspace(start, stop, num) creates num evenly spaced numbers within a closed interval [start, stop]. So, x1 is an array containing 100 evenly spaced numbers within the interval [-2, 2], and x2 is the same array but within the interval [-5, 5].\n\nx1\n\narray([-2.        , -1.95959596, -1.91919192, -1.87878788, -1.83838384,\n       -1.7979798 , -1.75757576, -1.71717172, -1.67676768, -1.63636364,\n       -1.5959596 , -1.55555556, -1.51515152, -1.47474747, -1.43434343,\n       -1.39393939, -1.35353535, -1.31313131, -1.27272727, -1.23232323,\n       -1.19191919, -1.15151515, -1.11111111, -1.07070707, -1.03030303,\n       -0.98989899, -0.94949495, -0.90909091, -0.86868687, -0.82828283,\n       -0.78787879, -0.74747475, -0.70707071, -0.66666667, -0.62626263,\n       -0.58585859, -0.54545455, -0.50505051, -0.46464646, -0.42424242,\n       -0.38383838, -0.34343434, -0.3030303 , -0.26262626, -0.22222222,\n       -0.18181818, -0.14141414, -0.1010101 , -0.06060606, -0.02020202,\n        0.02020202,  0.06060606,  0.1010101 ,  0.14141414,  0.18181818,\n        0.22222222,  0.26262626,  0.3030303 ,  0.34343434,  0.38383838,\n        0.42424242,  0.46464646,  0.50505051,  0.54545455,  0.58585859,\n        0.62626263,  0.66666667,  0.70707071,  0.74747475,  0.78787879,\n        0.82828283,  0.86868687,  0.90909091,  0.94949495,  0.98989899,\n        1.03030303,  1.07070707,  1.11111111,  1.15151515,  1.19191919,\n        1.23232323,  1.27272727,  1.31313131,  1.35353535,  1.39393939,\n        1.43434343,  1.47474747,  1.51515152,  1.55555556,  1.5959596 ,\n        1.63636364,  1.67676768,  1.71717172,  1.75757576,  1.7979798 ,\n        1.83838384,  1.87878788,  1.91919192,  1.95959596,  2.        ])\n\n\n\\Delta x for this array is (2 - (-2)) / (100 - 1) = 0.\\overline{04}\n\nnp.isclose(np.diff(x1)[0], (2 - (-2)) / (100 - 1))\n\nTrue\n\n\n\nx2\n\narray([-5.        , -4.8989899 , -4.7979798 , -4.6969697 , -4.5959596 ,\n       -4.49494949, -4.39393939, -4.29292929, -4.19191919, -4.09090909,\n       -3.98989899, -3.88888889, -3.78787879, -3.68686869, -3.58585859,\n       -3.48484848, -3.38383838, -3.28282828, -3.18181818, -3.08080808,\n       -2.97979798, -2.87878788, -2.77777778, -2.67676768, -2.57575758,\n       -2.47474747, -2.37373737, -2.27272727, -2.17171717, -2.07070707,\n       -1.96969697, -1.86868687, -1.76767677, -1.66666667, -1.56565657,\n       -1.46464646, -1.36363636, -1.26262626, -1.16161616, -1.06060606,\n       -0.95959596, -0.85858586, -0.75757576, -0.65656566, -0.55555556,\n       -0.45454545, -0.35353535, -0.25252525, -0.15151515, -0.05050505,\n        0.05050505,  0.15151515,  0.25252525,  0.35353535,  0.45454545,\n        0.55555556,  0.65656566,  0.75757576,  0.85858586,  0.95959596,\n        1.06060606,  1.16161616,  1.26262626,  1.36363636,  1.46464646,\n        1.56565657,  1.66666667,  1.76767677,  1.86868687,  1.96969697,\n        2.07070707,  2.17171717,  2.27272727,  2.37373737,  2.47474747,\n        2.57575758,  2.67676768,  2.77777778,  2.87878788,  2.97979798,\n        3.08080808,  3.18181818,  3.28282828,  3.38383838,  3.48484848,\n        3.58585859,  3.68686869,  3.78787879,  3.88888889,  3.98989899,\n        4.09090909,  4.19191919,  4.29292929,  4.39393939,  4.49494949,\n        4.5959596 ,  4.6969697 ,  4.7979798 ,  4.8989899 ,  5.        ])\n\n\n\\Delta x for this array is (5 - (-5)) / (100 - 1) = 0.\\overline{10}\n\nnp.isclose(np.diff(x2)[0], (5 - (-5)) / (100 - 1))\n\nTrue\n\n\n(x1, y1) points are used to draw the graph of y=x^2, while (x2, y2) points are used for the graph of y=\\sin(x)."
  },
  {
    "objectID": "posts/draw-1d-scalar-function/index.html#matplotlib",
    "href": "posts/draw-1d-scalar-function/index.html#matplotlib",
    "title": "How to Draw 1D Scalar Functions in Python",
    "section": "Matplotlib",
    "text": "Matplotlib\n\nMatplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n\nMatplotlib is one of the most popular visualization libraries in Python, see FigureÂ 2.\n\nimport matplotlib.pyplot as plt\n\nplt.plot(x1, y1, label=r'$x^2$')\nplt.plot(x2, y2, label=r'$\\sin x$')\nplt.legend()\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.show()\n\n\n\n\n\n\n\nFigureÂ 2: A plot using matplotlib"
  },
  {
    "objectID": "posts/draw-1d-scalar-function/index.html#pandas",
    "href": "posts/draw-1d-scalar-function/index.html#pandas",
    "title": "How to Draw 1D Scalar Functions in Python",
    "section": "pandas",
    "text": "pandas\n\npandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\n\nSince pandas is a great data analysis tool in Python, it can used for drawing graphs, see FigureÂ 3.\n\nimport pandas as pd \n\ndf1 = pd.DataFrame(data={'x':x1, 'y':y1})\ndf2 = pd.DataFrame(data={'x':x2, 'y':y2})\n\nax = df1.plot(x='x', y='y', label=r'$x^2$')\ndf2.plot(ax=ax, x='x', y='y', label=r'$\\sin x$')\nax.axvline(0, color='k')\nax.axhline(0, color='k')\nplt.show()\n\n\n\n\n\n\n\nFigureÂ 3: A plot using pandas"
  },
  {
    "objectID": "posts/draw-1d-scalar-function/index.html#plotly",
    "href": "posts/draw-1d-scalar-function/index.html#plotly",
    "title": "How to Draw 1D Scalar Functions in Python",
    "section": "Plotly",
    "text": "Plotly\n\nPlotly is a technical computing company headquartered in Montreal, Quebec, that develops online data analytics and visualization tools. Plotly provides online graphing, analytics, and statistics tools for individuals and collaboration, as well as scientific graphing libraries for Python, R, MATLAB, Perl, Julia, Arduino, JavaScript and REST. #\n\nPlotly is a useful tool for creating interactive plots, see FigureÂ 4.\n\nimport plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x1, y=y1, mode='lines', name='xÂ²'))\nfig.add_trace(go.Scatter(x=x2, y=y2, mode='lines', name='sin(x)'))\nfig.show()\n\n\n\n                                                \n\n\nFigureÂ 4: A plot using plotly"
  },
  {
    "objectID": "posts/double-pendulum-julia/index.html",
    "href": "posts/double-pendulum-julia/index.html",
    "title": "The double pendulum problem in Julia",
    "section": "",
    "text": "This post is based on an example of Plots.jl."
  },
  {
    "objectID": "posts/double-pendulum-julia/index.html#the-double-pendulum-problem",
    "href": "posts/double-pendulum-julia/index.html#the-double-pendulum-problem",
    "title": "The double pendulum problem in Julia",
    "section": "",
    "text": "This post is based on an example of Plots.jl."
  },
  {
    "objectID": "posts/double-pendulum-julia/index.html#code",
    "href": "posts/double-pendulum-julia/index.html#code",
    "title": "The double pendulum problem in Julia",
    "section": "Code",
    "text": "Code\n\nusing OrdinaryDiffEq, Plots; gr()\nusing Printf\n\n\nfunction pendulum!(du, u, p, t)\n    # u[1] = theta1\n    # u[2] = omega1\n    # u[3] = theta2\n    # u[4] = omega2\n    \n    (; M1, M2, L1, L2, G) = p\n\n    du[1] = u[2]\n\n    delta = u[3] - u[1]\n    den1 = (M1 + M2) * L1 - M2 * L1 * cos(delta) * cos(delta)\n    du[2] = (\n        (\n            M2 * L1 * u[2] * u[2] * sin(delta) * cos(delta) +\n            M2 * G * sin(u[3]) * cos(delta) +\n            M2 * L2 * u[4] * u[4] * sin(delta) - (M1 + M2) * G * sin(u[1])\n        ) / den1\n    )\n\n    du[3] = u[4]\n\n    den2 = (L2 / L1) * den1\n    du[4] = (\n        (\n            -M2 * L2 * u[4] * u[4] * sin(delta) * cos(delta) +\n            (M1 + M2) * G * sin(u[1]) * cos(delta) -\n            (M1 + M2) * L1 * u[2] * u[2] * sin(delta) - (M1 + M2) * G * sin(u[3])\n        ) / den2\n    )\n    nothing\nend\n\npendulum! (generic function with 1 method)\n\n\n\nG = 9.8       # acceleration due to gravity, in m/s^2\nL1 = 1.0      # length of pendulum 1 in m\nL2 = 1.0      # length of pendulum 2 in m\nL = L1 + L2   # maximal length of the combined pendulum\nM1 = 1.0      # mass of pendulum 1 in kg\nM2 = 1.0      # mass of pendulum 2 in kg\nt_stop = 5.0  # how many seconds to simulate\n\n5.0\n\n\n\n# th1 and th2 are the initial angles (degrees)\n# w10 and w20 are the initial angular velocities (degrees per second)\nth1 = 120.0\nw1 = 0.0\nth2 = -10.0\nw2 = 0.0\n\n0.0\n\n\n\nu0 = deg2rad.([th1, w1, th2, w2])\n\n4-element Vector{Float64}:\n  2.0943951023931953\n  0.0\n -0.17453292519943295\n  0.0\n\n\n\np = (; M1, M2, L1, L2, G)\n\n(M1 = 1.0, M2 = 1.0, L1 = 1.0, L2 = 1.0, G = 9.8)\n\n\n\ntspan = (0.0, t_stop)\n\n(0.0, 5.0)\n\n\n\nprob = ODEProblem(pendulum!, u0, tspan, p)\n\n\nODEProblem with uType Vector{Float64} and tType Float64. In-place: true\ntimespan: (0.0, 5.0)\nu0: 4-element Vector{Float64}:\n  2.0943951023931953\n  0.0\n -0.17453292519943295\n  0.0\n\n\n\n\n@time solve(prob, dense=true, alg=Vern7(), reltol=1e-10, abstol=1e-10);\n\n  4.801410 seconds (20.07 M allocations: 1.311 GiB, 6.50% gc time, 99.99% compilation time)\n\n\n\n@time sol = solve(prob, dense=true, \n    alg=Vern7(), reltol=1e-10, abstol=1e-10)\n\n  0.000413 seconds (3.97 k allocations: 404.250 KiB)\n\n\nretcode: Success\nInterpolation: specialized 7th order lazy interpolation\nt: 327-element Vector{Float64}:\n 0.0\n 0.015120200135242772\n 0.03461247124860289\n 0.05621034906611724\n 0.08063338298221337\n 0.10655860257718384\n 0.13371069061057467\n 0.16136170833943062\n 0.18910379555029622\n 0.216500191087515\n â‹®\n 4.877658909987774\n 4.891048061088556\n 4.906726954985946\n 4.92395952857032\n 4.940477265391924\n 4.9570673499295275\n 4.973347466199946\n 4.989481530533818\n 5.0\nu: 327-element Vector{Vector{Float64}}:\n [2.0943951023931953, 0.0, -0.17453292519943295, 0.0]\n [2.093251192266732, -0.15130144360225076, -0.17507316706106824, -0.07138583688240614]\n [2.0884020066846594, -0.34620684293642423, -0.17735151407883185, -0.16197940762950855]\n [2.0785960375730372, -0.5617458491336331, -0.18190022469696743, -0.2583291215327368]\n [2.0619088616767502, -0.8045658145300556, -0.18945998215379264, -0.35897310430460627]\n [2.0377259296673795, -1.0606883684801727, -0.20000780534447987, -0.45198941094552436]\n [2.0053127296813607, -1.3263167089129453, -0.21337992707010664, -0.5290751421284102]\n [1.9649409859714275, -1.5930439677685073, -0.22879032047995732, -0.5805198650083305]\n [1.9170909858635226, -1.8556580077531657, -0.24523226705660403, -0.5987532995918393]\n [1.8627674994092769, -2.109011300081415, -0.2614479063701741, -0.5781647279534727]\n â‹®\n [0.08055304727076054, -4.844672221947719, 7.323641407873413, -0.3937092424276102]\n [0.016456248134838113, -4.729974482015508, 7.315465794703606, -0.8259494949202341]\n [-0.056649840079156244, -4.5949029003734845, 7.298626670050392, -1.3197608125366442]\n [-0.13450819146501108, -4.439547315775765, 7.271324047281913, -1.8459341422625748]\n [-0.20652600642233343, -4.277983589438366, 7.236791129717663, -2.3322767387862955]\n [-0.27603285796575844, -4.097988312352799, 7.194181777987756, -2.800971206639784]\n [-0.3411670498167553, -3.899839597788059, 7.144980717318993, -3.2396924617007903]\n [-0.40234149964195665, -3.6791729003067517, 7.08935288274075, -3.652222880783009]\n [-0.44021974519477647, -3.5211389770525976, 7.049578950062814, -3.9088281792608424]\n\n\n\ndt = 0.01\nt = range(0, t_stop, 500)\nt\n\n0.0:0.01002004008016032:5.0\n\n\n\nss = sol(t)\n\nt: 0.0:0.01002004008016032:5.0\nu: 500-element Vector{Vector{Float64}}:\n [2.0943951023931953, 0.0, -0.17453292519943295, 0.0]\n [2.093892727794568, -0.1002718148594462, -0.17477031576780788, -0.047361688467315]\n [2.0923857338065837, -0.20051767898773526, -0.17548119651329958, -0.09446566162367707]\n [2.089874512316763, -0.3007111508060837, -0.17666169217282704, -0.14105372938857924]\n [2.0863597246275583, -0.4008248182697641, -0.17830533609426816, -0.18686676551089001]\n [2.0818423134938038, -0.5008298418502478, -0.18040305865053075, -0.23164427293860568]\n [2.076323519577815, -0.6006955317654576, -0.18294317148887201, -0.2751239894162722]\n [2.069804901918936, -0.7003889715061674, -0.18591134808623772, -0.31704154681648083]\n [2.0622883618913157, -0.7998747002091745, -0.18929060121668145, -0.3571301977165818]\n [2.0537761699948334, -0.8991144670078379, -0.1930612580721276, -0.3951206226371907]\n â‹®\n [-0.11613910894023596, -4.4776867736889425, 7.278673697988922, -1.7218077760104107]\n [-0.16053801455439923, -4.3835492670133664, 7.2599127844500435, -2.0217833125716056]\n [-0.2039680558672177, -4.284106009021184, 7.238179522753177, -2.3150140108684756]\n [-0.2463703579186004, -4.178233875161714, 7.213543772354339, -2.601042788066967]\n [-0.287675318032719, -4.064916713625344, 7.186080007668746, -2.8794106387414]\n [-0.32780373308398425, -3.943255996139626, 7.1558671806928364, -3.1496882975237526]\n [-0.366668020773485, -3.8124788731823114, 7.122988257425244, -3.4115093994105914]\n [-0.404173506838206, -3.6719431947583643, 7.087529421169394, -3.6646035735052447]\n [-0.4402197451947838, -3.5211389770525665, 7.0495789500628065, -3.908828179260892]\n\n\n\ns = reduce(hcat, ss.u)'\n\n500Ã—4 adjoint(::Matrix{Float64}) with eltype Float64:\n  2.0944     0.0       -0.174533   0.0\n  2.09389   -0.100272  -0.17477   -0.0473617\n  2.09239   -0.200518  -0.175481  -0.0944657\n  2.08987   -0.300711  -0.176662  -0.141054\n  2.08636   -0.400825  -0.178305  -0.186867\n  2.08184   -0.50083   -0.180403  -0.231644\n  2.07632   -0.600696  -0.182943  -0.275124\n  2.0698    -0.700389  -0.185911  -0.317042\n  2.06229   -0.799875  -0.189291  -0.35713\n  2.05378   -0.899114  -0.193061  -0.395121\n  â‹®                               \n -0.116139  -4.47769    7.27867   -1.72181\n -0.160538  -4.38355    7.25991   -2.02178\n -0.203968  -4.28411    7.23818   -2.31501\n -0.24637   -4.17823    7.21354   -2.60104\n -0.287675  -4.06492    7.18608   -2.87941\n -0.327804  -3.94326    7.15587   -3.14969\n -0.366668  -3.81248    7.12299   -3.41151\n -0.404174  -3.67194    7.08753   -3.6646\n -0.44022   -3.52114    7.04958   -3.90883\n\n\n\n# theta1\ns[:, 1]\n\n500-element Vector{Float64}:\n  2.0943951023931953\n  2.093892727794568\n  2.0923857338065837\n  2.089874512316763\n  2.0863597246275583\n  2.0818423134938038\n  2.076323519577815\n  2.069804901918936\n  2.0622883618913157\n  2.0537761699948334\n  â‹®\n -0.11613910894023596\n -0.16053801455439923\n -0.2039680558672177\n -0.2463703579186004\n -0.287675318032719\n -0.32780373308398425\n -0.366668020773485\n -0.404173506838206\n -0.4402197451947838\n\n\n\n# u[1] = theta1\n# u[2] = omega1\n# u[3] = theta2\n# u[4] = omega2\n\nx1 = +L1 * sin.(s[:, 1])\ny1 = -L1 * cos.(s[:, 1])\n\nx2 = +L2 * sin.(s[:, 3]) + x1\ny2 = -L2 * cos.(s[:, 3]) + y1\n\n500-element Vector{Float64}:\n -0.48480775301220824\n -0.48520163506531977\n -0.4863838171334237\n -0.4883559068223133\n -0.49112058298184197\n -0.4946815946474795\n -0.499043758925124\n -0.5042129571957659\n -0.5101961288529362\n -0.5170012616341575\n  â‹®\n -1.537356613268544\n -1.5468788057341616\n -1.556884012872978\n -1.567350616246526\n -1.5782459039766115\n -1.5895261435074444\n -1.6011366077255564\n -1.6130116056633983\n -1.625074551166418\n\n\n\nplot(x2, y2,\n    legend = false,\n    grid = true,\n    gridlinewidth = 2,\n    aspect_ratio = :equal;\n    xaxis = \"x2\",\n    yaxis = \"y2\",\n    xlims = (-2.0, 2.0),\n    ylims = (-2.0, 2.0),\n    widen = true,\n    dpi = 300\n)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsavefig(\"thumbnail.png\")\n\n\nts = [i for i in t]\nani = @animate for i in eachindex(x2)\n\n    x = [0, x1[i], x2[i]]\n    y = [0, y1[i], y2[i]]\n\n    plot(x, y, aspect_ratio=1.0, legend = false)\n    plot!(xlims = (-L, L), xticks = -L:0.5:L)\n    plot!(ylims = (-L, 1), yticks = -L:0.5:1)\n    scatter!(x, y, color = :red)\n\n    x = x2[1:i]\n    y = y2[1:i]\n\n    plot!(x, y, linecolor = :orange)\n    plot!(xlims = (-L, L), xticks = -L:0.5:L)\n    plot!(ylims = (-L, 1), yticks = -L:0.5:1)\n    scatter!(x, y, \n        color = :orange,\n        markersize = 2,\n        markerstrokewidth = 0,\n        markerstrokecolor = :orange,\n    )\n    annotate!(-1.25, 0.5, \"time= $(@sprintf(\"%.1f\", round(ts[i]; digits=2))) s\")\nend every 10\n\n\ngif(ani, \"ani_julia.mp4\", fps = 10)"
  },
  {
    "objectID": "posts/conservation-law/index.html",
    "href": "posts/conservation-law/index.html",
    "title": "ë³´ì¡´ë²•ì¹™",
    "section": "",
    "text": "2018ë…„ì— ë¬¼ë¦¬í•™ì‹¤í—˜ (ê²½í¬ëŒ€í•™êµ ê¹€ì„ ê²½ êµìˆ˜) ë³´ê³ ì„œìš©ìœ¼ë¡œ ìž‘ì„±í•œ ê¸€"
  },
  {
    "objectID": "posts/conservation-law/index.html#ì—­í•™ì -ì—ë„ˆì§€-ë³´ì¡´-ë²•ì¹™",
    "href": "posts/conservation-law/index.html#ì—­í•™ì -ì—ë„ˆì§€-ë³´ì¡´-ë²•ì¹™",
    "title": "ë³´ì¡´ë²•ì¹™",
    "section": "ì—­í•™ì  ì—ë„ˆì§€ ë³´ì¡´ ë²•ì¹™",
    "text": "ì—­í•™ì  ì—ë„ˆì§€ ë³´ì¡´ ë²•ì¹™\në‰´í„´ì˜ ìš´ë™ë²•ì¹™ì€ ê·¼ë³¸ì ìœ¼ë¡œ ë¯¸ë¶„ë°©ì •ì‹ìœ¼ë¡œ ì„œìˆ ëœë‹¤. íŠ¹ížˆ íž˜ê³¼ ê°€ì†ë„ì™€ ê°™ì€ ë¬¼ë¦¬ëŸ‰ë“¤ì€ ë²¡í„°ëŸ‰ì´ê¸° ë•Œë¬¸ì— ë‹¤ë£¨ê¸°ê°€ ì‰½ì§€ ì•Šë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ ë¬¼ë¦¬í•™ìžë“¤ì€ ìŠ¤ì¹¼ë¼ëŸ‰ì¸ ì¼ì´ë¼ëŠ” ê°œë…ì„ ë§Œë“  í›„ì—, ë‰´í„´ ìš´ë™ë²•ì¹™ì„ ìˆ˜í•™ì ìœ¼ë¡œ ì•½ê°„ ì¡°ìž‘í•˜ì—¬ ìš´ë™ì—ë„ˆì§€ë¼ëŠ” ìƒˆë¡œìš´ ê°œë…ì„ ë§Œë“¤ê²Œ ë˜ì—ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ê²ƒì„ í†µí•´ ì¼-(ìš´ë™)ì—ë„ˆì§€ ì •ë¦¬ë¥¼ ì´ëŒì–´ ë‚´ì—ˆë‹¤. ì´ ì •ë¦¬ëŠ” â€™ë¬¼ì²´ì— ê°€í•´ì§„ ì•Œì§œíž˜ì´ í•œ ì¼ì€ ë¬¼ì²´ì˜ ìš´ë™ì—ë„ˆì§€ ë³€í™”ëŸ‰ê³¼ ê°™ë‹¤â€™ë¼ëŠ” ì‚¬ì‹¤ì„ ì•Œë ¤ì¤€ë‹¤(\\mathbf{F} = m \\mathbf{a}ì—ì„œì˜ \\mathbf{F}ê°€ ì•Œì§œíž˜(í•©ë ¥, net force)ì´ê¸° ë•Œë¬¸ì´ë‹¤). ì¼-ìš´ë™ì—ë„ˆì§€ ì •ë¦¬ë¥¼ ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\nW_{\\text{ì•Œì§œ íž˜}} = \\Delta K\n\nì´ ì •ë¦¬ëŠ” ìˆ˜í•™ì ìœ¼ë¡œ ìœ ë„ëœ ì •ë¦¬ì´ê¸° ë•Œë¬¸ì—, ë¬¼ì²´ì— ê°€í•´ì§€ëŠ” ëª¨ë“  ì•Œì§œíž˜ì— ëŒ€í•´ ì„±ë¦½í•˜ëŠ” ì •ë¦¬ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ë¬¼ë¦¬í•™ìžë“¤ì€ ì—¬ê¸°ì„œ í•œë°œ ë” ë‚˜ì•„ê°€ ì¢Œë³€ì„ ë‹¤ìŒê³¼ ê°™ì´ ì“°ê³  ì‹¶ì–´í–ˆë‹¤.\n\n-\\Delta U = \\Delta K\n\nì™œëƒí•˜ë©´ ë§Œì•½ ì´ë ‡ê²Œ ì“¸ ìˆ˜ë§Œ ìžˆë‹¤ë©´, Kë¼ëŠ” ì–‘ê³¼ Uë¼ëŠ” ì–‘ì´ â€™ë³´ì¡´â€™ë˜ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ëŸ°ë° ë‹¤í–‰ížˆë„ ë¬¼ë¦¬í•™ìžë“¤ì€ ì¤‘ë ¥ì´ë‚˜ íƒ„ì„±ë ¥, ì „ê¸°ë ¥ê³¼ ê°™ì€ íŠ¹ì •í•œ íž˜ë“¤ì´ í•˜ëŠ” ì¼ì€ ìœ„ì™€ ê°™ì´ ì“¸ìˆ˜ ìžˆìŒì„ ì•Œê²Œ ë˜ì—ˆê³ , Uë¥¼ â€™ìœ„ì¹˜ì—ë„ˆì§€(í¼í…ì…œì—ë„ˆì§€)â€™ë¼ ì •ì˜í•˜ì˜€ë‹¤. ë˜í•œ í¼í…ì…œì—ë„ˆì§€ë¥¼ ì •ì˜í•  ìˆ˜ ìžˆëŠ” íž˜ì„ ë³´ì¡´ë ¥ì´ë¼ê³  ë¶€ë¥´ê²Œ ë˜ì—ˆë‹¤. ë”°ë¼ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìžˆë‹¤.\n\nW_{\\text{ë³´ì¡´ë ¥}} = -\\Delta U_{\\text{ë³´ì¡´ë ¥}}\n\në˜í•œ ëª¨ë“  íž˜ì€ ì´ëŸ¬í•œ ë³´ì¡´ë ¥ê³¼ ë³´ì¡´ë ¥ì´ ì•„ë‹Œ íž˜, ì¦‰ ë¹„ë³´ì¡´ë ¥ ë‘ ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆë‹¤. ì¼ì€ íž˜ê³¼ ë³€ìœ„ë²¡í„°ì˜ ë‚´ì ìœ¼ë¡œ ì •ì˜ë˜ê³ , ë‚´ì ì€ ìˆ˜í•™ì ìœ¼ë¡œ ë¶„ë°°ë²•ì¹™ì´ ì„±ë¦½í•˜ê¸° ë•Œë¬¸ì— ì¼-ìš´ë™ì—ë„ˆì§€ ì •ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìžˆë‹¤.\n\nW_{\\text{ë³´ì¡´ë ¥}} + W_{\\text{ë¹„ë³´ì¡´ë ¥}} = \\Delta K\n \nW_{\\text{ë¹„ë³´ì¡´ë ¥}} = \\Delta K + \\Delta U_{\\text{ë³´ì¡´ë ¥}}\n\nì´ë•Œ ë¬¼ì²´ì˜ ìš´ë™ì—ë„ˆì§€ì™€ í¼í…ì…œì—ë„ˆì§€ì˜ í•©ì„ ì—­í•™ì  ì—ë„ˆì§€ë¼ê³  ì •ì˜í•˜ê²Œ ë˜ë©´ ë‹¤ìŒì„ ì–»ëŠ”ë‹¤.\n\nW_{\\text{ë¹„ë³´ì¡´ë ¥}} = \\Delta E_{\\text{ì—­í•™ì }}\n\në”°ë¼ì„œ ë¹„ë³´ì¡´ë ¥ì´ ì¼ì„ í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ì˜ ì—­í•™ì  ì—ë„ˆì§€ëŠ” ì¼ì •í•˜ê²Œ ìœ ì§€ëœë‹¤. ì¦‰ ì–´ë–¤ ë¬¼ì²´ì— ë³´ì¡´ë ¥ë§Œ ì¼ì„ í•œë‹¤ë©´ ê·¸ ë¬¼ì²´ì˜ ì—­í•™ì  ì—ë„ˆì§€ëŠ” ì¼ì •í•˜ê²Œ ìœ ì§€ëœë‹¤. ë°”ë¡œ ì´ê²ƒì„ ì—­í•™ì  ì—ë„ˆì§€ ë³´ì¡´ ë²•ì¹™ì´ë¼ê³  ë¶€ë¥¸ë‹¤.\n\ní¼í…ì…œ ì—ë„ˆì§€(Potential Energy)ì˜ ì •ì˜\n\nì–´ë–¤ ë¬¼ì²´ì˜ ìœ„ì¹˜ë²¡í„°ê°€ ë²¡í„°í•¨ìˆ˜ \\mathbf{r}(t) (a\\leq t \\leq b)ë¡œ ì£¼ì–´ì§€ê³ , ì‹œê°„ a\\leq t \\leq b ë™ì•ˆ ë¬¼ì²´ê°€ ì›€ì§ì¸ ê²½ë¡œê°€ ê³¡ì„  Cì´ë©° ê·¸ë™ì•ˆ ë¬¼ì²´ì— ê°€í•´ì§„ íž˜ì´ \\mathbf{F}(\\mathbf{r})ì¼ ë•Œ(ë˜ëŠ” ë¬¼ì²´ê°€ ë²¡í„°ìž¥ \\mathbf{F}(\\mathbf{r})ê°€ ìžˆëŠ” ê³µê°„ì—ì„œ ê³¡ì„  Cë¥¼ ë”°ë¼ ì›€ì§ì˜€ì„ ë•Œ), íž˜ \\mathbf{F}ê°€ ë¬¼ì²´ì— í•œ ì¼ WëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•œë‹¤. ì´ë•Œ \\rm{d}\\mathbf{l} = \\rm{d}\\mathbf{r} = \\mathbf{r}'\\rm{d}t ì´ë‹¤.\n\n\n\\begin{align*}\nW & = \\int_{C} \\mathbf{F} \\cdot \\rm{d}\\mathbf{l} \\\\\n& = \\int_{a}^{b} \\mathbf{F}(\\mathbf{r}(t)) \\cdot \\mathbf{r}'(t)\\rm{d}t\n\\end{align*}\n\n\nì–´ë–¤ íž˜ \\mathbf{F}ê°€ ë³´ì¡´ë ¥ì¼ë•Œ, ì¦‰ ìœ„ì¹˜ë²¡í„° \\mathbf{r}(t)ì— ëŒ€í•œ ë²¡í„°í•¨ìˆ˜ \\mathbf{F}(\\mathbf{r}(t))ê°€ ë³´ì¡´ìž¥ì¼ë•Œ, ë‹¤ìŒì„ ë§Œì¡±í•˜ëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ U(\\mathbf{r}(t))ë¥¼ íž˜ \\mathbf{F}ì— ëŒ€í•œ í¼í…ì…œ ì—ë„ˆì§€ë¼ê³  ì •ì˜í•œë‹¤.\n\n\n\\mathbf{F}(\\mathbf{r}) = -\\nabla U(\\mathbf{r})\n\n\nì–´ë–¤ íž˜ \\mathbf{F}ê°€ \\mathbf{F}(\\mathbf{r}) = - \\nabla U(\\mathbf{r})ë¡œ ì£¼ì–´ì§€ëŠ” ë³´ì¡´ë ¥ì´ê³ , ìœ„ì¹˜ë²¡í„°ê°€ \\mathbf{r}(t)ë¡œ ì£¼ì–´ì§€ëŠ” ë¬¼ì²´ê°€ ì‹œê°„ a \\leq t \\leq bë™ì•ˆ íž˜ \\mathbf{F}ë¥¼ ë°›ìœ¼ë©° ê²½ë¡œ Cë¥¼ ë”°ë¼ ì›€ì§ì˜€ë‹¤ê³  í•˜ë©´, ì„ ì ë¶„ì˜ ê¸°ë³¸ì •ë¦¬ì— ì˜í•´ ë‹¤ìŒì´ ì„±ë¦½í•œë‹¤.\n\n\nU(\\mathbf{r}(b)) - U(\\mathbf{r}(a)) = - \\int_{C} \\mathbf{F} \\cdot \\rm{d}\\mathbf{l}\n\n\në”°ë¼ì„œ ë³´ì¡´ë ¥ \\mathbf{F}ì— ëŒ€í•œ ìœ„ì¹˜ \\mathbf{r}ì—ì„œì˜ í¼í…ì…œ ì—ë„ˆì§€ U(\\mathbf{r})ì€ ì„ ì ë¶„ì„ ì´ìš©í•´ ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìžˆë‹¤. ì´ë•Œ \\mathbf{r}^{*}ëŠ” í¼í…ì…œ ì—ë„ˆì§€ê°€ 0ì´ ë˜ëŠ” ìž„ì˜ì˜ ê¸°ì¤€ì ì´ë‹¤.\n\n\nU(\\mathbf{r}) = - \\int_{\\mathbf{r}^{*}}^{\\mathbf{r}} \\mathbf{F} \\cdot \\rm{d} \\mathbf{l}"
  },
  {
    "objectID": "posts/conservation-law/index.html#ìš´ë™ëŸ‰-ë³´ì¡´-ë²•ì¹™",
    "href": "posts/conservation-law/index.html#ìš´ë™ëŸ‰-ë³´ì¡´-ë²•ì¹™",
    "title": "ë³´ì¡´ë²•ì¹™",
    "section": "ìš´ë™ëŸ‰ ë³´ì¡´ ë²•ì¹™",
    "text": "ìš´ë™ëŸ‰ ë³´ì¡´ ë²•ì¹™\nê´€ì„±ê¸°ì¤€ê³„ì˜ ì›ì ì— ëŒ€í•´ ìœ„ì¹˜ë²¡í„°ê°€ \\mathbf{r}_{1}, \\mathbf{r}_{2}, \\cdots, \\mathbf{r}_{n}ìœ¼ë¡œ ì£¼ì–´ì§€ê³ , ì§ˆëŸ‰ì´ ê°ê° m_{1}, m_{2}, \\cdots, m_{n}ì¸ nê°œì˜ ë¬¼ì²´ë“¤ë¡œ êµ¬ì„±ëœ ê³„ë¥¼ ì„¤ì •í•˜ìž. ê° ë¬¼ì²´ëŠ” ìœ„ì¹˜ë²¡í„°ì˜ ì²¨ìžì— ë”°ë¼ 1, 2, \\cdots, në²ˆì§¸ ë¬¼ì²´ë¼ê³  í•˜ê² ë‹¤. ê´€ì„±ê¸°ì¤€ê³„ì— ëŒ€í•´ ë¬¼ì²´ì˜ ìœ„ì¹˜ë²¡í„°ë¥¼ í‘œí˜„í•˜ì˜€ìœ¼ë¯€ë¡œ, ië²ˆì§¸ ë¬¼ì²´ì— ëŒ€í•´ ë‰´í„´ ì œ 2ë²•ì¹™ì„ ì ìš©í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ì´ë•Œ \\mathbf{F}_{\\text{ë‚´ë ¥}, i}ëŠ” ië²ˆì§¸ ë¬¼ì²´ë¥¼ ì œì™¸í•œ ê³„ ë‚´ë¶€ì˜ n-1ê°œì˜ ë¬¼ì²´ë“¤ì´ ië²ˆì§¸ ë¬¼ì²´ì— ìž‘ìš©í•˜ëŠ” íž˜ë“¤ì˜ í•©ë ¥ì´ê³ , \\mathbf{F}_{\\text{ì™¸ë ¥}, i}ëŠ” ì£¼ì–´ì§„ ê³„ ì™¸ë¶€ì˜ ë¬¼ì²´ë“¤ì´ ië²ˆì§¸ ë¬¼ì²´ì— ìž‘ìš©í•˜ëŠ” íž˜ë“¤ì˜ í•©ë ¥ì´ë‹¤. ë˜í•œ \\mathbf{v}_{i} = \\displaystyle \\frac{d}{dt} \\mathbf{r}_{i}ì´ë‹¤.\n\n\\mathbf{F}_{\\text{ë‚´ë ¥}, i} + \\mathbf{F}_{\\text{ì™¸ë ¥}, i} = m_{i} \\frac{d}{dt} \\mathbf{v}_{i}\n\nì´ë•Œ ë‰´í„´ ì œ 3ë²•ì¹™ì— ì˜í•´\n\n\\sum_{i=1}^{n} \\mathbf{F}_{\\text{ë‚´ë ¥}, i} = \\mathbf{0}\n\nì´ ì„±ë¦½í•˜ê³ , ë¬¼ì²´ì˜ ì§ˆëŸ‰ì´ ì‹œê°„ì— ëŒ€í•´ ë³€í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê°€ì •ì„ í•œë‹¤ë©´\n\nm_{i} \\frac{d}{dt} \\mathbf{v}_{i} = \\frac{d}{dt} (m_{i} \\mathbf{v}_{i})\n\nì´ ì„±ë¦½í•œë‹¤. ë”°ë¼ì„œ ië²ˆì§¸ ë¬¼ì²´ì— ëŒ€í•œ ë‰´í„´ ìš´ë™ë°©ì •ì‹ ì–‘ë³€ì— ì‹œê·¸ë§ˆë¥¼ ì·¨í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ì´ë•Œ \\mathbf{F}_{\\text{ì™¸ë ¥}} = \\displaystyle \\sum_{i=1}^{n} \\mathbf{F}_{\\text{ì™¸ë ¥}, i}ì´ë‹¤.\n\n\\mathbf{F}_{\\text{ì™¸ë ¥}} = \\frac{d}{dt} \\left( \\sum_{i=1}^{n} m_{i} \\mathbf{v}_{i} \\right)\n\nì´ë•Œ ìƒˆë¡œìš´ ë¬¼ë¦¬ëŸ‰ \\mathbf{p} \\equiv m\\mathbf{v}ë¥¼ ì •ì˜í•˜ê³ , ì´ê²ƒì„ (ì„ )ìš´ë™ëŸ‰ì´ë¼ê³  ë¶€ë¥´ìž. ê·¸ëŸ¬ë©´ ië²ˆì§¸ ë¬¼ì²´ì˜ ìš´ë™ëŸ‰ì€ \\mathbf{p}_{i} = m_{i}\\mathbf{v}_{i}ì´ë¯€ë¡œ, ìœ„ ì‹ì˜ ìš°ë³€ì€ ê³„ ë‚´ë¶€ ë¬¼ì²´ë“¤ì˜ ì´ìš´ë™ëŸ‰ì˜ ì‹œê°„ì— ëŒ€í•œ ë³€í™”ìœ¨ì´ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ê³„ ë‚´ë¶€ ë¬¼ì²´ë“¤ì˜ ì´ìš´ë™ëŸ‰ì„ \\mathbf{P} = \\displaystyle \\sum_{i=1}^{n} m_{i} \\mathbf{v}_{i}ë¼ê³  í•˜ë©´ ë‹¤ìŒ ì‹ì´ ì„±ë¦½í•œë‹¤.\n\n\\mathbf{F}_{\\text{ì™¸ë ¥}} = \\frac{d}{dt} \\mathbf{P}\n\nì—¬ê¸°ì„œ \\mathbf{F}_{\\text{ì™¸ë ¥}} = \\mathbf{0}ì¼ë•Œ \\mathbf{P} = \\text{ì¼ì •} ìž„ì„ ì•Œìˆ˜ ìžˆë‹¤. ì¦‰ ì–´ë–¤ ê³„ì— ìž‘ìš©í•˜ëŠ” ì•Œì§œ ì™¸ë ¥ì´ 0ì´ë©´, ê·¸ ê³„ì˜ ì´ìš´ë™ëŸ‰ì€ ì‹œê°„ì— ëŒ€í•´ ë³€í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ ì‚¬ì‹¤ì„ ìš´ë™ëŸ‰ ë³´ì¡´ ë²•ì¹™ì´ë¼ê³  í•œë‹¤."
  },
  {
    "objectID": "posts/conservation-law/index.html#ê°ìš´ë™ëŸ‰-ë³´ì¡´-ë²•ì¹™",
    "href": "posts/conservation-law/index.html#ê°ìš´ë™ëŸ‰-ë³´ì¡´-ë²•ì¹™",
    "title": "ë³´ì¡´ë²•ì¹™",
    "section": "ê°ìš´ë™ëŸ‰ ë³´ì¡´ ë²•ì¹™",
    "text": "ê°ìš´ë™ëŸ‰ ë³´ì¡´ ë²•ì¹™\nì¼ë°˜ì ìœ¼ë¡œ íž˜ \\mathbf{F}ê°€ ìž‘ìš©í•˜ëŠ” ìœ„ì¹˜ì˜ ìœ„ì¹˜ë²¡í„°ë¥¼ \\mathbf{r}ì´ë¼ê³  í•œë‹¤ë©´, ê·¸ ìœ„ì¹˜ì— ìžˆëŠ” ë¬¼ì²´ì— ìž‘ìš©í•˜ëŠ” í† í¬(ëŒë¦¼íž˜)ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì£¼ì–´ì§„ë‹¤.\n\n\\boldsymbol{\\tau} = \\mathbf{r} \\times \\mathbf{F}\n\në§Œì•½ ì´ íž˜ \\mathbf{F}ê°€ ê·¸ ìœ„ì¹˜ì— ìžˆëŠ” ë¬¼ì²´ì— ìž‘ìš©í•˜ëŠ” ì•Œì§œíž˜ì´ë¼ë©´, ë‰´í„´ ì œ 2ë²•ì¹™ì— ì˜í•´ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìžˆë‹¤.\n\n\\boldsymbol{\\tau} = \\mathbf{r} \\times \\frac{d\\mathbf{p}}{dt}\n\nê·¸ëŸ°ë° ë‹¤ìŒì´ ì„±ë¦½í•˜ë¯€ë¡œ\n\n\\begin{align*}\n\\frac{d}{dt} (\\mathbf{r} \\times \\mathbf{p}) & = \\frac{d\\mathbf{r}}{dt} \\times \\mathbf{p} + \\mathbf{r} \\times \\frac{d\\mathbf{p}}{dt} \\\\\n& = \\mathbf{v} \\times m\\mathbf{v} + \\mathbf{r} \\times \\frac{d\\mathbf{p}}{dt} \\\\\n& = \\mathbf{r} \\times \\frac{d\\mathbf{p}}{dt}\n\\end{align*}\n\nì•Œì§œíž˜ì— ì˜í•œ í† í¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìžˆë‹¤. ì´ë•Œ \\mathbf{l} = \\mathbf{r} \\times \\mathbf{p}ì€ ê°ìš´ë™ëŸ‰ì´ë‹¤.\n\n\\begin{align*}\n\\boldsymbol{\\tau} & = \\frac{d}{dt} (\\mathbf{r} \\times \\mathbf{p}) \\\\\n& = \\frac{d\\mathbf{l}}{dt}\n\\end{align*}\n\nì—¬ëŸ¬ ë¬¼ì²´ë¡œ ì´ë£¨ì–´ì§„ ê³„ì—ì„œ ê° ë¬¼ì²´ì— ëŒ€í•´, ë‰´í„´ ì œ 2ë²•ì¹™ì„ ë°˜ë³µì ìœ¼ë¡œ ì ìš©í•˜ë©´ ë‹¤ìŒì„ ì–»ëŠ”ë‹¤. ì´ë•Œ \\mathbf{F}_{\\text{ext}}ëŠ” ê³„ì— ëŒ€í•œ ì™¸ë ¥ì˜ ì´í•©ì´ê³ , \\mathbf{P}ëŠ” ê³„ ë‚´ë¶€ ë¬¼ì²´ë“¤ì˜ ìš´ë™ëŸ‰ì˜ ì´í•©ì´ë‹¤.\n\n\\mathbf{F}_{\\text{ext}} = \\frac{d\\mathbf{P}}{dt}\n\në”°ë¼ì„œ \\mathbf{F}_{\\text{ext}}ê°€ ìž‘ìš©í•˜ëŠ” ìœ„ì¹˜ì— ìž‘ìš©í•˜ëŠ” í† í¬ë¥¼ \\boldsymbol{\\tau}_{\\text{ext}}ë¼ê³  ì“´ë‹¤ë©´ ë‹¤ìŒì´ ì„±ë¦½í•œë‹¤. ì´ë•Œ \\mathbf{L}ì€ ê³„ ë‚´ë¶€ ë¬¼ì²´ë“¤ì˜ ê°ìš´ë™ëŸ‰ì˜ ì´í•©ì´ë‹¤.\n\n\\boldsymbol{\\tau}_{\\text{ext}} = \\frac{d\\mathbf{L}}{dt}\n\në”°ë¼ì„œ ì•Œì§œ ì™¸ë¶€ í† í¬ê°€ \\mathbf{0}ì´ë©´ ê³„ì˜ ì´ ê°ìš´ë™ëŸ‰ì€ ë³´ì¡´ë¨ì„ ì•Œ ìˆ˜ ìžˆê³ , ì´ë¥¼ ê°ìš´ë™ëŸ‰ ë³´ì¡´ ë²•ì¹™ì´ë¼ê³  í•œë‹¤."
  },
  {
    "objectID": "posts/CASA/index.html",
    "href": "posts/CASA/index.html",
    "title": "Imaging of HD163296 Using ALMA Data",
    "section": "",
    "text": "This post is based on a project conducted during the â€œRadio Astronomyâ€ lecture in 2024 by Professor Jongho Park at Kyung Hee University."
  },
  {
    "objectID": "posts/CASA/index.html#casa",
    "href": "posts/CASA/index.html#casa",
    "title": "Imaging of HD163296 Using ALMA Data",
    "section": "CASA",
    "text": "CASA\nWe use CASA for imaging of HD163296.\n\nCASA, the Common Astronomy Software Applications package, is the primary data processing software for the Atacama Large Millimeter/submillimeter Array (ALMA) and NSFâ€™s Karl G. Jansky Very Large Array (VLA), and is frequently used also for other radio telescopes.\n\n\nCASA Docs\nCASA Guides\n\nInstall CASA according to the instructions.\n$ casa --version\nCASA 6.6.1.17"
  },
  {
    "objectID": "posts/AG_wave/index.html",
    "href": "posts/AG_wave/index.html",
    "title": "Finding the Dispersion Relation of Acoustic-Gravity Waves Using SymPy",
    "section": "",
    "text": "This post is based on content from the â€œTopics in Magnetohydrodynamicsâ€ lecture in 2023 by Professor Tetsuya Magara at Kyung Hee University.\n\nObtaining the dispersion relation\nFirst, import SymPy and define the necessary symbols.\n\nfrom sympy import *\n\n\nrho, p, vx, vz = symbols(r'\\rho_1^{**} p_1^{**} v_{1x}^{**} v_{1z}^{**}')\nw, H, gamma = symbols(r'\\omega H \\gamma')\nrho0, p0, g0, cs0 = symbols(r'\\rho_0 p_0, g_0, c_{s0}')\nkx, kz = symbols(r'k_x k_z')\n\nTo obtain the dispersion relation for acoustic-gravity waves, we need to compute the determinant of the following matrix:\n\nA = Matrix([[-I*w, I*kx*rho0, (I*kz-1/(2*H))*rho0, 0],\n            [0, -I*w*rho0, 0, I*kx],\n            [g0, 0, -I*w*rho0, I*kz-1/(2*H)],\n            [I*w*(cs0**2), 0, ((gamma-1)/H)*p0, -I*w]])\n\n\nA\n\n\\displaystyle \\left[\\begin{matrix}- i \\omega & i \\rho_{0} k_{x} & \\rho_{0} \\left(i k_{z} - \\frac{1}{2 H}\\right) & 0\\\\0 & - i \\omega \\rho_{0} & 0 & i k_{x}\\\\g_{0} & 0 & - i \\omega \\rho_{0} & i k_{z} - \\frac{1}{2 H}\\\\i \\omega c_{s0}^{2} & 0 & \\frac{p_{0} \\left(\\gamma - 1\\right)}{H} & - i \\omega\\end{matrix}\\right]\n\n\nWe can easily calculate the determinant using SymPy. However, the resulting expression is too complex, so we need to simplify it.\n\ndetA = A.det()\ndetA\n\n\\displaystyle \\frac{4 H^{2} \\omega^{4} \\rho_{0}^{2} - 4 H^{2} \\omega^{2} \\rho_{0}^{2} c_{s0}^{2} k_{x}^{2} - 4 H^{2} \\omega^{2} \\rho_{0}^{2} c_{s0}^{2} k_{z}^{2} + 4 i H^{2} \\omega^{2} \\rho_{0}^{2} g_{0} k_{z} + 4 i H \\gamma \\omega^{2} \\rho_{0} k_{z} p_{0} + 4 H \\gamma \\rho_{0} g_{0} k_{x}^{2} p_{0} - 4 i H \\omega^{2} \\rho_{0}^{2} c_{s0}^{2} k_{z} - 2 H \\omega^{2} \\rho_{0}^{2} g_{0} - 4 i H \\omega^{2} \\rho_{0} k_{z} p_{0} - 4 H \\rho_{0} g_{0} k_{x}^{2} p_{0} - 2 \\gamma \\omega^{2} \\rho_{0} p_{0} + \\omega^{2} \\rho_{0}^{2} c_{s0}^{2} + 2 \\omega^{2} \\rho_{0} p_{0}}{4 H^{2}}\n\n\nAs a first step, we substitute the relations for the sound speed c_{s0} and the scale height H:\n\nc_{s0}^2 = \\gamma \\frac{p_0}{\\rho_0} = \\gamma g_0 H\n\n\nH = \\frac{p_0}{\\rho_0 g_0}\n\n\ndetA_subs = detA.subs(cs0**2, gamma*p0/rho0).subs(H, p0/(rho0*g0))\ndetA_subs\n\n\\displaystyle \\frac{\\rho_{0}^{2} g_{0}^{2} \\left(- \\gamma \\omega^{2} \\rho_{0} p_{0} - \\frac{4 \\gamma \\omega^{2} k_{x}^{2} p_{0}^{3}}{\\rho_{0} g_{0}^{2}} - \\frac{4 \\gamma \\omega^{2} k_{z}^{2} p_{0}^{3}}{\\rho_{0} g_{0}^{2}} + 4 \\gamma k_{x}^{2} p_{0}^{2} + \\frac{4 \\omega^{4} p_{0}^{2}}{g_{0}^{2}} - 4 k_{x}^{2} p_{0}^{2}\\right)}{4 p_{0}^{2}}\n\n\nNext, we factor out \\omega from this equation\n\ndetA_collect = collect(expand(detA_subs), w, factor)\ndetA_collect\n\n\\displaystyle - \\frac{\\gamma \\omega^{2} \\rho_{0} \\left(\\rho_{0}^{2} g_{0}^{2} + 4 k_{x}^{2} p_{0}^{2} + 4 k_{z}^{2} p_{0}^{2}\\right)}{4 p_{0}} + \\omega^{4} \\rho_{0}^{2} + \\rho_{0}^{2} g_{0}^{2} k_{x}^{2} \\left(\\gamma - 1\\right)\n\n\nand divide by \\rho_0^2.\n\nrho02 = (rho0**2)\ndetA_collect_ = collect(expand((detA_collect/rho02).cancel()), w, factor)\ndetA_collect_\n\n\\displaystyle - \\frac{\\gamma \\omega^{2} \\left(\\rho_{0}^{2} g_{0}^{2} + 4 k_{x}^{2} p_{0}^{2} + 4 k_{z}^{2} p_{0}^{2}\\right)}{4 \\rho_{0} p_{0}} + \\omega^{4} + g_{0}^{2} k_{x}^{2} \\left(\\gamma - 1\\right)\n\n\nNow, we examine the key coefficients:\n\nConstant term\n\n\nwc0 = detA_collect_.coeff(w, 0)\nwc0\n\n\\displaystyle g_{0}^{2} k_{x}^{2} \\left(\\gamma - 1\\right)\n\n\n\nCoefficient of \\omega^4\n\n\nwc4 = detA_collect_.coeff(w, 4)\nwc4\n\n\\displaystyle 1\n\n\n\nCoefficient of \\omega^2\n\n\nwc2_ = detA_collect_.coeff(w, 2)\nwc2_\n\n\\displaystyle - \\frac{\\gamma \\left(\\rho_{0}^{2} g_{0}^{2} + 4 k_{x}^{2} p_{0}^{2} + 4 k_{z}^{2} p_{0}^{2}\\right)}{4 \\rho_{0} p_{0}}\n\n\nWe substitute p_0 = \\rho_0 c_{s0}^2 for the coefficient of \\omega^2,\n\nwc2_subs = wc2_.subs(p0, (rho0*cs0**2)/gamma).cancel()\nwc2_subs\n\n\\displaystyle \\frac{- \\gamma^{2} g_{0}^{2} - 4 c_{s0}^{4} k_{x}^{2} - 4 c_{s0}^{4} k_{z}^{2}}{4 c_{s0}^{2}}\n\n\nfactor out c_{s0}^2,\n\nwc2 = collect(expand(wc2_subs), cs0**2, factor)\nwc2     \n\n\\displaystyle - \\frac{\\gamma^{2} g_{0}^{2}}{4 c_{s0}^{2}} + c_{s0}^{2} \\left(- k_{x}^{2} - k_{z}^{2}\\right)\n\n\nand multiply by -1.\n\n_wc2 = collect(expand((-wc2).cancel()), cs0**2, factor)\n_wc2\n\n\\displaystyle \\frac{\\gamma^{2} g_{0}^{2}}{4 c_{s0}^{2}} + c_{s0}^{2} \\left(k_{x}^{2} + k_{z}^{2}\\right)\n\n\nUsing the above coefficients, we rewrite the determinant of the matrix.\n\nexpr = Mul(rho02, Add(Mul(wc4, Pow(w, 4)), Mul(Integer(-1), Mul(_wc2, Pow(w, 2))), wc0))\nexpr\n\n\\displaystyle \\rho_{0}^{2} \\left(\\omega^{4} - \\omega^{2} \\left(\\frac{\\gamma^{2} g_{0}^{2}}{4 c_{s0}^{2}} + c_{s0}^{2} \\left(k_{x}^{2} + k_{z}^{2}\\right)\\right) + g_{0}^{2} k_{x}^{2} \\left(\\gamma - 1\\right)\\right)\n\n\nSince the dispersion relation is given by \\text{det}A = 0, we can divide by \\rho_0^2 for it.\n\ndispersion = Add(Mul(wc4, Pow(w, 4)), Mul(Integer(-1), Mul(_wc2, Pow(w, 2))), wc0)\ndispersion\n\n\\displaystyle \\omega^{4} - \\omega^{2} \\left(\\frac{\\gamma^{2} g_{0}^{2}}{4 c_{s0}^{2}} + c_{s0}^{2} \\left(k_{x}^{2} + k_{z}^{2}\\right)\\right) + g_{0}^{2} k_{x}^{2} \\left(\\gamma - 1\\right)\n\n\nThis is the dispersion relation of acoustic-gravity waves.\n\nEq(dispersion, 0)\n\n\\displaystyle \\omega^{4} - \\omega^{2} \\left(\\frac{\\gamma^{2} g_{0}^{2}}{4 c_{s0}^{2}} + c_{s0}^{2} \\left(k_{x}^{2} + k_{z}^{2}\\right)\\right) + g_{0}^{2} k_{x}^{2} \\left(\\gamma - 1\\right) = 0\n\n\nHere, we define two key frequencies of acoustic-gravity waves:\n\nacoustic cut-off frequency \n\\omega_a = \\frac{\\gamma g_0}{2 c_{s0}} = \\frac{c_{s0}}{2H}\n\nBruntâ€“VÃ¤isÃ¤lÃ¤ frequency \n\\omega_g = \\frac{\\sqrt{\\gamma-1}g_0}{c_{s0}} = \\frac{\\sqrt{\\gamma-1}}{\\gamma}\\frac{c_{s0}}{H}\n\n\nDefine symbols for the key frequencies.\n\nwa, wg = symbols(r'\\omega_a, \\omega_g')\n\nNow, we substitute g_0 = \\frac{2\\omega_a c_{s0}}{\\gamma} into the coefficient of \\omega^2,\n\ndis_w2 = dispersion.coeff(w, 2).subs(g0, 2*wa*cs0/gamma).cancel()\ndis_w2\n\n\\displaystyle - \\omega_{a}^{2} - c_{s0}^{2} k_{x}^{2} - c_{s0}^{2} k_{z}^{2}\n\n\nmultiply by -1, and factor out c_{s0}^2.\n\n_dis_w2 = collect(expand((-dis_w2).cancel()), cs0**2, factor)\n_dis_w2\n\n\\displaystyle \\omega_{a}^{2} + c_{s0}^{2} \\left(k_{x}^{2} + k_{z}^{2}\\right)\n\n\nNext, we substitut g_0 = \\frac{\\omega_g c_{s0}}{\\sqrt{\\gamma-1}} into the constant term.\n\ndis_w0 = dispersion.coeff(w, 0).subs(g0, wg*cs0/sqrt(gamma-1)).cancel()\ndis_w0\n\n\\displaystyle \\omega_{g}^{2} c_{s0}^{2} k_{x}^{2}\n\n\nFinally, we obtain the dispersion relation for acoustic-gravity waves.\n\ndispersion_ = Add(Mul(wc4, Pow(w, 4)), Mul(Integer(-1), Mul(_dis_w2, Pow(w, 2))), dis_w0)\ndispersion_\n\n\\displaystyle \\omega^{4} - \\omega^{2} \\left(\\omega_{a}^{2} + c_{s0}^{2} \\left(k_{x}^{2} + k_{z}^{2}\\right)\\right) + \\omega_{g}^{2} c_{s0}^{2} k_{x}^{2}\n\n\nFinally, we get the following dispersion relation for acoustic-gravity waves using \\omega_a and \\omega_g.\n\nEq(dispersion_, 0)\n\n\\displaystyle \\omega^{4} - \\omega^{2} \\left(\\omega_{a}^{2} + c_{s0}^{2} \\left(k_{x}^{2} + k_{z}^{2}\\right)\\right) + \\omega_{g}^{2} c_{s0}^{2} k_{x}^{2} = 0\n\n\n\n\nGraph for the dispersion relation\nWe consider k_x = k\\sin\\theta and k_z = k\\cos\\theta.\n\nk, theta = symbols(r'k \\theta')\nkx_sub = k * sin(theta)\nkz_sub = k * cos(theta)\n\nWe subsitute the above expressions and factor out c_{s0}^2k^2.\n\ndispersion_eq = dispersion_.subs({kx: kx_sub, kz: kz_sub})\ndispersion_eq = simplify(dispersion_eq)\ndispersion_eq = collect(expand(dispersion_eq), cs0**2*k**2)\ndispersion_eq\n\n\\displaystyle \\omega^{4} - \\omega^{2} \\omega_{a}^{2} + c_{s0}^{2} k^{2} \\left(- \\omega^{2} + \\omega_{g}^{2} \\sin^{2}{\\left(\\theta \\right)}\\right)\n\n\nWe divide by \\omega_g^2.\n\ndispersion_e = dispersion_eq / (wg**2)\ndispersion_e = collect(expand(dispersion_e), cs0**2*k**2)\ndispersion_e\n\n\\displaystyle \\frac{\\omega^{4}}{\\omega_{g}^{2}} - \\frac{\\omega^{2} \\omega_{a}^{2}}{\\omega_{g}^{2}} + c_{s0}^{2} k^{2} \\left(- \\frac{\\omega^{2}}{\\omega_{g}^{2}} + \\sin^{2}{\\left(\\theta \\right)}\\right)\n\n\nWe examine each term.\n\nConstant term\n\n\nconst_t = dispersion_e.coeff(cs0**2*k**2, 0)\nconst_t = collect(expand(const_t), w**2/wg**2, factor)\nconst_t\n\n\\displaystyle \\frac{\\omega^{2} \\left(\\omega - \\omega_{a}\\right) \\left(\\omega + \\omega_{a}\\right)}{\\omega_{g}^{2}}\n\n\n\ncoeff_const_t = const_t.coeff(w, 2)\ncoeff_const_t = expand(coeff_const_t)\ncoeff_const_t\n\n\\displaystyle \\frac{\\omega^{2}}{\\omega_{g}^{2}} - \\frac{\\omega_{a}^{2}}{\\omega_{g}^{2}}\n\n\n\na = Mul(wg**2, (w**2 / wg**2), evaluate=False)\na\n\n\\displaystyle \\omega_{g}^{2} \\frac{\\omega^{2}}{\\omega_{g}^{2}}\n\n\n\nconst_t = Mul(a, coeff_const_t, evaluate=False)\nconst_t\n\n\\displaystyle \\omega_{g}^{2} \\frac{\\omega^{2}}{\\omega_{g}^{2}} \\left(\\frac{\\omega^{2}}{\\omega_{g}^{2}} - \\frac{\\omega_{a}^{2}}{\\omega_{g}^{2}}\\right)\n\n\n\nCoefficient of c_{s0}^2k^2\n\n\ncoeff_cs0k2 = dispersion_e.coeff(cs0**2*k**2, 1)\ncoeff_cs0k2 = Mul(Pow(cs0*k, 2), -coeff_cs0k2)\ncoeff_cs0k2 = Mul(Integer(-1), coeff_cs0k2, evaluate=False)\ncoeff_cs0k2\n\n\\displaystyle - c_{s0}^{2} k^{2} \\left(\\frac{\\omega^{2}}{\\omega_{g}^{2}} - \\sin^{2}{\\left(\\theta \\right)}\\right)\n\n\nThen we obtain the following form.\n\ndispersion_eqq = Add(const_t, coeff_cs0k2)\ndispersion_eqq\n\n\\displaystyle - c_{s0}^{2} k^{2} \\left(\\frac{\\omega^{2}}{\\omega_{g}^{2}} - \\sin^{2}{\\left(\\theta \\right)}\\right) + \\omega_{g}^{2} \\frac{\\omega^{2}}{\\omega_{g}^{2}} \\left(\\frac{\\omega^{2}}{\\omega_{g}^{2}} - \\frac{\\omega_{a}^{2}}{\\omega_{g}^{2}}\\right)\n\n\nWhen we assume that c_{s0} =1, H=1, \\gamma=5/3, we can caluate \\omega_a and \\omega_g:\n\n\\omega_a = \\frac{c_{s0}}{2H}\n\n\n\\omega_g = \\frac{\\sqrt{\\gamma-1}g_0}{c_{s0}}\n\n\nwr = symbols(r'\\omega/\\omega_g')\nwr\n\n\\displaystyle \\omega/\\omega_{g}\n\n\n\nimport numpy as np\n\ncs0n = 1\nHn = 1\ngamman = 5/3\n\nwan = (1/2) * (cs0n/Hn)\nwgn = (np.sqrt(gamman-1)/gamman) * (cs0n/Hn)\n\nThen, we obtain an implicit equation for \\omega/\\omega_g, k, and \\theta.\n\nfunc = Eq(-cs0n**2 * k**2 * (wr**2 - sin(theta)**2) + wgn**2 * wr**2 * (wr**2 - (wan/wgn)**2) , 0)\nfunc\n\n\\displaystyle 0.24 \\omega/\\omega_{g}^{2} \\left(\\omega/\\omega_{g}^{2} - 1.04166666666667\\right) - k^{2} \\left(\\omega/\\omega_{g}^{2} - \\sin^{2}{\\left(\\theta \\right)}\\right) = 0\n\n\nWe consider the case where \\theta=0, \\theta=\\pi/4, or \\theta=\\pi/2.\n\nthetas = [[0, r'$\\theta = 0$'],\n          [np.pi/4, r'$\\theta = \\pi/4$'],\n          [np.pi/2, r'$\\theta = \\pi/2$']]\n\nFor each value of \\theta, we can plot the implicit equation in the k - \\omega/\\omega_g plane.\n\nfor thet in thetas:\n    plot_dict = dict(x_var=(k, 0, 3), y_var=(wr, 0, 3),\n                     aspect_ratio=(5, 5), show=False)\n\n    p1 = plot_implicit(func.subs({theta: thet[0]}), \n                       line_color='red', title= thet[1], **plot_dict)\n    p2 = plot_implicit(Eq(wr, 1),\n                       line_color='blue', **plot_dict)\n    p1.extend(p2)\n    p1.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe mode with \\omega/\\omega_g &gt; 1 is pressure-mode (p-mode) mainly driven by gas pressure.\nThe mode with \\omega/\\omega_g &lt; 1 is gravity-mode (g-mode) mainly driven by buoyancy."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a PhD student advised by Yong-Jae Moon in the Sun and Space Weather Laboratory at Kyung Hee University. My research interests are in solar physics and machine learning."
  },
  {
    "objectID": "about.html#mingyu-jeon-ì „ë¯¼ê·œ",
    "href": "about.html#mingyu-jeon-ì „ë¯¼ê·œ",
    "title": "About",
    "section": "",
    "text": "I am a PhD student advised by Yong-Jae Moon in the Sun and Space Weather Laboratory at Kyung Hee University. My research interests are in solar physics and machine learning."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mingyu Jeonâ€™s Blog",
    "section": "",
    "text": "Reproducing Figure 1 of the 2023 SunPy Paper in 2025\n\n\n\nsolar physics\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nAug 6, 2025\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nSHARP Data Guide (1)\n\n\n\nsolar physics\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nAug 1, 2025\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nImaging of HD163296 Using ALMA Data\n\n\n\nastronomy\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nFeb 23, 2025\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nFinding the Dispersion Relation of Acoustic-Gravity Waves Using SymPy\n\n\n\nphysics\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nFeb 22, 2025\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nA collection of resources on pendulum\n\n\n\nphysics\n\nenglish\n\n\n\n\n\n\n\n\n\nNov 30, 2024\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone\n\n\n\ndeep learning\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nAug 31, 2024\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nThe double pendulum problem in Julia\n\n\n\nphysics\n\njulia\n\nenglish\n\n\n\n\n\n\n\n\n\nAug 30, 2024\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nThe double pendulum problem in Python\n\n\n\nphysics\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nAug 29, 2024\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nLow and Lou (1990) force free magnetic fields\n\n\n\nsolar physics\n\nenglish\n\n\n\n\n\n\n\n\n\nMar 30, 2024\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nSolar Eruptions & Magnetic Fields\n\n\n\nsolar physics\n\nenglish\n\n\n\n\n\n\n\n\n\nMar 9, 2024\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nThe very, very basics of gravitational wave\n\n\n\nphysics\n\nenglish\n\n\n\n\n\n\n\n\n\nDec 25, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nVisualization of ISEE Nonlinear Force-Free Field of Solar Active Regions in Python\n\n\n\nsolar physics\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nNov 12, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating Derivatives of a 1D Scalar Function in Python\n\n\n\nmath\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nNov 4, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nSpherical Astronomy\n\n\n\nastronomy\n\nenglish\n\n\n\n\n\n\n\n\n\nOct 22, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nì²œë¬¸ìš©ì–´ ì„¤ëª…\n\n\n\nastronomy\n\nkorean\n\n\n\n\n\n\n\n\n\nOct 21, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Draw 1D Scalar Functions in Python\n\n\n\nmath\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nOct 20, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\në³´ì¡´ë²•ì¹™\n\n\n\nphysics\n\nkorean\n\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nMotion of Charged Particles in Magnetic Dipole Fields\n\n\n\nphysics\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nSep 25, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nStable Diffusion Inference with Diffusers (low-level)\n\n\n\ndeep learning\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nSep 10, 2023\n\n\nMingyu Jeon\n\n\n\n\n\n\n\n\n\n\n\n\nStable Diffusion Inference with Diffusers (high-level)\n\n\n\ndeep learning\n\npython\n\nenglish\n\n\n\n\n\n\n\n\n\nSep 9, 2023\n\n\nMingyu Jeon\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/baisc_GWs/index.html",
    "href": "posts/baisc_GWs/index.html",
    "title": "The very, very basics of gravitational wave",
    "section": "",
    "text": "This post is based on content from the â€œRelativistic Astrophysicsâ€ lecture in 2023 by Professor Gwangson Choe at Kyung Hee University."
  },
  {
    "objectID": "posts/baisc_GWs/index.html#sign-conventions-and-notations",
    "href": "posts/baisc_GWs/index.html#sign-conventions-and-notations",
    "title": "The very, very basics of gravitational wave",
    "section": "Sign conventions and notations",
    "text": "Sign conventions and notations\nI use the following sign conventions (Misner, Thorne, and Wheeler 1973) and notations.\n\npartial derivative\n\n\n\\partial_{\\mu} = \\frac{\\partial}{\\partial x^{\\mu}}\n\n\n(- + + +) metric signature\n\nFor example, the Minkowski metric \\eta_{\\mu \\nu} in the Cartesian coordinates is written as the following matrix form. \n[\\eta_{\\mu \\nu}] = [\\eta^{\\mu \\nu}] = \\begin{bmatrix}\n-1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n\\end{bmatrix}\n\nThe general metric tensor is denoted by g_{\\mu \\nu}.\n\nChristoffel symbol\n\n\n\\Gamma^{\\sigma}{}_{\\mu \\nu} = \\frac{1}{2} g^{\\sigma \\alpha}(\\partial_{\\mu} g_{\\alpha \\nu} + \\partial_{\\nu} g_{\\alpha \\mu} - \\partial_{\\alpha} g_{\\mu \\nu})\n\n\nRiemann curvature tensor\n\n\nR^{\\mu}{}_{\\nu \\alpha \\beta} = \\partial_{\\alpha} \\Gamma^{\\mu}{}_{\\nu \\beta} - \\partial_{\\beta} \\Gamma^{\\mu}{}_{\\nu \\alpha} + \\Gamma^{\\mu}{}_{\\sigma \\alpha}\\Gamma^{\\sigma}{}_{\\nu \\beta} - \\Gamma^{\\mu}{}_{\\sigma \\beta}\\Gamma^{\\sigma}{}_{\\nu \\alpha}\n\n\nRicci tensor\n\n\nR_{\\mu \\nu} = R^{\\alpha}{}_{\\mu \\alpha \\nu}\n\n\nRicci scalar\n\n\nR = R^{\\alpha}{}_{\\alpha}\n\n\nEinstein tensor\n\n\nG_{\\mu \\nu} = R_{\\mu \\nu} - \\frac{1}{2} R g_{\\mu \\nu}\n\n\nFour-velocity\n\nIn Minkowski space with the Cartesian coordinates, \n[U^{\\mu}] = \\begin{bmatrix}\n\\gamma c \\\\\n\\gamma u_{x} \\\\\n\\gamma u_{y} \\\\\n\\gamma u_{z} \\\\\n\\end{bmatrix}\n\nHere, the Lorentz factor is denoted by \\displaystyle \\gamma = \\frac{1}{\\sqrt{1-\\frac{u^2}{c^2}}} and u^2 = u_{x}^2 + u_{y}^2 + u_{z}^2.\n\nEnergy-momentum tensor\n\nperfect fluid\n\n  T^{\\mu \\nu} = \\left(\\rho_{0} + \\frac{p}{c^2}\\right)U^{\\mu}U^{\\nu} + p g^{\\mu \\nu}\n  \n\nHere, \\rho_{0} is the rest mass denstiy and \\rho = \\gamma^2 \\rho_{0} is the relativistic mass density.\n\ndust (p=0)\n\n  T^{\\mu \\nu} = \\rho_{0} U^{\\mu}U^{\\nu}\n  \n\nIn this case, T^{00} = \\rho c^2."
  },
  {
    "objectID": "posts/baisc_GWs/index.html#linearized-gravity",
    "href": "posts/baisc_GWs/index.html#linearized-gravity",
    "title": "The very, very basics of gravitational wave",
    "section": "Linearized gravity",
    "text": "Linearized gravity\nThe Einstein Field Equation (EFE) is\n\nG_{\\mu \\nu} + \\Lambda g_{\\mu \\nu} = \\frac{8 \\pi G}{c^{4}}T_{\\mu \\nu}\n\nwhere \\Lambda is the cosmological constant.\nIn the linearized gravity, we ignore the cosmological constant, i.e.Â \\Lambda = 0.\nThen, EFE is\n\nG_{\\mu \\nu} = \\frac{8 \\pi G}{c^{4}}T_{\\mu \\nu}\n\nConsider the small perturbation h_{\\mu \\nu} of the metric.\n\ng_{\\mu \\nu} = \\eta_{\\mu \\nu} + h_{\\mu \\nu}, \\qquad |h_{\\mu \\nu}| \\ll 1\n\nFor convenience, we define the following two quantities.\n\nh = \\eta^{\\mu \\nu} h_{\\mu \\nu}\n\n\n\\bar{h}_{\\mu \\nu} = h_{\\mu \\nu} - \\frac{1}{2} \\eta_{\\mu \\nu} h\n\nAlso, we use the Lorenz gauge condition \\partial_{\\mu} \\bar{h}^{\\mu}{}_{\\nu} = 0.\nAfter many calculations, we get the following linearized EFE in the Lorenz gauge.\n\n\\Box \\bar{h}_{\\mu \\nu} = - \\frac{16 \\pi G}{c^4} T_{\\mu \\nu}\n\nHere, \\Box = \\eta^{\\mu \\nu}\\partial_{\\mu}\\partial_{\\nu} = \\partial^{\\nu} \\partial_{\\nu} is the dâ€™Alembertian.\nThis is the wave equation.\nIn electrodynamics, the Maxwell equation in the Lorenz gauge \\partial_{\\mu}A^{\\mu}=0 in the Gaussian units is\n\n\\Box A^{\\mu} = -\\frac{4 \\pi}{c} J^{\\mu}\n\nHere, A^{\\mu} is the four-potential and J^{\\mu} is the four-current.\nAs you can see, the form of the linearized EFE is very similar to that of the Maxwell equation which predicts electromagnetic waves. Therefore, we can expect the existence of gravitational waves. The theory of gravitational waves in linearized gravity is also very similar to that of electromagnetic waves. For these reasons, Landau and Lifshitz wrote the famous physics textbook â€œThe Classical Theory of Fieldsâ€ which covers both electrodynamics and relativity."
  },
  {
    "objectID": "posts/charged-particle-motion-in-dipole/index.html",
    "href": "posts/charged-particle-motion-in-dipole/index.html",
    "title": "Motion of Charged Particles in Magnetic Dipole Fields",
    "section": "",
    "text": "This post is based on the homework report from the â€œSolar-Terrestrial Physicsâ€ lecture in 2022 by Professor Dong-Hun Lee at Kyung Hee University."
  },
  {
    "objectID": "posts/charged-particle-motion-in-dipole/index.html#theory",
    "href": "posts/charged-particle-motion-in-dipole/index.html#theory",
    "title": "Motion of Charged Particles in Magnetic Dipole Fields",
    "section": "Theory",
    "text": "Theory\n\nDipole Magnetic field\n\n\\mathbf{B} = -\\frac{\\mu_0}{4\\pi}\\left( \\frac{\\mathbf{m}}{r^3} - \\frac{3(\\mathbf{m}\\cdot\\mathbf{r})\\mathbf{r}}{r^5} \\right)\n\nIn (r, \\lambda, \\phi) coordinates, we describe the magnetic field as follows:\n\nB_r = Z = -\\frac{\\mu_0 m}{2\\pi}\\frac{\\sin\\lambda}{r^3}\n\n\nB_\\lambda = H = \\frac{\\mu_0 m}{4\\pi}\\frac{\\cos\\lambda}{r^3}\n\n\nB_\\phi = 0\n\nTherefore, the magnetic field \\mathbf{B} does not depend on longitude \\phi.\n\n\\mathbf{B} = \\mathbf{B}(r, \\lambda)\n\nThe strength B is given by:\n\nB = \\frac{\\mu_0 m}{4\\pi r^3}(1+3\\sin^2\\lambda)^{\\textstyle \\frac{1}{2}}\n\nFor the Earthâ€™s magnetic field at the equator, denoted as B_E, it can be expressed as:\n\nB_E = \\frac{\\mu_0 m}{4\\pi R_E^3}\n\nThe actual value for B_E is approximately 0.31 Gauss (G).\nThe components of the magnetic field can be re-express in terms of B_E as follows:\n\nB_r = -\\frac{2B_E}{(r/R_E)^3}\\sin\\lambda\n\n\nB_\\lambda = \\frac{B_E}{(r/R_E)^3}\\cos\\lambda\n\n\nB_\\phi = 0\n\nThe magnetic field line in the meridian (when \\phi=\\text{const} or in the (r,\\lambda)-plane) is given by:\n\nr = r_\\text{eq} \\cos^2\\lambda\n\nHere, r_\\text{eq} = LR_E and L is called L-parameter.\n\nL-parameter describes the set of magnetic field lines which cross the Earthâ€™s magnetic equator at a number of Earth-radii equal to the L-parameter. For example, L=2 describes the set of the Earthâ€™s magnetic field lines which cross the Earthâ€™s magnetic equator two earth radii from the center of the Earth.1\n\n\nThe dipole model of the Earthâ€™s magnetic field is a first order approximation of the rather complex true Earthâ€™s magnetic field. Due to effects of the interplanetary magnetic field (IMF), and the solar wind, the dipole model is particularly inaccurate at high L-shells (e.g., above L=3), but may be a good approximation for lower L-shells. For more precise work, or for any work at higher L-shells, a more accurate model that incorporates solar effects, such as the Tsyganenko magnetic field model, is recommended.2\n\n\n\\begin{align*}\n\\mathbf{B}(\\mathbf{r}) & = B_r(r, \\lambda) \\hat{r} + B_\\lambda (r, \\lambda) \\hat{\\lambda} \\\\\n& = B_x(x, y)\\hat{x} + B_y(x, y)\\hat{y}\n\\end{align*}\n\n\n\nNewtonâ€™s equation of motion for a charged particle in magnetic field\n\n\\frac{d^2\\mathbf{r}}{dt^2} = \\frac{q}{m}\\mathbf{v}\\times\\mathbf{B}\n\n\n\\frac{d^2x}{dt^2}\\hat{x} + \\frac{d^2y}{dt^2}\\hat{y} + \\frac{d^2z}{dt^2}\\hat{z} = \\frac{q}{m}(\\hat{x}(v_yB_z - v_zB_y) + \\hat{y}(v_zB_x - v_xB_z) + \\hat{z}(v_xB_y - v_yB_x))\n\n\n\\frac{d^2x}{dt^2} = \\frac{q}{m}(v_yB_z - v_zB_y)\n\n\n\\frac{d^2y}{dt^2} = \\frac{q}{m}(v_zB_x - v_xB_z)\n\n\n\\frac{d^2z}{dt^2} = \\frac{q}{m}(v_xB_y - v_yB_x)\n\n\n\nThe coupled 1st ODEs\n\n\\frac{dx}{dt} = v_x\n\n\n\\frac{dy}{dt} = v_y\n\n\n\\frac{dz}{dt} = v_z\n\n\n\\frac{dv_x}{dt} = \\frac{q}{m}(v_yB_z - v_zB_y)\n\n\n\\frac{dv_y}{dt} = \\frac{q}{m}(v_zB_x - v_xB_z)\n\n\n\\frac{dv_z}{dt} = \\frac{q}{m}(v_xB_y - v_yB_x)\n\n\n\nThe state vector for odeint\n\nS = (x, y, z, v_x, v_y, v_z)\n\n\n\\frac{dS}{dt} = (\\frac{dx}{dt}, \\frac{dy}{dt}, \\frac{dz}{dt}, \\frac{dv_x}{dt}, \\frac{dv_y}{dt},\\frac{dv_z}{dt})"
  },
  {
    "objectID": "posts/charged-particle-motion-in-dipole/index.html#code",
    "href": "posts/charged-particle-motion-in-dipole/index.html#code",
    "title": "Motion of Charged Particles in Magnetic Dipole Fields",
    "section": "Code",
    "text": "Code\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom matplotlib.animation import FuncAnimation\n\n\n# Be = 0.31 G = 0.31 * 10^-4 T\nBe = 0.31 * 1e-4\n# Re = 6371 km = 6371 * 10^3 m\nRe = 6371 * 1e3\nC = Be * (Re**3)\n\n\ndef B(x, y, z):\n    \"\"\"dipole field at (x, y, z)\"\"\"\n    r = np.sqrt(x**2 + y**2 + z**2)\n    Bx = -1 * C * (3 * x * z) / (r**5)\n    By = -1 * C * (3 * y * z) / (r**5)\n    Bz = C * (r**2 - 3 * z**2) / (r**5)\n    return Bx, By, Bz\n\n\ndef field_line_3D(phi, L=6.6):\n    \"\"\"dipole field line (3D)\"\"\"\n    phi = np.deg2rad(phi)\n    theta = np.linspace(0, 2 * np.pi, 1000)\n    rf = L * np.sin(theta) ** 2\n    xf = rf * np.sin(theta) * np.cos(phi)\n    yf = rf * np.sin(theta) * np.sin(phi)\n    zf = rf * np.cos(theta)\n    return xf, yf, zf\n\n\ndef field_line_2D(L=6.6):\n    \"\"\"dipole field line (2D)\"\"\"\n    lamb = np.linspace(0, 2 * np.pi, 1000)\n    rf2 = L * np.cos(lamb) ** 2\n    xf2 = rf2 * np.cos(lamb)\n    zf2 = rf2 * np.sin(lamb)\n    return xf2, zf2\n\n\ndef dSdt(S, t, q_over_m):\n    \"\"\"dS/dt for odeint\"\"\"\n    x, y, z, vx, vy, vz = S\n    Bx, By, Bz = B(x, y, z)\n    dvxdt = q_over_m * (vy * Bz - vz * By)\n    dvydt = q_over_m * (vz * Bx - vx * Bz)\n    dvzdt = q_over_m * (vx * By - vy * Bx)\n    return [vx, vy, vz, dvxdt, dvydt, dvzdt]\n\n\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot()\nxmin, xmax = -7, 7\nymin, ymax = -7, 7\n\nax.add_patch(\n    plt.Circle(\n        (0, 0), 1, zorder=99, facecolor=\"white\", edgecolor=\"black\", label=\"Earth\"\n    )\n)\nax.set_aspect(\"equal\")\nax.legend()\nax.axhline(y=0, color=\"black\", linewidth=0.5)\nax.xaxis.grid(True, which=\"both\")\nax.set_xlim(xmin, xmax)\nax.set_ylim(ymin, ymax)\nmajors = np.arange(xmin + 1, xmax, 1)\nax.xaxis.set_major_locator(ticker.FixedLocator(majors))\nax.set_xlabel(\"x ($R_E$)\")\nax.set_ylabel(\"z ($R_E$)\")\n\nLvalues = [2, 4, 6, 8, 10, 20, 100]\ncolors = [\"r\", \"darkorange\", \"gold\", \"green\", \"blue\", \"magenta\", \"purple\"]\nlamb = np.linspace(0, 2 * np.pi, 1000)\nfor i, L in enumerate(Lvalues):\n    x, z = field_line_2D(L)\n    ax.plot(x, z, label=f\"L={L}\", color=colors[i])\n\nax.legend()\nax.set_title(\"Magnetic Dipole Field line (2D)\")\nplt.show()\n\n\n\n\n\n\n\n\n\nspecies = \"Proton\"\n\ne = 1.602e-19\nq = e  # C\n\nmH = 1.67e-27\nm = mH  # kg\nq_over_m = q / m\n\nE_keV = 2000  # keV\n\n\n# L-parameter\nL = 6.6\n\n# start at equator\nx0, y0, z0 = L * Re, 0, 0\n\nkeV_to_J = 1e3 * e  # J\n\n# particle energy (keV) and pitch angle\nE = E_keV * keV_to_J  # J\npitch_angle_deg = 30\nalpha = np.deg2rad(pitch_angle_deg)\n\n# particle velocity\nv0 = np.sqrt(2 * E / m)\n\n# vx = v_perp\n# vy = 0\n# vz = v_para\nvx0 = v0 * np.sin(alpha)\nvy0 = 0\nvz0 = v0 * np.cos(alpha)\n\n# bounce time_scale\nt_B = 290 * (np.pi * L / 10) * np.sqrt(m / (mH * E_keV))\nprint(f\"bounce time scale ~ {t_B} s\")\n\nS0 = [x0, y0, z0, vx0, vy0, vz0]\n\n# number of bounce\nn = 3\n\ntmin = 0\ntmax = n * t_B\n\nt = np.linspace(tmin, tmax, 1000)\n\n# solve ODE\nsol = odeint(dSdt, S0, t, args=(q_over_m,))\nx, y, z, vx, vy, vz = sol.T\nx, y, z = x / Re, y / Re, z / Re\n\nprint(f\"t_max ~ {tmax:.4f} s\")\n\nbounce time scale ~ 13.44549539521195 s\nt_max ~ 40.3365 s\n\n\n\ntrajectory_linewidth = 0.8\nfieldline_linewidth = 0.5\n\n\n# xyzrange = 10\n\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot(projection=\"3d\")\nax.set_aspect(\"equal\")\n# ax.plot([-xyzrange,xyzrange], [0,0], [0, 0], color='black')\n# ax.plot([0,0], [-xyzrange,xyzrange], [0, 0], color='black')\n# ax.plot([0,0], [0,0], [-xyzrange, xyzrange], color='black')\nax.plot(\n    x,\n    y,\n    z,\n    color=\"red\",\n    label=\"Particle Trajectory\",\n    linewidth=trajectory_linewidth,\n    zorder=200,\n)\nax.set_xlabel(\"x ($R_E$)\")\nax.set_ylabel(\"y ($R_E$)\")\nax.set_zlabel(\"z ($R_E$)\")\nax.set_xlim(-L, L)\nax.set_ylim(-L, L)\nax.set_zlim(-L, L)\nfor az in np.arange(0, 361, 20):\n    xf, yf, zf = field_line_3D(az, L)\n    if az == 360:\n        ax.plot(\n            xf,\n            yf,\n            zf,\n            color=\"blue\",\n            linewidth=fieldline_linewidth,\n            zorder=-1,\n            label=f\"Magnetic Field (L={L})\",\n        )\n    else:\n        ax.plot(xf, yf, zf, color=\"blue\", linewidth=fieldline_linewidth, zorder=-1)\n\n# Sphere with radius Re\nu = np.linspace(0, 2 * np.pi, 1000)\nv = np.linspace(0, np.pi, 1000)\nxs = 1 * np.outer(np.cos(u), np.sin(v))\nys = 1 * np.outer(np.sin(u), np.sin(v))\nzs = 1 * np.outer(np.ones(np.size(u)), np.cos(v))\nax.set_title(\n    f\"{species}, E = {E_keV/1000:.0f} MeV, initial pitch angle = {pitch_angle_deg} deg\"\n)\nax.plot_surface(xs, ys, zs, color=\"white\", alpha=1)\nax.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot()\nax.set_aspect(\"equal\")\nax.add_patch(\n    plt.Circle(\n        (0, 0), 1, zorder=99, facecolor=\"white\", edgecolor=\"black\", label=\"Earth\"\n    )\n)\nax.plot([-10, 10], [0, 0], color=\"black\")\nax.plot([0, 0], [-10, 10], color=\"black\")\nax.plot(\n    x,\n    y,\n    color=\"red\",\n    label=\"Particle Trajectory\",\n    linewidth=trajectory_linewidth,\n    zorder=200,\n)\nax.set_xlabel(\"x ($R_E$)\")\nax.set_ylabel(\"y ($R_E$)\")\nax.set_xlim(-L - 1, L + 1)\nax.set_ylim(-L - 1, L + 1)\ntheta = np.linspace(0, 2 * np.pi, 100)\nrc = L\nxc = rc * np.cos(theta)\nyc = rc * np.sin(theta)\nplt.plot(xc, yc, color=\"green\", zorder=-1, label=f\"Circle with radius L={L}\")\nax.set_title(\n    f\"{species}, E = {E_keV/1000:.0f} MeV, initial pitch angle = {pitch_angle_deg} deg\"\n)\nax.legend(loc=1)\nplt.show()\n\n\n\n\n\n\n\n\n\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot()\nax.add_patch(\n    plt.Circle(\n        (0, 0), 1, zorder=99, facecolor=\"white\", edgecolor=\"black\", label=\"Earth\"\n    )\n)\nax.set_aspect(\"equal\")\nax.plot([-10, 10], [0, 0], color=\"black\")\nax.plot([0, 0], [-10, 10], color=\"black\")\nax.plot(\n    x,\n    z,\n    color=\"red\",\n    label=\"Particle Trajectory\",\n    linewidth=trajectory_linewidth,\n    zorder=200,\n)\nax.set_xlabel(\"x ($R_E$)\")\nax.set_ylabel(\"z ($R_E$)\")\nax.set_xlim(-L - 1, L + 1)\nax.set_ylim(-L - 1, L + 1)\n\nxf2, zf2 = field_line_2D(L)\nax.plot(xf2, zf2, zorder=-1, color=\"blue\", label=f\"Magnetic field line (L={L})\")\nax.set_title(\n    f\"{species}, E = {E_keV/1000:.0f} MeV, initial pitch angle = {pitch_angle_deg} deg\"\n)\nax.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot()\nax.add_patch(\n    plt.Circle(\n        (0, 0), 1, zorder=99, facecolor=\"white\", edgecolor=\"black\", label=\"Earth\"\n    )\n)\nax.set_aspect(\"equal\")\nax.plot([-10, 10], [0, 0], color=\"black\")\nax.plot([0, 0], [-10, 10], color=\"black\")\nax.plot(\n    x,\n    z,\n    color=\"red\",\n    label=\"Particle Trajectory\",\n    linewidth=trajectory_linewidth,\n    zorder=200,\n)\nax.set_xlabel(\"x ($R_E$)\")\nax.set_ylabel(\"z ($R_E$)\")\nax.set_xlim(-L - 1, L + 1)\nax.set_ylim(-L - 1, L + 1)\n\nxf2, zf2 = field_line_2D(L)\nax.plot(xf2, zf2, zorder=-1, color=\"blue\", label=f\"Magnetic field line (L={L})\")\nax.set_title(\n    f\"{species}, E = {E_keV/1000:.0f} MeV, initial pitch angle = {pitch_angle_deg} deg\"\n)\nax.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nfig = plt.figure(figsize=(16, 8))\nax1 = plt.subplot(121)\nax2 = plt.subplot(122, projection=\"3d\")\n\nxdata = x\nydata = y\nzdata = z\n\nsc1 = ax1.scatter([], [], color=\"green\")\n(ln1,) = ax1.plot([], [], \"r-\", zorder=99)\nsc2 = ax2.scatter([], [], [], color=\"green\")\n(ln2,) = ax2.plot([], [], [], \"r-\", zorder=99)\n\n# Field line (2D)\nxf2, zf2 = field_line_2D(L)\nax1.plot(xf2, zf2, zorder=-1, color=\"blue\", label=f\"Magnetic field line (L={L})\")\n\n# Earth (2D)\nax1.add_patch(plt.Circle((0, 0), 1, zorder=99, facecolor=\"white\", edgecolor=\"black\"))\n\n# Field line (3D)\nfor az in np.arange(0, 361, 20):\n    xf, yf, zf = field_line_3D(az, L)\n    if az == 360:\n        ax2.plot(\n            xf,\n            yf,\n            zf,\n            color=\"blue\",\n            linewidth=fieldline_linewidth,\n            zorder=-1,\n            label=f\"Magnetic Field (L={L})\",\n        )\n    else:\n        ax2.plot(xf, yf, zf, color=\"blue\", linewidth=fieldline_linewidth, zorder=-1)\n\n# Earth (3D)\nu = np.linspace(0, 2 * np.pi, 1000)\nv = np.linspace(0, np.pi, 1000)\nxs = 1 * np.outer(np.cos(u), np.sin(v))\nys = 1 * np.outer(np.sin(u), np.sin(v))\nzs = 1 * np.outer(np.ones(np.size(u)), np.cos(v))\nax2.plot_surface(xs, ys, zs, color=\"white\", alpha=1)\n\n\ndef init():\n    ax1.set_aspect(\"equal\")\n    ax1.plot([-10, 10], [0, 0], color=\"black\")\n    ax1.plot([0, 0], [-10, 10], color=\"black\")\n    ax1.set_xlabel(\"x ($R_E$)\")\n    ax1.set_ylabel(\"z ($R_E$)\")\n    ax1.set_xlim(-L - 1, L + 1)\n    ax1.set_ylim(-L - 1, L + 1)\n\n    ax2.set_aspect(\"equal\")\n    ax2.plot([-10, 10], [0, 0], [0, 0], color=\"black\")\n    ax2.plot([0, 0], [-10, 10], [0, 0], color=\"black\")\n    ax2.plot([0, 0], [0, 0], [-10, 10], color=\"black\")\n    ax2.set_xlabel(\"x ($R_E$)\")\n    ax2.set_ylabel(\"y ($R_E$)\")\n    ax2.set_zlabel(\"z ($R_E$)\")\n    ax2.set_xlim(-L, L)\n    ax2.set_ylim(-L, L)\n    ax2.set_zlim(-L, L)\n\n    return ln1, ln2\n\n\ndef update(frame):\n    sc1.set_offsets([xdata[frame - 1], zdata[frame - 1]])\n    ln1.set_data(xdata[:frame], zdata[:frame])\n    ln1.set_label(f\"t={frame}\")\n    ax1.legend()\n\n    sc2._offsets3d = ([xdata[frame - 1]], [ydata[frame - 1]], [zdata[frame - 1]])\n    ln2.set_data(xdata[:frame], ydata[:frame])\n    ln2.set_3d_properties(zdata[:frame])\n    ln2.set_label(f\"t={frame}\")\n    ax2.legend()\n    return ln1, ln2\n\n\nani = FuncAnimation(\n    fig, update, frames=np.arange(1, len(xdata)), init_func=init, blit=True\n)\n\nani.save(\"simulation.gif\", fps=30)\n\n\n\nani.save(\"simulation.mp4\", fps=30)"
  },
  {
    "objectID": "posts/charged-particle-motion-in-dipole/index.html#footnotes",
    "href": "posts/charged-particle-motion-in-dipole/index.html#footnotes",
    "title": "Motion of Charged Particles in Magnetic Dipole Fields",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://en.wikipedia.org/wiki/L-shellâ†©ï¸Ž\nhttps://en.wikipedia.org/wiki/Dipole_model_of_the_Earth%27s_magnetic_fieldâ†©ï¸Ž"
  },
  {
    "objectID": "posts/derivative-of-1d-scalar-function/index.html",
    "href": "posts/derivative-of-1d-scalar-function/index.html",
    "title": "Calculating Derivatives of a 1D Scalar Function in Python",
    "section": "",
    "text": "There are four techniques to compute derivatives: hand-coded analytical derivative, finite differentiation, symbolic differentiation, and automatic differentiation (Margossian 2019). In this post, I will demonstrate how to find the derivative of a simple 1D scalar function, f(x) = x^2 + \\sin(3x), using each of these four methods in Python within the interval x \\in [0, \\pi]."
  },
  {
    "objectID": "posts/derivative-of-1d-scalar-function/index.html#hand-coded-analytical-derivative",
    "href": "posts/derivative-of-1d-scalar-function/index.html#hand-coded-analytical-derivative",
    "title": "Calculating Derivatives of a 1D Scalar Function in Python",
    "section": "1 Hand-coded analytical derivative",
    "text": "1 Hand-coded analytical derivative\nYou can find the analytical derivative of the fucntion f(x) = x^2 + \\sin(3x) using the table of derivatives learned in your Calculus course.\n\n\\begin{align*}\n\\frac{d}{dx} f(x) & = \\frac{d}{dx} (x^2 + \\sin(3x)) \\\\\n& = \\frac{d}{dx} x^2 + \\frac{d}{dx} \\sin(3x) \\\\\n& = 2x + 3\\cos(3x)\n\\end{align*}\n\nThus, for every x,\n\nf'(x) = 2x + 3\\cos(3x)\n\nAccording to the previous post where I explained how to draw a 1D scalar function in Python, I will plot f(x) and its derivative f'(x) using Matplotlib.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.rcParams.update({\n    \"text.usetex\": True,\n    \"font.family\": \"Helvetica\",\n    \"font.size\": 15,\n    \"figure.figsize\": (8, 6)\n})\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfunc = lambda x: x**2 + np.sin(3*x)\nd_func = lambda x: 2*x + 3*np.cos(3*x)\n\nx = np.linspace(0, np.pi, 100)\nf = func(x)\ndf_dx = d_func(x)\n\nplt.plot(x, f, label=r\"$f(x)$\")\nplt.plot(x, df_dx, label=r\"$f'(x)$\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/derivative-of-1d-scalar-function/index.html#finite-differentiation",
    "href": "posts/derivative-of-1d-scalar-function/index.html#finite-differentiation",
    "title": "Calculating Derivatives of a 1D Scalar Function in Python",
    "section": "2 Finite differentiation",
    "text": "2 Finite differentiation\nYou can derive the following finite differentiation formulae using Taylorâ€™s theorem.\n\n2.1 Finite differentiation formulae\n\nForward difference\n\n1st order accuracy \n  f'(x) = \\frac{f(x+h) - f(x)}{h} + \\mathcal{O}(h)\n  \n2nd order accuracy \n  f'(x) = \\frac{-3f(x) + 4f(x+h) - f(x+2h)}{2h} + \\mathcal{O}(h^2)\n  \n\nBackward difference\n\n1st order accuracy \n  f'(x) = \\frac{f(x) - f(x-h)}{h} + \\mathcal{O}(h)\n  \n2nd order accuracy \n  f'(x) = \\frac{3f(x) - 4f(x-h) + f(x-2h)}{2h} + \\mathcal{O}(h^2)\n  \n\nCentral difference\n\n2nd order accuracy \n  f'(x) = \\frac{f(x+h) - f(x-h)}{2h} + \\mathcal{O}(h^2)\n  \n\n\n\n\n2.2 Implementation using NumPy\nNumPy arrays make the implementation of finite differentitation very straightforward. Itâ€™s important to note that at the left boundary (x=0), I use the forward difference, while at the right boundary (x=\\pi), I use the backward difference. Within the domain (0&lt;x&lt;\\pi), I use the central difference.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfunc = lambda x: x**2 + np.sin(3*x)\n\nx = np.linspace(0, np.pi, 100)\nf = func(x)\n\n# calculate the spacing dx \ndx = x[1]-x[0]\n# you can use np.diff\n# dx = np.diff(x)[0] or\n# dx = np.mean(np.diff(x))\n\n# create an array with the same shape as `f`\ndf_dx = np.zeros_like(f)\n\n# forward difference (1st order) at the left boundary\ndf_dx[0] = (f[1] - f[0]) / dx\n\n# backward difference (1st order) at the right boundary\ndf_dx[-1] = (f[-1] - f[-2]) / dx\n\n# central difference (2nd accuracy) within the domain\ndf_dx[1:-1] = (f[2:] - f[:-2]) / (2*dx)\n\n# plot for comparison\nexact_d_func = lambda x: 2*x + 3*np.cos(3*x)\ndf_dx_exact = exact_d_func(x)\nplt.plot(x, df_dx_exact, 'b-', lw=3, label=\"exact\")\nplt.plot(x, df_dx, 'r--', lw=3, label=\"finite diff.\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$f'(x)$\")\nRMSE = np.sqrt(np.mean((df_dx_exact - df_dx)**2))\nplt.title(f\"RMSE: {RMSE:.3e}\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn the case of using 1st order accuracy formulae, the errors at the boundaries are\n\nprint('1st order')\nprint(f'dx   : {dx:.4f}')\nprint(f'left : {np.abs(df_dx[0] - df_dx_exact[0]):.4f}')\nprint(f'right: {np.abs(df_dx[-1] - df_dx_exact[-1]):.4f}')\n\n1st order\ndx   : 0.0317\nleft : 0.0272\nright: 0.0272\n\n\nIf we use the 2nd order accuracy formulae at the boundaries instead, we get the following errors:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfunc = lambda x: x**2 + np.sin(3*x)\n\nx = np.linspace(0, np.pi, 100)\nf = func(x)\n\n# calculate the spacing dx \ndx = x[1]-x[0]\n# you can use np.diff\n# dx = np.diff(x)[0] or\n# dx = np.mean(np.diff(x))\n\n# create an array with the same shape as `f`\ndf_dx = np.zeros_like(f)\n\n# forward difference (2nd order) at the left boundary\ndf_dx[0] = (-3*f[0] + 4*f[1] - f[2]) / (2*dx)\n\n# backward difference (2nd order) at the right boundary\ndf_dx[-1] = (3*f[-1] - 4*f[-2] + f[-3]) / (2*dx)\n\n# central difference (2nd accuracy) within the domain\ndf_dx[1:-1] = (f[2:] - f[:-2]) / (2*dx)\n\n# plot for comparison\nexact_d_func = lambda x: 2*x + 3*np.cos(3*x)\ndf_dx_exact = exact_d_func(x)\nplt.plot(x, df_dx_exact, 'b-', lw=3, label=\"exact\")\nplt.plot(x, df_dx, 'r--', lw=3, label=\"finite diff.\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$f'(x)$\")\nRMSE = np.sqrt(np.mean((df_dx_exact - df_dx)**2))\nplt.title(f\"RMSE: {RMSE:.3e}\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nprint('2nd order')\nprint(f'dx^2 : {dx**2:.4f}')\nprint(f'left : {np.abs(df_dx[0] - df_dx_exact[0]):.4f}')\nprint(f'right: {np.abs(df_dx[-1] - df_dx_exact[-1]):.4f}')\n\n2nd order\ndx^2 : 0.0010\nleft : 0.0090\nright: 0.0090\n\n\n\nnp.allclose(df_dx_exact, df_dx)\n\nFalse\n\n\n\nnp.allclose(df_dx_exact, df_dx, atol=1e-2)\n\nTrue\n\n\n\n2.2.1 numpy.gradient\nThere is a function for finite differentiation in NumPy.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfunc = lambda x: x**2 + np.sin(3*x)\n\nx = np.linspace(0, np.pi, 100)\nf = func(x)\n\n# calculate the spacing dx \ndx = x[1]-x[0]\n\n# calculate derivatives of `f` using np.gradient (2nd order)\ndf_dx_npgrad = np.gradient(f, dx, axis=0, edge_order=2)\n\n# plot for comparison\nexact_d_func = lambda x: 2*x + 3*np.cos(3*x)\ndf_dx_exact = exact_d_func(x)\nplt.plot(x, df_dx_exact, 'b-', lw=3, label=\"exact\")\nplt.plot(x, df_dx_npgrad, 'r--', lw=3, label=\"finite diff. (np.gradient)\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$f'(x)$\")\nRMSE = np.sqrt(np.mean((df_dx_exact - df_dx_npgrad)**2))\nplt.title(f\"RMSE: {RMSE:.3e}\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nThis computes the same value as manually computed.\n\nnp.allclose(df_dx, df_dx_npgrad)\n\nTrue\n\n\n\n\n\n2.3 Implementation using findiff\nThere is a convenient library for finite differentiation in Python: findiff\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom findiff import FinDiff\n\nfunc = lambda x: x**2 + np.sin(3*x)\n\nx = np.linspace(0, np.pi, 100)\nf = func(x)\n\n# calculate the spacing dx \ndx = x[1]-x[0]\n\n# construct the differential operator: FinDiff(axis, spacing, degree)\nd_dx = FinDiff(0, dx, 1) \n\ndf_dx_findiff = d_dx(f)\n\n# plot for comparison\nexact_d_func = lambda x: 2*x + 3*np.cos(3*x)\ndf_dx_exact = exact_d_func(x)\nplt.plot(x, df_dx_exact, 'b-', lw=3, label=\"exact\")\nplt.plot(x, df_dx_findiff, 'r--', lw=3, label=\"finite diff. (findiff)\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$f'(x)$\")\nRMSE = np.sqrt(np.mean((df_dx_exact - df_dx_findiff)**2))\nplt.title(f\"RMSE: {RMSE:.3e}\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nBy default, findiff uses 2nd order accuray.\n\nnp.allclose(df_dx, df_dx_findiff)\n\nTrue\n\n\nYou can also find finite difference coefficients using this library. (see SectionÂ 2.1)\n\nimport findiff\n# coefficients of 2nd order accuracy formulae for 1st derivative\nfindiff.coefficients(deriv=1, acc=2)\n\n{'center': {'coefficients': array([-0.5,  0. ,  0.5]),\n  'offsets': array([-1,  0,  1]),\n  'accuracy': 2},\n 'forward': {'coefficients': array([-1.5,  2. , -0.5]),\n  'offsets': array([0, 1, 2]),\n  'accuracy': 2},\n 'backward': {'coefficients': array([ 0.5, -2. ,  1.5]),\n  'offsets': array([-2, -1,  0]),\n  'accuracy': 2}}\n\n\n\nnp.allclose(df_dx_exact, df_dx_findiff)\n\nFalse\n\n\n\nnp.allclose(df_dx_exact, df_dx_findiff, atol=1e-2)\n\nTrue\n\n\n\n\n2.4 Implementation using numdifftools\nThere is another convenient library for automatic numerical differentiation in Python: numdifftools\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport numdifftools as nd\n\nfunc = lambda x: x**2 + np.sin(3*x)\n\n# construct a derivative function (FD)\nd_func = nd.Derivative(func, n=1)\n\nx = np.linspace(0, np.pi, 100)\ndf_dx_numdifftools = d_func(x)\n\n# plot for comparison\nexact_d_func = lambda x: 2*x + 3*np.cos(3*x)\ndf_dx_exact = exact_d_func(x)\nplt.plot(x, df_dx_exact, 'b-', lw=3, label=\"exact\")\nplt.plot(x, df_dx_numdifftools, 'r--', lw=3, label=\"finite diff. (numdifftools)\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$f'(x)$\")\nRMSE = np.sqrt(np.mean((df_dx_exact - df_dx_numdifftools)**2))\nplt.title(f\"RMSE: {RMSE:.3e}\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSince this library uses an adaptive finite differences with a Richardson extrapolation methodology, the result is maximally accurate.\n\nnp.allclose(df_dx_exact, df_dx_numdifftools)\n\nTrue"
  },
  {
    "objectID": "posts/derivative-of-1d-scalar-function/index.html#symbolic-differentiation",
    "href": "posts/derivative-of-1d-scalar-function/index.html#symbolic-differentiation",
    "title": "Calculating Derivatives of a 1D Scalar Function in Python",
    "section": "3 Symbolic differentiation",
    "text": "3 Symbolic differentiation\n\n3.1 Implementation using Sympy\nBy using SymPy, we can symbolically differentiate f(x) = x^2 + \\sin(3x)\n\nfrom sympy import symbols, sin, diff\nx = symbols('x')\nf = x**2 + sin(3*x)\nf\n\n\\displaystyle x^{2} + \\sin{\\left(3 x \\right)}\n\n\n\ndf_dx_sympy = diff(f, x)\ndf_dx_sympy\n\n\\displaystyle 2 x + 3 \\cos{\\left(3 x \\right)}\n\n\nAs I mentioned in the previous post, SymPy also supports plotting of a function.\n\nfrom sympy.plotting import plot\np1 = plot(f, (x, 0, np.pi), legend=True, show=False, label=\"$f(x)$\", ylabel='')\np2 = plot(df_dx_sympy, (x, 0, np.pi), legend=True, show=False, label=r\"$f'(x)$\", ylabel='')\np1.extend(p2)\np1.show()"
  },
  {
    "objectID": "posts/derivative-of-1d-scalar-function/index.html#automatic-differentiation",
    "href": "posts/derivative-of-1d-scalar-function/index.html#automatic-differentiation",
    "title": "Calculating Derivatives of a 1D Scalar Function in Python",
    "section": "4 Automatic differentiation",
    "text": "4 Automatic differentiation\n\nIn mathematics and computer algebra, automatic differentiation (auto-differentiation, autodiff, or AD), also called algorithmic differentiation, computational differentiation, is a set of techniques to evaluate the partial derivative of a function specified by a computer program. #\n\nThe efficient implementation of automatic differentiation is quite challenging. However, since the backpropagation is used to minimize loss in neural networks and is essentially a reverse-mode automatic differentiation, most deep learning libraries natively support automatic differentiation tools. In this post, I will demonstrate how to use automatic differentiation in Python with TensorFlow, PyTorch, and JAX.\n\n4.1 Implementation using TensorFlow\n\nTensorFlow is an end-to-end open source platform for machine learning.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfunc = lambda x: x**2 + tf.math.sin(3*x)\n\nx = tf.linspace(0.0, tf.constant(np.pi), 100)\n\n# calculate derivatives of `f`\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    f = func(x)\n    df_dx_tf = tape.gradient(f, x)\n\ndf_dx_tf = df_dx_tf.numpy()\n\n# plot for comparison\nexact_d_func = lambda x: 2*x + 3*np.cos(3*x)\nx_numpy = x.numpy()\ndf_dx_exact = exact_d_func(x_numpy)\nplt.plot(x_numpy, df_dx_exact, 'b-', lw=3, label=\"exact\")\nplt.plot(x_numpy, df_dx_tf, 'r--', lw=3, label=\"auto diff. (TensorFlow)\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$f'(x)$\")\nRMSE = np.sqrt(np.mean((df_dx_exact - df_dx_tf)**2))\nplt.title(f\"RMSE: {RMSE:.3e}\")\nplt.legend()\nplt.show();\n\n\n\n\n\n\n\n\n\nnp.allclose(df_dx_exact, df_dx_tf)\n\nTrue\n\n\n\n\n4.2 Implementation using PyTorch\n\nPyTorch is a Python package that supports tensors and dynamic neural networks in Python with strong GPU acceleration.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\n\nfunc = lambda x: x**2 + torch.sin(3*x)\n\nx = torch.linspace(0, np.pi, 100)\n\n# calculate derivatives of `f`\nx.requires_grad = True\nf = func(x)\ndf_dx_torch = torch.autograd.grad(f, x, grad_outputs=torch.ones_like(f), \n                            retain_graph=True, create_graph=True, allow_unused=True)[0]\n\ndf_dx_torch = df_dx_torch.detach().numpy()\n\n# plot for comparison\nexact_d_func = lambda x: 2*x + 3*np.cos(3*x)\nx_numpy = x.detach().numpy()\ndf_dx_exact = exact_d_func(x_numpy)\nplt.plot(x_numpy, df_dx_exact, 'b-', lw=3, label=\"exact\")\nplt.plot(x_numpy, df_dx_torch, 'r--', lw=3, label=\"auto diff. (PyTorch)\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$f'(x)$\")\nRMSE = np.sqrt(np.mean((df_dx_exact - df_dx_torch)**2))\nplt.title(f\"RMSE: {RMSE:.3e}\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nnp.allclose(df_dx_exact, df_dx_torch)\n\nTrue\n\n\n\n\n4.3 Implementation using JAX\n\nJAX is Autograd and XLA, brought together for high-performance numerical computing, including large-scale machine learning research.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport jax.numpy as jnp\nimport jax\n\nfunc = lambda x: x**2 + jnp.sin(3*x)\n\nx = jnp.linspace(0, jnp.pi, 100)\n\n# calculate derivatives of `f`\ndf_dx_jax = jax.vmap(jax.grad(func))(x)\n\ndf_dx_jax = np.array(df_dx_jax)\n\n# plot for comparison\nexact_d_func = lambda x: 2*x + 3*np.cos(3*x)\nx_numpy = np.array(x)\ndf_dx_exact = exact_d_func(x_numpy)\nplt.plot(x_numpy, df_dx_exact, 'b-', lw=3, label=\"exact\")\nplt.plot(x_numpy, df_dx_jax, 'r--', lw=3, label=\"auto diff. (JAX)\")\nplt.axvline(0, color='k')\nplt.axhline(0, color='k')\nplt.xlabel(r\"$x$\")\nplt.ylabel(r\"$f'(x)$\")\nRMSE = np.sqrt(np.mean((df_dx_exact - df_dx_jax)**2))\nplt.title(f\"RMSE: {RMSE:.3e}\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nnp.allclose(df_dx_exact, df_dx_jax)\n\nTrue"
  },
  {
    "objectID": "posts/double-pendulum-python/index.html",
    "href": "posts/double-pendulum-python/index.html",
    "title": "The double pendulum problem in Python",
    "section": "",
    "text": "This post is based on an example of matplotlib."
  },
  {
    "objectID": "posts/double-pendulum-python/index.html#the-double-pendulum-problem",
    "href": "posts/double-pendulum-python/index.html#the-double-pendulum-problem",
    "title": "The double pendulum problem in Python",
    "section": "",
    "text": "This post is based on an example of matplotlib."
  },
  {
    "objectID": "posts/double-pendulum-python/index.html#code",
    "href": "posts/double-pendulum-python/index.html#code",
    "title": "The double pendulum problem in Python",
    "section": "Code",
    "text": "Code\n\nimport scipy\nimport numpy as np\nfrom numpy import cos, sin\n\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\n\ndef pendulum(t, u, M1, M2, L1, L2, G):\n    # u[0] = theta1\n    # u[1] = omega1\n    # u[2] = theta2\n    # u[3] = omega2\n    \n    du = np.zeros_like(u)\n\n    du[0] = u[1]\n    \n    delta = u[2] - u[0]\n    den1 = (M1 + M2) * L1 - M2 * L1 * cos(delta) * cos(delta)\n    du[1] = (\n        (\n            M2 * L1 * u[1] * u[1] * sin(delta) * cos(delta) + \n            M2 * G * sin(u[2]) * cos(delta) + \n            M2 * L2 * u[3] * u[3] * sin(delta) - (M1 + M2) * G * sin(u[0])\n        ) / den1\n    )\n    \n    du[2] = u[3]\n\n    den2 = (L2 / L1) * den1\n    du[3] = (\n        (\n            -M2 * L2 * u[3] * u[3] * sin(delta) * cos(delta) + \n            (M1 + M2) * G * sin(u[0]) * cos(delta) - \n            (M1 + M2) * L1 * u[1] * u[1] * sin(delta) - (M1 + M2) * G * sin(u[2])\n        ) / den2\n    )\n    \n    return du\n\n\nG = 9.8      # acceleration due to gravity, in m/s^2\nL1 = 1.0     # length of pendulum 1 in m\nL2 = 1.0     # length of pendulum 2 in m\nL = L1 + L2  # maximal length of the combined pendulum\nM1 = 1.0     # mass of pendulum 1 in kg\nM2 = 1.0     # mass of pendulum 2 in kg\nt_stop = 5.0   # how many seconds to simulate\n\n\n# th1 and th2 are the initial angles (degrees)\n# w10 and w20 are the initial angular velocities (degrees per second)\nth1 = 120.0\nw1 = 0.0\nth2 = -10.0\nw2 = 0.0\n\n\nu0 = np.radians([th1, w1, th2, w2])\nu0\n\narray([ 2.0943951 ,  0.        , -0.17453293,  0.        ])\n\n\n\np = (M1, M2, L1, L2, G)\np\n\n(1.0, 1.0, 1.0, 1.0, 9.8)\n\n\n\ntspan = (0.0, t_stop)\ntspan\n\n(0.0, 5.0)\n\n\n\nres = %timeit -o scipy.integrate.solve_ivp(pendulum, tspan, u0, args=p, dense_output=True, \\\n                                        method='DOP853', rtol=1e-10, atol=1e-10)\n\n63.3 ms Â± 839 Î¼s per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n\n\n\nprint(f\"{res.best:.6f} seconds\")\n\n0.062364 seconds\n\n\n\nsol = scipy.integrate.solve_ivp(pendulum, tspan, u0, args=p, dense_output=True, \\\n                                        method='DOP853', rtol=1e-10, atol=1e-10)\n\n\nsol\n\n  message: The solver successfully reached the end of the integration interval.\n  success: True\n   status: 0\n        t: [ 0.000e+00  2.553e-02 ...  4.985e+00  5.000e+00]\n        y: [[ 2.094e+00  2.091e+00 ... -3.871e-01 -4.402e-01]\n            [ 0.000e+00 -2.555e-01 ... -3.738e+00 -3.521e+00]\n            [-1.745e-01 -1.761e-01 ...  7.104e+00  7.050e+00]\n            [ 0.000e+00 -1.201e-01 ... -3.549e+00 -3.909e+00]]\n      sol: &lt;scipy.integrate._ivp.common.OdeSolution object&gt;\n t_events: None\n y_events: None\n     nfev: 4004\n     njev: 0\n      nlu: 0\n\n\n\nt = np.linspace(0, t_stop, 500)\nt.shape\n\n(500,)\n\n\n\ns = sol.sol(t)\ns\n\narray([[ 2.0943951 ,  2.09389273,  2.09238573, ..., -0.36666802,\n        -0.40417351, -0.44021975],\n       [ 0.        , -0.10027181, -0.20051768, ..., -3.81247888,\n        -3.6719432 , -3.52113898],\n       [-0.17453293, -0.17477032, -0.1754812 , ...,  7.12298826,\n         7.08752942,  7.04957895],\n       [ 0.        , -0.04736169, -0.09446566, ..., -3.41150939,\n        -3.66460357, -3.90882817]])\n\n\n\ns.shape\n\n(4, 500)\n\n\n\n# theta1\ns[0, :] \n\narray([ 2.0943951 ,  2.09389273,  2.09238573,  2.08987451,  2.08635972,\n        2.08184231,  2.07632352,  2.0698049 ,  2.06228836,  2.05377617,\n        2.04427099,  2.03377593,  2.02229454,  2.00983085,  1.99638943,\n        1.98197535,  1.96659427,  1.95025238,  1.93295643,  1.91471374,\n        1.89553213,  1.8754199 ,  1.85438575,  1.83243875,  1.80958814,\n        1.78584331,  1.76121353,  1.73570785,  1.70933481,  1.68210224,\n        1.6540169 ,  1.62508422,  1.59530785,  1.5646893 ,  1.53322745,\n        1.500918  ,  1.46775295,  1.43371989,  1.39880128,  1.36297364,\n        1.32620657,  1.28846171,  1.24969137,  1.20983715,  1.1688281 ,\n        1.12657866,  1.08298619,  1.03792806,  0.99125831,  0.94280406,\n        0.89236193,  0.83969567,  0.78453699,  0.72659457,  0.66557999,\n        0.60126609,  0.53359691,  0.46285337,  0.38981596,  0.31576919,\n        0.2422171 ,  0.17044198,  0.10122448,  0.03485021, -0.02872957,\n       -0.08973502, -0.14844932, -0.20516057, -0.26013525, -0.31360838,\n       -0.36578172, -0.41682532, -0.46688021, -0.51606127, -0.56445994,\n       -0.6121465 , -0.65917205, -0.70557024, -0.75135872, -0.79654052,\n       -0.84110525, -0.88503034, -0.92828229, -0.97081783, -1.01258522,\n       -1.05352556, -1.0935741 , -1.13266158, -1.17071557, -1.20766181,\n       -1.24342545, -1.27793226, -1.31110977, -1.34288826, -1.37320165,\n       -1.40198827, -1.42919143, -1.45475989, -1.47864818, -1.50081672,\n       -1.52123181, -1.53986552, -1.55669543, -1.57170418, -1.58487908,\n       -1.59621142, -1.60569592, -1.61332996, -1.6191128 , -1.62304481,\n       -1.62512658, -1.62535807, -1.62373765, -1.62026121, -1.6149211 ,\n       -1.60770518, -1.59859567, -1.58756812, -1.57459027, -1.55962099,\n       -1.54260932, -1.52349393, -1.50220318, -1.47865646, -1.45276789,\n       -1.42445376, -1.39364601, -1.36031435, -1.32449866, -1.28634925,\n       -1.24616428, -1.20440261, -1.16164927, -1.11853126, -1.07561487,\n       -1.03333011, -0.99194588, -0.95158759, -0.91227401, -0.87395459,\n       -0.83653893, -0.7999169 , -0.76397119, -0.72858459, -0.69364384,\n       -0.65904154, -0.62467677, -0.59045515, -0.55628865, -0.52209513,\n       -0.48779804, -0.45332606, -0.4186129 , -0.38359716, -0.3482223 ,\n       -0.31243678, -0.27619425, -0.23945387, -0.20218073, -0.16434633,\n       -0.12592914, -0.0869152 , -0.04729873, -0.00708275,  0.03372036,\n        0.07508832,  0.11698858,  0.15937799,  0.20220264,  0.24539788,\n        0.28888842,  0.33258868,  0.37640325,  0.4202275 ,  0.46394834,\n        0.50744509,  0.55059048,  0.59325168,  0.63529154,  0.67656977,\n        0.71694425,  0.75627242,  0.7944127 ,  0.83122582,  0.86657636,\n        0.90033402,  0.93237501,  0.96258314,  0.99085089,  1.01708017,\n        1.04118281,  1.06308089,  1.08270659,  1.10000181,  1.1149175 ,\n        1.12741261,  1.1374528 ,  1.14500888,  1.15005494,  1.15256639,\n        1.15251759,  1.14987941,  1.14461641,  1.1366838 ,  1.12602401,\n        1.1125629 ,  1.0962055 ,  1.07683152,  1.05429082,  1.02839993,\n        0.99894175,  0.9656734 ,  0.92835223,  0.88679762,  0.84101338,\n        0.79138105,  0.73885916,  0.68499537,  0.63158026,  0.58011461,\n        0.53149531,  0.48605199,  0.44374855,  0.40436928,  0.36763489,\n        0.33326142,  0.30098534,  0.27057186,  0.24181546,  0.21453737,\n        0.18858212,  0.16381405,  0.1401142 ,  0.11737756,  0.0955109 ,\n        0.07443082,  0.05406232,  0.03433748,  0.01519455, -0.00342288,\n       -0.02156646, -0.03928357, -0.05661762, -0.07360829, -0.0902916 ,\n       -0.10669994, -0.12286203, -0.13880274, -0.15454298, -0.17009946,\n       -0.18548448, -0.20070577, -0.21576636, -0.23066455, -0.24539396,\n       -0.25994378, -0.27429912, -0.28844156, -0.3023498 , -0.31600048,\n       -0.32936909, -0.34243085, -0.35516168, -0.36753904, -0.37954268,\n       -0.39115531, -0.40236298, -0.41315547, -0.42352641, -0.43347327,\n       -0.44299728, -0.45210323, -0.4607992 , -0.4690963 , -0.47700832,\n       -0.48455145, -0.491744  , -0.49860613, -0.50515959, -0.51142757,\n       -0.51743452, -0.52320599, -0.52876861, -0.53414994, -0.53937846,\n       -0.5444836 , -0.54949568, -0.55444597, -0.55936673, -0.56429129,\n       -0.56925413, -0.57429096, -0.57943887, -0.58473648, -0.59022408,\n       -0.59594385, -0.60194007, -0.6082594 , -0.61495118, -0.62206774,\n       -0.62966485, -0.63780211, -0.6465435 , -0.65595792, -0.66611976,\n       -0.67710953, -0.68901444, -0.70192871, -0.71595368, -0.73119705,\n       -0.74777081, -0.76578689, -0.78534865, -0.80653616, -0.82938205,\n       -0.85383544, -0.87971524, -0.90666289, -0.93411881, -0.96135316,\n       -0.98756199, -1.0119963 , -1.03406466, -1.05337146, -1.06969796,\n       -1.08295641, -1.09314302, -1.1003016 , -1.1044994 , -1.10581283,\n       -1.1043198 , -1.10009618, -1.09321472, -1.08374525, -1.07175553,\n       -1.05731244, -1.04048307, -1.02133584, -0.99994134, -0.97637299,\n       -0.95070745, -0.92302469, -0.89340787, -0.86194288, -0.82871768,\n       -0.79382135, -0.75734304, -0.7193706 , -0.67998921, -0.63927981,\n       -0.59731756, -0.55417017, -0.50989631, -0.46454401, -0.41814905,\n       -0.37073346, -0.32230404, -0.27285094, -0.22234635, -0.17074336,\n       -0.11797526, -0.0639554 , -0.00857858,  0.04827514,  0.10673204,\n        0.16690872,  0.22888411,  0.29265532,  0.3580776 ,  0.42480159,\n        0.4922419 ,  0.55962136,  0.62610289,  0.69095463,  0.75366322,\n        0.81395537,  0.87175247,  0.92710381,  0.98012854,  1.03097537,\n        1.07979849,  1.12674457,  1.17194683,  1.21552287,  1.2575747 ,\n        1.29818975,  1.33744224,  1.37539479,  1.41209987,  1.44760125,\n        1.48193522,  1.51513175,  1.54721545,  1.5782065 ,  1.60812134,\n        1.6369734 ,  1.66477366,  1.69153112,  1.71725328,  1.74194649,\n        1.76561623,  1.78826743,  1.80990466,  1.83053226,  1.85015457,\n        1.86877597,  1.88640095,  1.90303423,  1.9186807 ,  1.93334552,\n        1.94703404,  1.95975182,  1.97150461,  1.9822983 ,  1.99213885,\n        2.00103229,  2.00898462,  2.01600181,  2.02208969,  2.02725394,\n        2.03150002,  2.03483311,  2.03725809,  2.03877947,  2.03940138,\n        2.03912749,  2.03796103,  2.03590473,  2.03296079,  2.02913088,\n        2.02441611,  2.01881703,  2.01233359,  2.00496515,  1.99671047,\n        1.98756769,  1.97753431,  1.96660722,  1.95478263,  1.9420561 ,\n        1.92842246,  1.91387583,  1.89840954,  1.88201609,  1.86468708,\n        1.84641313,  1.82718378,  1.80698732,  1.7858107 ,  1.76363931,\n        1.74045677,  1.71624468,  1.6909823 ,  1.66464622,  1.63720998,\n        1.60864353,  1.57891279,  1.547979  ,  1.5157981 ,  1.48232003,\n        1.44748799,  1.41123784,  1.37349749,  1.33418677,  1.29321779,\n        1.25049656,  1.20592627,  1.15941378,  1.11088037,  1.06027866,\n        1.00761653,  0.95298659,  0.89659479,  0.83877539,  0.77997726,\n        0.72071458,  0.66149456,  0.60274982,  0.54479927,  0.48784309,\n        0.43198138,  0.37724196,  0.32360712,  0.27103489,  0.21947412,\n        0.16887442,  0.11919239,  0.07039531,  0.0224631 , -0.02461066,\n       -0.07081848, -0.11613911, -0.16053801, -0.20396806, -0.24637036,\n       -0.28767532, -0.32780373, -0.36666802, -0.40417351, -0.44021975])\n\n\n\n# u[0] = theta1\n# u[1] = omega1\n# u[2] = theta2\n# u[3] = omega2\n\nx1 = +L1 * sin(s[0, :])\ny1 = -L1 * cos(s[0, :])\n\nx2 = +L2 * sin(s[2, :]) + x1\ny2 = -L2 * cos(s[2, :]) + y1\n\n\nplt.plot(x2, y2)\nplt.grid(linewidth=1)\nplt.gca().set_aspect(\"equal\")\nplt.xlabel(\"x2\")\nplt.ylabel(\"y2\")\nplt.xlim((-2.0, 2.0))\nplt.ylim((-2.0, 2.0))\nplt.show()\n\n\n\n\n\n\n\n\n\nfig = plt.figure(figsize=(5, 4))\nax = fig.add_subplot(autoscale_on=False, xlim=(-L, L), ylim=(-L, 1.))\nax.set_aspect('equal')\nax.grid()\n\nline, = ax.plot([], [], 'o-', lw=2, markerfacecolor=\"red\", markeredgecolor=\"black\")\ntrace, = ax.plot([], [], '.-', lw=1, ms=2)\ntime_template = 'time = %.1f s'\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(i):\n    this_x = [0, x1[i], x2[i]]\n    this_y = [0, y1[i], y2[i]]\n    \n    history_x = x2[:i]\n    history_y = y2[:i]\n    \n    line.set_data(this_x, this_y)\n    trace.set_data(history_x, history_y)\n    time_text.set_text(time_template % (t[i]))\n    return line, trace, time_text\n\nn = len(x1)\nframes = np.arange(0, n, 10)\nani = animation.FuncAnimation(fig, animate, frames, blit=True)\n\n\nani.save(\"ani_python.mp4\", fps=10)"
  },
  {
    "objectID": "posts/explain-words/index.html",
    "href": "posts/explain-words/index.html",
    "title": "ì²œë¬¸ìš©ì–´ ì„¤ëª…",
    "section": "",
    "text": "2019ë…„ ìš°ì£¼ê´€ì¸¡ ìˆ˜ì—… (ê²½í¬ëŒ€í•™êµ ë°•ìˆ˜ì¢… êµìˆ˜)ì—ì„œ 2020 ì—­ì„œ 09. ì²œë¬¸ìƒìˆ˜ì™€ ìžë£Œ ì„¤ëª…ìš©ìœ¼ë¡œ ìž‘ì„±í•œ ê¸€"
  },
  {
    "objectID": "posts/explain-words/index.html#êµ­ì œì²œë¬¸ì—°ë§¹-ì²œë¬¸ìƒìˆ˜",
    "href": "posts/explain-words/index.html#êµ­ì œì²œë¬¸ì—°ë§¹-ì²œë¬¸ìƒìˆ˜",
    "title": "ì²œë¬¸ìš©ì–´ ì„¤ëª…",
    "section": "êµ­ì œì²œë¬¸ì—°ë§¹ ì²œë¬¸ìƒìˆ˜",
    "text": "êµ­ì œì²œë¬¸ì—°ë§¹ ì²œë¬¸ìƒìˆ˜\n\nTT, TCG, TCB, TDB\n\n\\text{TCG} = \\text{TT} + L_G \\times (\\text{JD} - 2443144.5) \\times 86400 \\ \\text{s}\n\n\n(\\text{TCB}-\\text{TCG})_{\\text{secular}} = L_C \\times (\\text{JD} - 2443144.5) \\times 86400 \\ \\text{s}\n\n\n\\text{TDB} = \\text{TCB} - L_B \\times (\\text{JD}_{\\text{TCB}} - T_0) \\times 86400 \\ \\text{s} + \\text{TDB}_0\n\n\n\\text{TDB}(T_0) - \\text{TCB}(T_0) = (\\text{TDB} - \\text{TCB} \\quad \\text{at} \\quad \\text{JD}_{\\text{TCB}} = T_0)\n\nSIë‹¨ìœ„ê³„(International System of Units)ì˜ 1 ì´ˆ(second)ëŠ” í˜„ìž¬ ì„¸ìŠ˜-133 ì›ìžì˜ ì„­ë™ì´ ì—†ëŠ” ë°”ë‹¥ìƒíƒœì˜ ì´ˆë¯¸ì„¸ ì „ì´ ì£¼íŒŒìˆ˜ \\Delta \\nu_{\\text{Cs}}ë¥¼ Hz ë‹¨ìœ„ë¡œ ë‚˜íƒ€ë‚  ë•Œ ê·¸ ìˆ˜ì¹˜ë¥¼ 9 192 631 770ìœ¼ë¡œ ê³ ì •í•¨ìœ¼ë¡œì¨ ì •ì˜ëœë‹¤. ì—¬ê¸°ì„œ HzëŠ” s^{-1}ê³¼ ê°™ë‹¤.\nTAI(International Atomic Time)ëŠ” ì›ìžì‹œê³„ì— ê¸°ë°˜í•œ ì‹œì²™ë„ì´ë©°, BIPM(International Bureau of Weights and Measures)ì˜ ë¶„ì„ì— ì˜í•´ ìœ ì§€ë˜ê³  ìžˆë‹¤. TAIì˜ ë‹¨ìœ„ì‹œê°„ ê¸¸ì´ëŠ” ì§€ì˜¤ì´ë“œì—ì„œì˜ SIì´ˆì´ë‹¤.\nì§€êµ¬ í‘œë©´ì—ì„œ ì •ì˜ëœ ì¢Œí‘œì‹œê°„(coordinate time)ì„ TT(Terrestrial Time)ë¼ê³  ë¶€ë¥¸ë‹¤. ì§€í‘œë©´ì—ì„œ ì´ë£¨ì–´ì§€ëŠ” ì²œë¬¸ê´€ì¸¡ì—ì„œì˜ ì‹œê°„ì¸¡ì •ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì‹œì²™ë„ì´ë‹¤. TTì˜ ë‹¨ìœ„ ì‹œê°„ ê¸¸ì´ëŠ” TAIì˜ ë‹¨ìœ„ ì‹œê°„ ê¸¸ì´ë¡œ ì •ì˜í•˜ë©°, TAI 1977ë…„ 1ì›” 1ì¼ 0ì‹œ 0ë¶„ 0ì´ˆë¥¼ TT 1977ë…„ 1ì›” 1ì¼ 0ì‹œ 0ë¶„ 32.184ì´ˆë¡œ ì •ì˜í•œë‹¤.ì—­ì‚¬ì ìœ¼ë¡œ ET(Ephemeris Time)ë¥¼ TDT(Terrestrial Dynamic Time)ê°€ ê³„ìŠ¹í•˜ê³  TDTë¥¼ TTê°€ ê³„ìŠ¹í•˜ê¸°ì— 32.184ì´ˆê°€ ë¶™ëŠ”ë‹¤.\nGCRS(Geocentric Celestial Reference System)ëŠ” ì§€êµ¬ì˜ ì§ˆëŸ‰ì¤‘ì‹¬ì— ì›ì ì„ ë‘” ì¢Œí‘œê³„ì´ë©°, ì§€êµ¬ì ‘ê·¼ì²œì²´(near-Earth object, NEO)ì— ëŒ€í•œ ì—­í•™ì  ê³„ì‚°ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¢Œí‘œê³„ì´ë‹¤. GCRSì˜ ì‹œê°„ì„ TCG(Geocentric Coordinate Time)ë¼ê³  ë¶€ë¥¸ë‹¤. TCGëŠ” ì¤‘ë ¥ì— ì˜í•œ ì‹œê°„ ì§€ì—° íš¨ê³¼ë¥¼ ëª¨ë‘ ë¬´ì‹œí•˜ì˜€ì„ ë•Œ, ì§€êµ¬ì˜ ì§ˆëŸ‰ì¤‘ì‹¬ê³¼ ê°™ì´ ì›€ì§ì´ëŠ” ì¢Œí‘œê³„ì˜ ê³ ìœ ì‹œê°„(proper time)ì´ë‹¤.\nBCRS(Barycentric Celestial Reference System)ëŠ” íƒœì–‘ê³„ì˜ ì§ˆëŸ‰ì¤‘ì‹¬ì— ì›ì ì„ ë‘” ì¢Œí‘œê³„ì´ë©°, ì¼ë°˜ì ì¸ ì²œì²´ì— ëŒ€í•œ ì—­í•™ì  ê³„ì‚°ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¢Œí‘œê³„ì´ë‹¤. BCRSì˜ ì‹œê°„ì„ TCB(Barycentric Coordinate Time)ë¼ê³  ë¶€ë¥¸ë‹¤. TCBëŠ” ì¤‘ë ¥ì— ì˜í•œ ì‹œê°„ ì§€ì—° íš¨ê³¼ë¥¼ ëª¨ë‘ ë¬´ì‹œí•˜ì˜€ì„ë•Œ,íƒœì–‘ê³„ì˜ ì§ˆëŸ‰ì¤‘ì‹¬ê³¼ ê°™ì´ ì›€ì§ì´ëŠ” ì¢Œí‘œê³„ì˜ ê³ ìœ ì‹œê°„(proper time)ì´ë‹¤.\nTDB(Barycentric Dynamical Time)ëŠ” 2006ë…„ ì´í›„ë¡œ TCBë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ì˜ëœë‹¤.\nê° ì‹œìŠ¤í…œ ì‹œê°„ì˜ ë‹¨ìœ„ ì‹œê°„ ê¸¸ì´ëŠ” ìƒëŒ€ë¡ ì  íš¨ê³¼ì— ì˜í•´ ë¯¸ì„¸í•˜ê²Œ ë‹¤ë¥´ë‹¤.ê°ê°ì˜ ë‹¨ìœ„ ì‹œê°„ ê¸¸ì´ë¥¼ \\rm{d}(\\text{TT}), \\rm{d}(\\text{TCG}), \\rm{d}(\\text{TCB}), \\rm{d}(\\text{TDB}) ì²˜ëŸ¼ ë‚˜íƒ€ë‚¸ë‹¤.\n\n\nì§€êµ¬ìžì „ê°(ERA)\nì§€êµ¬ìžì „ê°(ERA, Earth Rotation Angle)ëŠ” í•­ì„±ì‹œ(Sidereal time)ì™€ ë¹„ìŠ·í•œ ê°œë…ìœ¼ë¡œ, ì§€êµ¬ê°€ ìžì „ì— ì˜í•´ ëŒì•„ê°„ ê°ë„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. revëŠ” revolutions(íšŒì „)ì˜ ì¤„ìž„ë§ì´ë‹¤.\n\n1 \\text{ rev} = 1 \\text{ íšŒì „} = 360^\\circ\n\n\n\níƒœì–‘ì§ˆëŸ‰ì¸ìˆ˜(íƒœì–‘ì¤‘ë ¥ìƒìˆ˜), ì§€êµ¬ì¤‘ë ¥ìƒìˆ˜\nGMì˜ ê²½ìš° ì²œë¬¸ê´€ì¸¡ì— ì˜í•´ ì¸¡ì •ì´ ê°€ëŠ¥í•˜ë‚˜, GëŠ” ë§¤ìš° ì •ë°€í•œ ì‹¤í—˜ì— ì˜í•´ì„œë§Œ ì¸¡ì •ì´ ê°€ëŠ¥í•˜ë‹¤. ë”°ë¼ì„œ GMì˜ ì •í™•ë„ê°€ G, Më³´ë‹¤ ë†’ì€ ê²½ìš°ê°€ ë§Žìœ¼ë¯€ë¡œ ì²œë¬¸ìƒìˆ˜ì— GM ê°’ì„ ëª…ì‹œí•œ ê²ƒì´ë‹¤.\n\n\nì§€êµ¬ì ë„ë°˜ê²½\nSI m(ë¯¸í„°)ëŠ” SI s(ì´ˆ)ì— ê¸°ë°˜í•˜ì—¬ ì •ì˜ë˜ë¯€ë¡œ, m ë‹¨ìœ„ì˜ ìƒìˆ˜ì—ë„ ì‹œì²™ë„ [\\text{TT}]ë¥¼ ë°ížŒ ê²ƒì´ë‹¤. \na_E = a_e\n\n\n\nì§€êµ¬ì—­í•™ê³„ìˆ˜, ì§€êµ¬ì—­í•™ê³„ìˆ˜ ì‹œê°„ë³€í™”ìœ¨\nì§€êµ¬ë¥¼ ê½‰ì°¬ íšŒì „íƒ€ì›ë©´(spheroid)í˜•íƒœì˜ ì§ˆëŸ‰ì²´ë¼ê³  ê°€ì •í•˜ìž. ì›ì ì´ ì§€êµ¬ì˜ ì§ˆëŸ‰ì¤‘ì‹¬ì— ìœ„ì¹˜í•˜ê³ , ì§€êµ¬ì˜ íšŒì „ì´ ê´€ì¸¡ë˜ì§€ ì•ŠëŠ” êµ¬ë©´ì¢Œí‘œê³„(spherical coordinate system)ì—ì„œì˜ ì§€êµ¬ ì¤‘ë ¥ í¬í…ì…œ(potential) \\phiëŠ” ì§€êµ¬ ì¤‘ë ¥ìƒìˆ˜ \\mu = GM_Eì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ì£¼ì–´ì§„ë‹¤. \n\\phi = - \\frac{\\mu}{r} + \\sum_{n=2}^{\\infty} \\frac{J_n P_n(\\sin \\theta)}{r^{n+1}}\n\nì—¬ê¸°ì„œ P_nì€ ë¥´ìž¥ë“œë¥´ ë‹¤í•­ì‹(Legendre polynomial)ìœ¼ë¡œ, ë¡œë“œë¦¬ê²ŒìŠ¤ê³µì‹(Rodriguesâ€™ formula)ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. \nP_n(x) = \\frac{1}{2^n n!} \\frac{d^n}{dx^n} (x^2 - 1)^n\n\n\\phiì—ì„œ ì²«í•­ì„ ì œì™¸í•œ ì§€ë°°í•­(dominating term)ì€ n=2ì¸ J_2 termìœ¼ë¡œ, n \\geq 3 í•­ë“¤ì€ ì¼ë°˜ì ìœ¼ë¡œ ë¬´ì‹œê°€ëŠ¥í•˜ë‹¤. J_2 í•­ì€ ë‹¤ìŒê³¼ ê°™ì´ ì£¼ì–´ì§„ë‹¤.\n\\phi_{J_2 \\  \\text{term}} = \\frac{J_2 P_2(\\sin \\theta)}{r^3} = J_2 \\frac{3 \\sin^2 \\theta - 1}{2r^3}\nì—¬ê¸°ì„œ J_2 í•­ì˜ ê³„ìˆ˜ê°€ J_2ì´ë©°, ì§€êµ¬ì—­í•™ê³„ìˆ˜(Dynamical form-factor for the Earth)ë¼ê³  ë¶€ë¥¸ë‹¤. ì§€êµ¬ì—­í•™ê³„ìˆ˜ ì‹œê°„ë³€í™”ìœ¨ì—ì„œ cyëŠ” century(1ì„¸ê¸°, 100ë…„)ì˜ ì¤„ìž„ë§ì´ë‹¤.\nJ_2ì˜ ê°’ì€ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•  ìˆ˜ ìžˆë‹¤.\n\nJ_2 = \\frac{2}{3}f - \\frac{a^3 \\omega^2}{3GM_E}\n\nì—¬ê¸°ì„œ fëŠ” ì§€êµ¬ íŽ¸í‰ë„, aëŠ” ì§€êµ¬ ì ë„ë°˜ê²½, \\omegaëŠ” ì§€êµ¬ í‰ê·  ê°ì†ë„, GM_EëŠ” ì§€êµ¬ ì¤‘ë ¥ìƒìˆ˜ì´ë‹¤.\n\n\nì§€ì˜¤ì´ë“œ í¬í…ì…œ\nì¤‘ë ¥ìž¥(gravitational field) \\mathbf{g}ì— ëŒ€í•´ \\mathbf{g} = - \\nabla \\phië¥¼ ë§Œì¡±ì‹œí‚¤ëŠ” ìŠ¤ì¹¼ë¼ìž¥(scalar field) \\phië¥¼ ì¤‘ë ¥ í¬í…ì…œ(potential)ì´ë¼ê³  ë¶€ë¥¸ë‹¤.\nì§€êµ¬ ì¤‘ë ¥ìž¥ì˜ ë“±í¼í…ì…œë©´(equipotential surface)ì„ ì§€ì˜¤ì´ë“œ(geoid)ë¼ê³  ë¶€ë¥¸ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì •ì˜ì— ì˜í•´ ì§€ì˜¤ì´ë“œëŠ” ì¤‘ë ¥ì— ìˆ˜ì§ì´ë‹¤. ë˜í•œ ì§€ì˜¤ì´ë“œëŠ” ë¬´ìˆ˜ížˆ ë§Žìœ¼ë©°, ê°ê°ì— ëŒ€ì‘ë˜ëŠ” ì§€ì˜¤ì´ë“œ í¬í…ì…œë„ ë¬´ìˆ˜ížˆ ë§Žë‹¤. ë‹¤ë§Œ ê´€ìŠµì ìœ¼ë¡œ íŠ¹ì •í•œ ë“±í¬í…ì…œë©´(ë°”ë‹¤ì—ì„œëŠ” í‰ê·  í•´ìˆ˜ë©´, ìœ¡ì§€ì—ì„œëŠ” í‰ê·  í•´ìˆ˜ë©´ì„ ì—°ìž¥í•œ ê³¡ë©´)ì„ ì§€ì˜¤ì´ë“œë¼ê³  ë¶€ë¥¸ë‹¤. ì§€ì˜¤ì´ë“œ í¬í…ì…œ W_0ëŠ” í˜„ìž¬ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤. \nW_0 = c^2 L_G\n\n\n\nì§€êµ¬ íŽ¸í‰ë„ ì—­ìˆ˜ (IERS 2010)\nì§€êµ¬ëŠ” ìžì „ì— ì˜í•´ ì ë„ë°˜ê²½ì´ ê·¹ë°˜ê²½ë³´ë‹¤ ê¸¸ë‹¤. ë”°ë¼ì„œ ì§€êµ¬ì˜ ë‹¨ë©´ì„ ìž¥ë°˜ê²½ì´ a, ë‹¨ë°˜ê²½ì´ bì¸ íƒ€ì›ìœ¼ë¡œ ê·¼ì‚¬ ê°€ëŠ¥í•˜ë‹¤. ì´ë•Œ ì§€êµ¬ íŽ¸í‰ë„(flattening) fëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤ \nf = \\frac{a-b}{a}\n\nIERSëŠ” International Earth Rotation and Reference Systems Serviceì˜ ì•½ìžì´ë‹¤.\n\n\nì¼ë°˜ ê²½ë„ì„¸ì°¨, ê²½ì‚¬ê° ë³€í™”ìœ¨, ê²½ë„ ì ë„ì„¸ì°¨, ê²½ì‚¬ê° ì ë„ì„¸ì°¨, ìž¥ë™ìƒìˆ˜\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nê´€ì„±ì¢Œí‘œê³„(inertial frame of reference)ì—ì„œ ê´€ì¸¡í•œ ì§€êµ¬ëŠ” ìœ„ì˜ ê·¸ë¦¼ ì²˜ëŸ¼ ìžì „(Rotation), ì„¸ì°¨(Precession), ìž¥ë™(Nutation)ì„ í•œë‹¤. ìžì „ì€ ì§€êµ¬ì˜ ì ë„ í‰ë©´ê³¼ ìˆ˜ì§í•œ ì§ì„  ìƒì— ì¡´ìž¬í•˜ë©´ì„œ ì§€êµ¬ì˜ ë¶ê·¹ ê·¼ë°©ì— ìžˆëŠ” ê´€ì¸¡ìžê°€ ì§€êµ¬ë¥¼ ë°”ë¼ë³´ì•˜ì„ ë•Œ ì§€êµ¬ ì „ì²´ê°€ ë°˜ì‹œê³„ ë°©í–¥ìœ¼ë¡œ íšŒì „í•˜ëŠ” í˜„ìƒì´ë‹¤. ìžì „ ì£¼ê¸°ëŠ” 1ì¼ì´ë‹¤. ì„¸ì°¨ëŠ” ì§€êµ¬ì˜ í™©ë„í‰ë©´ê³¼ ìˆ˜ì§í•œ ì§ì„  ìƒì— ì¡´ìž¬í•˜ë©´ì„œ ì§€êµ¬ì˜ ë¶ê·¹ ê·¼ë°©ì— ìžˆëŠ” ê´€ì¸¡ìžê°€ ì§€êµ¬ë¥¼ ë°”ë¼ë³´ì•˜ì„ ë•Œ ì§€êµ¬ì˜ ìžì „ì¶•ì´ ì‹œê³„ ë°©í–¥ìœ¼ë¡œ íšŒì „í•˜ëŠ” í˜„ìƒì´ë‹¤. ì„¸ì°¨ ì£¼ê¸°ëŠ” ì•½ 26000ë…„ì´ë‹¤. ìž¥ë™ì€ ì§€êµ¬ì˜ í™©ë„í‰ë©´ê³¼ ìˆ˜ì§í•œ ì§ì„  ìƒì— ì¡´ìž¬í•˜ë©´ì„œ ì§€êµ¬ì˜ ë¶ê·¹ ê·¼ë°©ì— ìžˆëŠ” ê´€ì¸¡ìžê°€ ì§€êµ¬ë¥¼ ë°”ë¼ë³´ì•˜ì„ ë•Œ ì§€êµ¬ì˜ ìžì „ì¶•ê³¼ ì§€êµ¬ì˜ ê³µì „ì¶• ì‚¬ì´ì˜ ê°ë„ê°€ ì£¼ê¸°ì ìœ¼ë¡œ ë³€í•˜ëŠ” í˜„ìƒì´ë‹¤. ìž¥ë™ ì£¼ê¸°ëŠ” ì•½ 18.61ë…„ì´ë‹¤.\nê·¸ë¦¬ìŠ¤ì˜ ížˆíŒŒë¥´ì½”ìŠ¤(Hipparchus of Nicaea)ê°€ ì¶˜ë¶„ì ì´ ì´ë™í•œë‹¤ëŠ” í˜„ìƒì„ BC 127ë…„ì— ë°œê²¬í•¨ìœ¼ë¡œì¨ ì§€êµ¬ì˜ ì„¸ì°¨ìš´ë™ì´ ì•Œë ¤ì¡Œê¸° ë•Œë¬¸ì—, ì—­ì‚¬ì ìœ¼ë¡œ ì§€êµ¬ì˜ ì„¸ì°¨ìš´ë™ì€ ë¶„ì ì˜ ì„¸ì°¨ìš´ë™(precession of the equinoxes)ì´ë¼ê³  ë¶ˆë ¸ë‹¤. ê·¸ëŸ¬ë‚˜ ë‰´í„´ ì´í›„ ì²œì²´ì—­í•™ì´ ë°œë‹¬í•˜ë©´ì„œ ì„¸ì°¨ìš´ë™ì´ íƒœì–‘, ë‹¬, ì§€êµ¬ ì™¸ í–‰ì„±ë“¤ì´ ì§€êµ¬ì— ìž‘ìš©í•˜ëŠ” ì¤‘ë ¥ì— ì˜í•´ ë°œìƒí•œë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ë©´ì„œ ìƒˆë¡œìš´ ìš©ì–´ê°€ ë§Œë“¤ì–´ì¡Œë‹¤. ì£¼ë¡œ íƒœì–‘ê³¼ ë‹¬ì— ì˜í•´ ì§€êµ¬ì˜ ì ë„ í‰ë©´ì´ ë³€í•˜ëŠ” í˜„ìƒì„ ì¼ì›” ì„¸ì°¨(Lunisolar precession), ì£¼ë¡œ ì§€êµ¬ ì™¸ í–‰ì„±ì— ì˜í•´ ì§€êµ¬ì˜ í™©ë„ í‰ë©´ì´ ë³€í•˜ëŠ” í˜„ìƒì„ í–‰ì„± ì„¸ì°¨(Planetary precession)ë¼ê³  ëª…ëª…í–ˆìœ¼ë©°, ì´ ë‘˜ì˜ ê²°í•©ìœ¼ë¡œ ë°œìƒí•˜ëŠ” ì‹¤ì œ ì„¸ì°¨ìš´ë™ì„ ì¼ë°˜ ì„¸ì°¨(General Precession)ë¼ê³  ëª…ëª…í–ˆë‹¤. ê·¸ëŸ¬ë‚˜ íƒœì–‘ê³¼ ë‹¬ì´ ì§€êµ¬ì˜ í™©ë„í‰ë©´ì„ ë³€í™”ì‹œí‚¤ê¸°ë„ í•˜ê³ , ì§€êµ¬ ì™¸ í–‰ì„±ì´ ì§€êµ¬ì˜ ì ë„í‰ë©´ì„ ë³€í™”ì‹œí‚¤ê¸°ë„ í•˜ê¸°ì—, ìš©ì–´ì— ìžˆì–´ í˜¼ì„ ì´ ì¡´ìž¬í•œë‹¤ëŠ” íŒë‹¨ í•˜ì— 2006ë…„ IAUê°€ ê°ê°ì˜ ìš©ì–´ë¥¼ ìž¬ì •ì˜í–ˆë‹¤. ì¦‰ ì¼ì›”ì„¸ì°¨(Lunisolar precession)ë¥¼ ì ë„ ì„¸ì°¨(Precession of the equator)ë¡œ, í–‰ì„± ì„¸ì°¨(Planetary precession)ë¥¼ í™©ë„ ì„¸ì°¨(Precession of the ecliptic)ë¡œ ìš©ì–´ë¥¼ ë°”ê¾¸ì—ˆë‹¤.\n\n\n\n\n\nìœ„ ê·¸ë¦¼ì€ ì§€êµ¬ì˜ í™©ë„í‰ë©´ê³¼ ìˆ˜ì§í•œ ì§ì„  ìƒì— ì¡´ìž¬í•˜ë©´ì„œ ì§€êµ¬ì˜ ë¶ê·¹ ê·¼ë°©ì— ìžˆëŠ” ê´€ì¸¡ìžê°€ ì§€êµ¬ë¥¼ ë°”ë¼ë³´ì•˜ì„ ë•Œ ì²œêµ¬ì˜ ë¶ê·¹(ì§€êµ¬ ìžì „ì¶•ì˜ ëë¶€ë¶„)ì´ ì´ë™í•˜ëŠ” ê²½ë¡œë¥¼ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤. ì ì„ ì˜ ìš´ë™ê²½ë¡œ(path of mean celestial pole)ëŠ” ì„¸ì°¨ìš´ë™ì— ì˜í•œ ê²½ë¡œì´ê³ , ì‹¤ì„ ì˜ ìš´ë™ê²½ë¡œ(path of instantaneous celestial pole)ëŠ” ì„¸ì°¨ìš´ë™ì— ì˜í•œ ì›ìš´ë™ì— ìž¥ë™ìš´ë™ì— ì˜í•œ íƒ€ì›ìš´ë™ì´ ê²°í•©ëœ ìš´ë™ì— ì˜í•œ ê²½ë¡œì´ë‹¤. ì²œêµ¬ì˜ ë¶ê·¹ì´ ì ì„ ì˜ ìš´ë™ê²½ë¡œë¥¼ ë”°ë¼ ì´ë™í•˜ëŠ” ê°ì†ë ¥ì„ ì¼ë°˜ ê²½ë„ì„¸ì°¨(General precession in longitude) p_Aë¼ê³  í•œë‹¤. ìž¥ë™ìš´ë™ì— ì˜í•´ ì²œêµ¬ì˜ ë¶ê·¹ì€ êµ­ì†Œì ì¸ íƒ€ì›ìš´ë™ì„ í•˜ê²Œ ë˜ëŠ”ë°, ì´ íƒ€ì›ì˜ ìž¥ë°˜ê²½(semi-major axis)ì„ ìž¥ë™ìž¥ìˆ˜(constant of nutation) Nì´ë¼ í•œë‹¤.\n\n\n\n\n\nEquinoctial colureëŠ” ì²œêµ¬ì˜ ë¶ê·¹(Celestial North Pole), ì²œêµ¬ì˜ ë‚¨ê·¹(Celestial South Pole), ì¶˜ë¶„ì (Vernal Equinox), ì¶”ë¶„ì (Autumnal Equinox)ì„ ì§€ë‚˜ëŠ” ëŒ€ì›ì´ë‹¤. Solstitial colureëŠ” ì²œêµ¬ì˜ ë¶ê·¹(Celestial North Pole), ì²œêµ¬ì˜ ë‚¨ê·¹(Celestial South Pole), í•˜ì§€ì (Summer Solstice), ë™ì§€ì (Winter Solstice)ì„ ì§€ë‚˜ëŠ” ëŒ€ì›ì´ë‹¤.\nì–´ëŠ ì‹œì ì—ì„œì˜ \\epsilon_AëŠ” ê·¸ ì‹œì ì—ì„œì˜ í™©ë„(ecliptic of date)ì™€ ê·¸ ì‹œì ì—ì„œì˜ í‰ê·  ì ë„(mean equator of date)ê°€ ì´ë£¨ëŠ” ê°ë„ì´ë‹¤. ì–´ëŠ ì‹œì ì—ì„œì˜ \\psi_AëŠ” ê·¸ ì‹œì ì—ì„œì˜ solstital colure(solstital colure of date)ì™€ ì—­ê¸°ì ì—ì„œì˜ solstital colure(solstitial colure of epoch)ê°€ ì´ë£¨ëŠ” ê°ë„ì´ë‹¤. ì–´ëŠ ì‹œì ì—ì„œì˜ \\omega_AëŠ” ê·¸ ì‹œì ì—ì„œì˜ í‰ê· ì ë„(mean equator of date)ì™€ ì—­ê¸°ì ì—ì„œì˜ ê³ ì •ëœ í™©ë„(fixed ecliptic of epoch)ê°€ ì´ë£¨ëŠ” ê°ë„ì´ë‹¤. P03 precession modelì— ì˜í•´ ì£¼ì–´ì§€ëŠ” ê°ê°ì˜ ê°’ì„ tì— ëŒ€í•œ 2ì°¨í•­ ê¹Œì§€ë§Œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n\\epsilon_A = 84381''.406 - 46''.836769t - 0''.0001831t^2\n\n\n\\psi_A = 5038''.481507t - 1''.0790069t^2\n\n\n\\omega_A = 84381''.406 - 0''.025754t + 0''.0512623t^2\n\nì—¬ê¸°ì„œ t = (\\text{TT} - \\text{2000 January 1d 12h TT})/36525 (ê°’ì€ dayë‹¨ìœ„ë¡œ ë„£ëŠ”ë‹¤)ëŠ” J2000.0 TT ë¡œë¶€í„° ê²½ê³¼ëœ ì‹œê°„ì„ Julian century ë‹¨ìœ„ë¡œ ë‚˜íƒ€ë‚¸ ê°’ì´ë‹¤.\nJ2000.0 ê²½ì‚¬ê° ë³€í™”ìœ¨(Rate of change in obliquity) \\dot{\\epsilon}ëŠ” \\epsilon_Aë¥¼ tì— ëŒ€í•´ ë¯¸ë¶„í•˜ê³  t=0ì„ ëŒ€ìž…í•œ ê°’ìœ¼ë¡œ, J2000.0ì—ì„œì˜ \\epsilon_Aì˜ ì‹œê°„ ë³€í™”ìœ¨ì„ ë‚˜íƒ€ë‚¸ë‹¤.\nJ2000.0 ê²½ë„ ì ë„ì„¸ì°¨(Precession of the equator in longitude) \\dot{\\psi}ëŠ” \\psi_Aë¥¼ tì— ëŒ€í•´ ë¯¸ë¶„í•˜ê³  t=0ì„ ëŒ€ìž…í•œ ê°’ìœ¼ë¡œ, J2000.0ì—ì„œì˜ \\psi_Aì˜ ì‹œê°„ ë³€í™”ìœ¨ì„ ë‚˜íƒ€ë‚¸ë‹¤.\nJ2000.0 ê²½ì‚¬ê° ì ë„ì„¸ì°¨(Precession of the equator in obliquity) \\dot{\\omega}ëŠ” \\omega_Aë¥¼ tì— ëŒ€í•´ ë¯¸ë¶„í•˜ê³  t=0ì„ ëŒ€ìž…í•œ ê°’ìœ¼ë¡œ, J2000.0ì—ì„œì˜ \\omega_Aì˜ ì‹œê°„ ë³€í™”ìœ¨ì„ ë‚˜íƒ€ë‚¸ë‹¤.\n\n\níƒœì–‘ ì‹œì°¨\níƒœì–‘ì—ì„œ ë³¸ ì§€êµ¬ì˜ ì‹œë°˜ê²½(apparent radius, angular radius)ì„ íƒœì–‘ ì‹œì°¨(solar parallax)ë¼ê³  ë¶€ë¥¸ë‹¤.\n\n\nê´‘í–‰ì°¨ ìƒìˆ˜\n\n\n\n\n\nê´‘í–‰ì°¨(aberration)ëž€ ê´€ì¸¡ìžì˜ ì†ë„ì— ì˜ì¡´í•˜ì—¬ ê´€ì¸¡ëŒ€ìƒì˜ ê²‰ë³´ê¸° ìœ„ì¹˜ê°€ ë°”ë€ŒëŠ” í˜„ìƒì´ë‹¤. ê´€ì¸¡ìžê°€ vì˜ ì†ë ¥ìœ¼ë¡œ ì›€ì§ì¸ë‹¤ê³  í•˜ìž. ê´€ì¸¡ìžê°€ ì›€ì§ì´ëŠ” ë°©í–¥ì„ ê°ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ê¸°ì¤€ì„ ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ê´€ì¸¡ìžê°€ ì •ì§€í–ˆì„ ë•Œ íŠ¹ì • ê´€ì¸¡ ëŒ€ìƒì— ëŒ€í•œ ì‹œì„ ë°©í–¥ê³¼ ê¸°ì¤€ì„ ì´ ì´ë£¨ëŠ” ê°ì„ \\theta, ê´€ì¸¡ìžê°€ ì›€ì§ì¼ ë•Œ íŠ¹ì • ê´€ì¸¡ ëŒ€ìƒì— ëŒ€í•œ ì‹œì„ ë°©í–¥ê³¼ ê¸°ì¤€ì„ ì´ ì´ë£¨ëŠ” ê°ì„ \\phië¼ê³  í•˜ìž. ê·¸ëŸ¬ë©´ v/c \\ll 1ì¼ ë•Œ ë‹¤ìŒì´ ì„±ë¦½í•œë‹¤.\n\n\\kappa = \\theta - \\phi \\approx v/c\n\nvê°€ ì§€êµ¬ì˜ í‰ê·  ê³µì „ ì†ë„ì¼ë•Œì˜ \\kappaë¥¼ ê´‘í–‰ì°¨ ìƒìˆ˜(constant of aberration)ë¼ê³  ë¶€ë¥¸ë‹¤."
  },
  {
    "objectID": "posts/explain-words/index.html#ì¼ë°˜-ì²œë¬¸ìƒìˆ˜",
    "href": "posts/explain-words/index.html#ì¼ë°˜-ì²œë¬¸ìƒìˆ˜",
    "title": "ì²œë¬¸ìš©ì–´ ì„¤ëª…",
    "section": "ì¼ë°˜ ì²œë¬¸ìƒìˆ˜",
    "text": "ì¼ë°˜ ì²œë¬¸ìƒìˆ˜\n\ní‘œë©´ì¤‘ë ¥, íƒœì–‘ìƒìˆ˜, í‘œë©´íƒˆì¶œì†ë„, í‘œë©´ìœ íš¨ì˜¨ë„, ì „ë³µì‚¬ì—ë„ˆì§€, í‘œë©´ë³µì‚¬ì—ë„ˆì§€\nì§ˆëŸ‰ì´ Mì¸ ì²œì²´ì˜ ë°˜ì§€ë¦„ì´ Rì´ë¼ë©´ í‘œë©´ì¤‘ë ¥ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í•  ìˆ˜ ìžˆë‹¤.\n\n\\text{í‘œë©´ì¤‘ë ¥} = \\frac{GM}{R^2}\n\níƒœì–‘ìœ¼ë¡œë¶€í„° 1 \\text{ au}ë§Œí¼ ë–¨ì–´ì§„ ë‹¨ìœ„ë©´ì ì— ë‹¨ìœ„ì‹œê°„ë™ì•ˆ í†µê³¼í•˜ëŠ” ì´ íƒœì–‘ì—ë„ˆì§€ë¥¼ íƒœì–‘ìƒìˆ˜ë¼ê³ í•œë‹¤. ì¦‰, r=1 \\text{ au}, L = \\text{ê´‘ë„} ì¼ë•Œ ë‹¤ìŒì„ ì–»ëŠ”ë‹¤.\n\n\\text{íƒœì–‘ìƒìˆ˜} = \\frac{L}{4 \\pi r^2}\n\nì§ˆëŸ‰ì´ Mì¸ ì²œì²´ì˜ ë°˜ì§€ë¦„ì´ Rì´ë¼ë©´ í‘œë©´íƒˆì¶œì†ë„ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬í•  ìˆ˜ ìžˆë‹¤. \n\\text{í‘œë©´íƒˆì¶œì†ë„} = \\sqrt{\\frac{2GM}{R}}\n\nì²œì²´ë¥¼ ê·¸ ì²œì²´ì™€ ê°™ì€ ê´‘ë„ë¥¼ ê°€ì§„ í‘ì²´ë¡œ ê°€ì •í–ˆì„ ë•Œ í‘ì²´ê°€ ê°€ì§€ëŠ” ì—´í‰í˜•ì˜¨ë„ë¥¼ í‘œë©´ìœ íš¨ì˜¨ë„ë¼ê³  í•œë‹¤. \n\\text{í‘œë©´ìœ íš¨ì˜¨ë„} = T_e = \\left( \\frac{F_R}{\\sigma} \\right)^{1/4}\n\nì²œì²´ê°€ ë‹¨ìœ„ ì‹œê°„ ë™ì•ˆ ë°©ì¶œí•˜ëŠ” ì´ì—ë„ˆì§€ë¥¼ ì „ë³µì‚¬ì—ë„ˆì§€(ë˜ëŠ” ê´‘ë„)ë¼ê³  í•œë‹¤. \n\\text{ì „ë³µì‚¬ì—ë„ˆì§€} = L = \\text{ê´‘ë„}\n\nì²œì²´ì˜ ë‹¨ìœ„ í‘œë©´ì ì´ ë‹¨ìœ„ ì‹œê°„ ë™ì•ˆ ë°©ì¶œí•˜ëŠ” ì´ì—ë„ˆì§€ë¥¼ í‘œë©´ë³µì‚¬ì—ë„ˆì§€ë¼ê³  í•œë‹¤. \n\\text{í‘œë©´ë³µì‚¬ì—ë„ˆì§€} = F_R = \\frac{L}{4 \\pi R^2}\n\n\n\nì´ì‹¬ë¥ \në‹«ížŒ ê³µì „ ê¶¤ë„ëŠ” íƒ€ì› ê¶¤ë„ì´ê³ , íƒ€ì›ì˜ ìž¥ë°˜ê²½ a, ë‹¨ë°˜ê²½ bì— ëŒ€í•´ ê¶¤ë„ì˜ ì´ì‹¬ë¥ (eccentricity) eëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤. \ne = \\frac{\\sqrt{a^2 - b^2}}{a}\n\n\n\nì ë„ ìˆ˜í‰ ì‹œì°¨\nì ë„ìƒì˜ í•œ ê´€ì¸¡ìž ì²œì •ì— ì²œì²´ê°€ ìœ„ì¹˜í•œë‹¤ê³  í•˜ìž. ê·¸ ê´€ì¸¡ìžë¡œë¶€í„° ì ë„ë¥¼ ë”°ë¼ 90^\\circë§Œí¼ ë–¨ì–´ì ¸ ìžˆëŠ” ê´€ì¸¡ìžê°€ ê°™ì€ ì²œì²´ë¥¼ ë°”ë¼ë³¸ë‹¤ê³  í•˜ìž. ì´ë•Œ ë‘ ê´€ì¸¡ìžì˜ ì‹œì„ ë°©í–¥ì´ ì´ë£¨ëŠ” ê°ì„ ì ë„ ìˆ˜í‰ ì‹œì°¨(equatorial horizontal parallax)ë¼ê³  í•œë‹¤.\në”°ë¼ì„œ ë‹¬ì˜ ì ë„ ìˆ˜í‰ ì‹œì°¨ \\piëŠ” ì§€êµ¬ ì ë„ ë°˜ê²½ R, ì§€êµ¬ ì¤‘ì‹¬ì—ì„œ ë‹¬ê¹Œì§€ì˜ ê±°ë¦¬ rì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ì£¼ì–´ì§„ë‹¤.\n\n\\pi = \\arcsin \\left( \\frac{R}{r} \\right)\n\n\n\nìž¥ë™ì£¼ê¸° (êµì ì£¼ê¸°)\n\n\n\n\n\nì²œì²´ì˜ ê³µì „ê¶¤ë„ê°€ ì–´ë–¤ ê¸°ì¤€í‰ë©´ê³¼ ë§Œë‚˜ëŠ” 2ê°œì˜ ì ì„ í†µí‹€ì–´ì„œ ê¶¤ë„ êµì (orbital node)ì´ë¼ê³  í•˜ë©°, ê¸°ì¤€í‰ë©´ì˜ ì–´ëŠ í•œìª½ì„ ìœ„ìª½ìœ¼ë¡œ ì •ì˜í•˜ì˜€ì„ ë•Œ, ì²œì²´ê°€ ì•„ëž˜ì—ì„œ ìœ„ë¡œ ì˜¬ë¼ì˜¤ëŠ” êµì ì„ ìŠ¹êµì (ascending node), ìœ„ì—ì„œ ì•„ëž˜ë¡œ ë‚´ë ¤ê°€ëŠ” êµì ì„ ê°•êµì (descending node)ì´ë¼ê³  í•œë‹¤.\nê¸°ì¤€í‰ë©´ì„ í™©ë„í‰ë©´ìœ¼ë¡œ í•˜ì˜€ì„ë•Œ, ë‹¬ì˜ ê³µì „ê¶¤ë„ì— ëŒ€í•œ ê¶¤ë„êµì ì„ ë‹¬ì˜ êµì (Lunar node)ì´ë¼ê³  í•œë‹¤. ì§€êµ¬ì˜ ìž¥ë™ ìš´ë™ì„ ë°œìƒì‹œí‚¤ëŠ” ì£¼ ì›ì¸ì´ ë‹¬ì´ê¸° ë•Œë¬¸ì—, ì´ì— ëŒ€í•œ ë°˜ìž‘ìš©ìœ¼ë¡œ ë‹¬ì˜ êµì ì´ ë³€í•˜ê²Œ ëœë‹¤. ë‹¬ì˜ êµì ì´ í™©ë„ë¥¼ ë”°ë¼ í•œë°”í€´ íšŒì „í•˜ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì€ ì§€êµ¬ì˜ ìž¥ë™ ìš´ë™ì£¼ê¸°ì™€ ê°™ì€ ì•½18.61ë…„ì´ë‹¤. ë”°ë¼ì„œ ì´ê²ƒì„ ìž¥ë™ì£¼ê¸°(nodal period) ë˜ëŠ” êµì ì£¼ê¸°(draconic period)ë¼ê³  í•œë‹¤.\n\n\nì‚¬ë¡œìŠ¤ ì£¼ê¸°\nì‚¬ë¡œìŠ¤ì£¼ê¸°(saros)ëŠ” íƒœì–‘, ë‹¬, ì§€êµ¬ì˜ ìƒëŒ€ì  ìœ„ì¹˜ ê´€ê³„ê°€ ë°˜ë³µë˜ëŠ” ì£¼ê¸°ë¡œ, ì •í™•ížˆ 223 ì‚­ë§ì›”(synodic month)ì´ë‹¤.\n\n\nì˜¤ì˜¤íŠ¸ ìƒìˆ˜\nì€í•˜ë©´(galactic midplane)ì— ì¡´ìž¬í•˜ëŠ”, ì€ê²½(galactic longitude)ì´ \\ellì¸ ìž„ì˜ì˜ ì²œì²´ê°€ íƒœì–‘ìœ¼ë¡œë¶€í„° ë–¨ì–´ì§„ ê±°ë¦¬ê°€ dë¼ê³  í•˜ìž. ê·¸ëŸ¬ë©´ íƒœì–‘ì— ëŒ€í•œ ê·¸ ì²œì²´ì˜ ìƒëŒ€ì†ë„ì˜ ì‹œì„ ë°©í–¥ ì„±ë¶„(radial component)ê³¼ ì ‘ì„  ë°©í–¥ ì„±ë¶„(tangential component)ì€ ë‹¤ìŒê³¼ ê°™ì´ ì£¼ì–´ì§„ë‹¤.\n\nv_r \\approx Ad\\sin(2\\ell)\n\n\nv_t \\approx Ad\\sin(2\\ell) + Bd\n\nì—¬ê¸°ì„œ A, Bê°€ ì˜¤ì˜¤íŠ¸ ìƒìˆ˜(Oort constant)ì´ë‹¤."
  },
  {
    "objectID": "posts/explain-words/index.html#ì •ì˜¤í‘œ",
    "href": "posts/explain-words/index.html#ì •ì˜¤í‘œ",
    "title": "ì²œë¬¸ìš©ì–´ ì„¤ëª…",
    "section": "ì •ì˜¤í‘œ",
    "text": "ì •ì˜¤í‘œ\n\nì§€êµ¬ í‰ê·  ê°ìš´ë™ëŸ‰\n\n\n\\text{ì§€êµ¬ í‰ê·  ê°ìš´ë™ëŸ‰} \\rightarrow \\text{ì§€êµ¬ í‰ê·  ê°ì†ë„}\n\nì§€êµ¬ í‰ê·  ê°ì†ë„ëŠ” ì§€êµ¬ì˜ í‰ê·  ìžì „ ê°ì†ë„ì´ë‹¤.\n\n\níƒœì–‘-(ì§€êµ¬+ë‹¬) ì§ˆëŸ‰ë¹„\n \n(S/E)(l+\\mu) \\rightarrow (S/E)(1+\\mu)\n\n\n\\because \\frac{S}{E+M_M} = \\frac{S}{E+\\mu E} = \\frac{S}{E}\\frac{1}{1+\\mu} = (S/E)(1+\\mu)\n\n\n\nì „ìžë³¼íŠ¸\n \neV = \\frac{e}{c} J \\rightarrow \\text{eV} = (e/\\text{C}) \\text{ J}\n\nì—¬ê¸°ì„œ \\text{J}ëŠ” ì—ë„ˆì§€ì˜ ë‹¨ìœ„ ì¤„(joule)ì´ê³ , (e/\\text{C})ëŠ” ì¿¨ë¡¬(coulomb) ë‹¨ìœ„ë¡œ ë‚˜íƒ€ë‚¸ ê¸°ë³¸ ì „í•˜(elementary charge)ì˜ ê°’ì´ë‹¤."
  },
  {
    "objectID": "posts/explain-words/index.html#ì°¸ê³ ë¬¸í—Œ",
    "href": "posts/explain-words/index.html#ì°¸ê³ ë¬¸í—Œ",
    "title": "ì²œë¬¸ìš©ì–´ ì„¤ëª…",
    "section": "ì°¸ê³ ë¬¸í—Œ",
    "text": "ì°¸ê³ ë¬¸í—Œ\n\nCAPITAINE, Nicole; WALLACE, Patrick T.; CHAPRONT, Jean. Expressions for IAU 2000 precession quantities. Astronomy & Astrophysicsâ€‹, 2003, 412.2: 567-586.\nCARROLL, Bradley W.; OSTLIE, Dale A. An introduction to modern astrophysicsâ€‹. Cambridge University Press, 2017.\nLIESKE, J.H., et al.Â Expressions for the precession quantities based upon the IAU/1976/system of astronomical constants. Astronomy and Astrophysicsâ€‹, 1977, 58: 1-16.\nMCCARTHY, Dennis D.; SEIDELMANN, P.Kenneth. Time: from Earth rotation to atomic physicsâ€‹. Cambridge University Press, 2018.\nVÃ–LGYESI, L. Physical backgrounds of Earthâ€™s rotation, revision of the terminology. Acta Geodaetica et Geophysica Hungaricaâ€‹, 2006, 41.1: 31-44.\nBIPM - Time, https://www.bipm.org/en/bipm/tai/\nFIG Article of the Month - December 2004, https://www.fig.net/resources/monthly_articles/2004/beutLer_july_2004.asp\nFile:Lunar eclipse diagram-en.svg - Wikimedia Commons, https://commons.wikimedia.org/wiki/File:Lunar_eclipse_diagram-en.svg\nFile:Praezession.svg - Wikimedia Commons, https://commons.wikimedia.org/wiki/File:Praezession.svg#mw-jump-to-license\nFile:Simple stellar aberration diagram.svg - Wikimedia Commons, https://commons.wikimedia.org/wiki/File:Simple_stellar_aberration_diagram.svg\nFundamental Physical Constants from NIST, https://pml.nist.gov/cuu/Constants/\nReference Earth Model - WGS84, https://topex.ucsd.edu/geodynamics/14gravity1_2.pdf\nThe Astronomical Almanac Online, http://asa.hmnao.com/index.html\nê¸°ë³¸ë‹¨ìœ„ì˜ ì •ì˜, https://www.kriss.re.kr/standard/view.do?pg=explanation_tab_02"
  },
  {
    "objectID": "posts/low_lou_force_free/index.html",
    "href": "posts/low_lou_force_free/index.html",
    "title": "Low and Lou (1990) force free magnetic fields",
    "section": "",
    "text": "Force free magnetic fields are defined as magnetic fields without Lorentz force\n\\begin{align*}\n\\mathbf{J} \\times \\mathbf{B} & = \\mathbf{0} \\\\\n\\nabla \\cdot \\mathbf{B} & = 0\n\\end{align*}\nIn magnetohydrodynamics (MHD), the current density \\mathbf{J} is given by (in SI units)\n\\mathbf{J} = \\frac{1}{\\mu_0} \\nabla \\times \\mathbf{B}\nTherefore, force free magnetic fields are determined by the following partial differential equations (PDEs)\n\\begin{align*}\n\\mathbf{(\\nabla \\times \\mathbf{B})} \\times \\mathbf{B} & = \\mathbf{0} \\\\\n\\nabla \\cdot \\mathbf{B} & = 0\n\\end{align*}\nThe analytical solution of these PDEs in a general case is unknown. But Low and Lou (1990) shows that we can calculate â€œaxisymmetricâ€ force free fields. If we rotate the plane perpendicular to the axis of symmetry, we can generate a quite general force free fields. In this post, I try to calculate this Low and Lou fields, referencing this code."
  },
  {
    "objectID": "posts/low_lou_force_free/index.html#low-lou-ode",
    "href": "posts/low_lou_force_free/index.html#low-lou-ode",
    "title": "Low and Lou (1990) force free magnetic fields",
    "section": "Low-Lou ODE",
    "text": "Low-Lou ODE\nTo calculate Low and Lou fields, we have to solve the following ordinary differential equation (ODE).\n\\begin{cases}\n\\displaystyle (1-\\mu^2)\\frac{d^2 P}{d\\mu^2} + n(n+1)P + a^2 \\frac{1+n}{n}P^{1 + \\frac{2}{n}} = 0 \\\\\n\\mu = \\cos\\theta \\in [-1, 1] \\\\\nP(-1) = 0 \\\\\nP(1) = 0 \\\\\n\\\\\nP'(-1) = 10 \\text{ for numerical normalization}\n\\end{cases}\n\nFor fixed n, a serves as a eignvalue for this homogenous BVP.\nFor n=1, we can list the positive eigenvalues in ascending order with m=0, 1, 2, ....\nWe denote a eigenvalue as a^2 _{n, m} and the corresponding eigenfunction as P_{n, m}.\nFor n=1, m=0, 1, 2,\n\n\\begin{align}\na^2 _{1, 0} &= 0 \\\\\na^2 _{1, 1} &= 0.425 \\\\\na^2 _{1, 2} &= 2.55 \\\\\n\\end{align}\n\nIf you carefully see the Figure 1 by Low and Lou (1990), we can notice that\nP_{1,0} (\\mu) \\sim \\cos\\left(\\displaystyle\\frac{\\pi}{2} \\mu\\right)\nP_{1,1} (\\mu) \\sim -\\sin\\left(\\displaystyle\\pi \\mu\\right)\nP_{1,2} (\\mu) \\sim -\\cos\\left(\\displaystyle\\frac{3\\pi}{2} \\mu\\right)\nThen we can generally say that\nFor m=0, 2 (even m)\nP_{1,m} (\\mu) \\sim \\cos\\left(\\displaystyle\\frac{(m + 1)\\pi}{2} \\mu\\right)\nFor m=1 (odd m) P_{1,m} (\\mu) \\sim \\sin\\left(\\displaystyle\\frac{(m + 1)\\pi}{2} \\mu\\right)\nThis is the initial guess of the solution.\n\nRewrite Low-Lou ODE using \\mathbf{S}(\\mu)\n\n(1-\\mu^2)P'' + n(n+1)P + a^2 \\frac{1+n}{n}P^{1 + \\frac{2}{n}} = 0\n\n\n\\rightarrow P'' =  \\frac{1}{1-\\mu^2}\\left[- n(n+1)P - a^2 \\frac{1+n}{n}P^{1 + \\frac{2}{n}}\\right]\n\n\n\\rightarrow P'' =  \\frac{-1}{1-\\mu^2 + \\epsilon}\\left[n(n+1)P + a^2 \\frac{1+n}{n}P^{1 + \\frac{2}{n}}\\right]\n\nwhere \\epsilon = 10^{-6} for numerical stability.\nTarget y \n\\mathbf{S}(\\mu) = \\begin{bmatrix}\n                     P(\\mu) \\\\\n                     P'(\\mu)\n                 \\end{bmatrix}\n              = \\begin{bmatrix}\n                     y[0] \\\\\n                     y[1]\n                 \\end{bmatrix}\n\nODE system F(x, y) \n\\frac{d\\mathbf{S}}{d\\mu} = \\mathbf{F}(\\mu, \\mathbf{S}(\\mu))\n                         = \\begin{bmatrix}\n                             P'(\\mu) \\\\\n                             P''(\\mu)\n                           \\end{bmatrix}\n                         = \\begin{bmatrix}\n                             y[1] \\\\\n                            \\displaystyle \\frac{-1}{1-\\mu^2 + \\epsilon}\\left[n(n+1)P + a^2 \\frac{1+n}{n}P^{1 + \\frac{2}{n}}\\right]\n                           \\end{bmatrix}   \n\n\\begin{cases}\n\\mu = \\cos\\theta \\in [-1, 1] \\\\\nP(-1) = 0 \\\\\nP(1) = 0 \\\\\n\\end{cases}\n\n\nP'(-1) = 10\n\nDomain\nmu_span = [-1, 1]\nN = 100 # number of points\nmu = np.linspace(mu_span[0], mu_span[1], N)\nBoundary condition function bc defined from ya, yb\n\n\\text{ya} = \\mathbf{S}(-1) = \\begin{bmatrix}\n                                 P(-1) \\\\\n                                 P'(-1)\n                             \\end{bmatrix}\n                          = \\begin{bmatrix}\n                                 0 \\\\\n                                 10\n                             \\end{bmatrix}\n                          = \\begin{bmatrix}\n                                 \\text{ya}[0] \\\\\n                                 \\text{ya}[1]\n                             \\end{bmatrix}\n\n\n\\text{yb} = \\mathbf{S}(1) = \\begin{bmatrix}\n                                 P(1) \\\\\n                                 P'(1)\n                             \\end{bmatrix}\n                            = \\begin{bmatrix}\n                                 0 \\\\\n                                 ?\n                              \\end{bmatrix}\n                            = \\begin{bmatrix}\n                                 \\text{yb}[0] \\\\\n                                 \\text{yb}[1]\n                              \\end{bmatrix}\n\n\n\\text{bc} = \\begin{bmatrix}\n                 \\text{ya} - \\mathbf{S}(-1) \\\\\n                 \\text{yb} - \\mathbf{S}(1)\n            \\end{bmatrix}\n          = \\begin{bmatrix}\n                 \\text{ya}[0] - 0 \\\\\n                 \\text{ya}[1] - 10 \\\\\n                 \\text{yb}[0] - 0\n            \\end{bmatrix}\n          = \\begin{bmatrix}\n                 \\text{ya}[0] \\\\\n                 \\text{ya}[1] - 10\\\\\n                 \\text{yb}[0]\n            \\end{bmatrix}\n\nInitial guess y0\nFor the given spacing h,\n\n\\begin{align}\n\\text{y0} & = [\\mathbf{S}(-1), \\mathbf{S}(-1 + h), \\mathbf{S}(-1 + 2h), \\cdots, \\mathbf{S}(1)] \\\\\n          & = \\begin{bmatrix}\n                  P(\\mu=-1) & P(\\mu=-1+h) & P(\\mu=-1+2h) & \\cdots & P(\\mu=1) \\\\\n                  P'(\\mu=-1) & P'(\\mu=-1+h) & P'(\\mu=-1+2h) & \\cdots & P'(\\mu=1) \\\\\n               \\end{bmatrix}\n\\end{align}\n\nFor m=0, 2 (even m)\nP_{1,m} (\\mu) \\sim \\cos\\left(\\displaystyle\\frac{(m + 1)\\pi}{2} \\mu\\right)\nFor m=1 (odd m) P_{1,m} (\\mu) \\sim \\sin\\left(\\displaystyle\\frac{(m + 1)\\pi}{2} \\mu\\right)\nif m % 2 == 0:\n    P_init = np.cos(mu * (m + 1) * np.pi / 2)\nelse:\n    P_init = np.sin(mu * (m + 1) * np.pi / 2)\nSince P'(-1) = 10,\ndP_init = 10*np.ones_like(mu)\nThen, together,\nS_init = np.vstack([P_init, dP_init])\n\nimport numpy as np \nfrom scipy.integrate import solve_bvp\nimport matplotlib.pyplot as plt \n\n\ndef find_P_and_a2(n, m):\n\n    # ODE system\n    # Define BVP (Low and Lou 1990)\n    # a2 -&gt; eigenvalue\n    # S = [P, dP/dmu]\n    # F = dSdmu\n    # \n    # dP/dmu = 10 at mu = -1\n    def F(x, y, p):\n        mu = x\n        P = y[0]\n        dP = y[1]\n        a2 = p[0]\n\n        ddP = (-1)*(n*(n+1)*P + a2*((1+n)/n)*P**(1+2/n)) / (1-mu**2 + 1e-6)\n\n        return [dP, ddP] \n\n    # Boundary Condition\n    def bc(ya, yb, p):\n        return [ya[0], ya[1]-10, yb[0]]\n\n    # Domain\n    mu_span = [-1, 1]\n    N = 100\n    mu = np.linspace(mu_span[0], mu_span[1], N)\n\n    # Initial guess\n    # For given m, use different initial guess\n    if m % 2 == 0:\n        P_guess = np.cos(mu * (m + 1) * np.pi / 2)\n    else:\n        P_guess = np.sin(mu * (m + 1) * np.pi / 2)\n\n    # For initial guess of dP/dmu, just use BC value\n    dP_guess = 10*np.ones_like(mu)\n\n    y_guess = np.vstack([P_guess, dP_guess])\n\n    # For each initial eigenvalue, solve the problem.\n    # If it is successful, return that otherwise do not return.\n    # np.vectorize -&gt; for loop & return type : array\n    @np.vectorize\n    def solve_eigenvalue_problem(a2_0):\n        sol = solve_bvp(F, bc, mu, y_guess, p=[a2_0], tol=1e-6)\n        if sol.success == True:\n            return sol\n        else:\n            return None \n\n    a2_0_list = np.linspace(0.0, 10.0, 100)\n\n    results = solve_eigenvalue_problem(a2_0_list)\n    eigenvalues = np.array([sol.p for sol in results if sol is not None])\n\n\n     # round & unique value & sorting\n    eigenvalues = np.sort(np.unique(np.round(eigenvalues, 4)))\n    \n    # The smallest value for given m is desired eigenvalue\n    eigenvalue = eigenvalues[0]\n    # If this eigenvalue is zero for nonzero m, choose the next big eigenvalue\n    if m &gt; 0:\n        if not (eigenvalue &gt; 0):\n            eigenvalue = eigenvalues[1]\n\n    # Solve again with that eigenvalue\n    sol = solve_eigenvalue_problem([eigenvalue])[0]\n    \n    return sol.sol, sol.p[0]\n\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.grid(True)\nax.axhline(0, color='k', lw=2)\nax.axvline(0, color='k', lw=2)\nax.set_xlabel(r'$\\mu$')\nax.set_ylabel(r'P($\\mu$)')\n\nmu_plot = np.linspace(-1, 1, 1000)\n\nn = 1\nfor m in [0, 1, 2]:\n    \n    S, a2 = find_P_and_a2(n, m)\n    P_plot = S(mu_plot)[0]\n    \n    if a2 &lt; 1e-3:\n        P_label = 'P' r'$_{' f'{n}, {m}' r'}(\\mu)$ with $a^2' r'_{' f'{n}, {m}' r'}$ = 0'\n    else:\n        P_label = 'P' r'$_{' f'{n}, {m}' r'}(\\mu)$ with $a^2' r'_{' f'{n}, {m}' r'}$ = ' f'{a2:.3g}'\n    ax.plot(mu_plot, P_plot, label=P_label)\n\nfig.legend()\n\n\n\n\n\n\n\n\nWe successfuly solve Low-Lou ODE for n=1, m=0, 1, 2. (see Figure 1 by Low and Lou (1990))"
  },
  {
    "objectID": "posts/low_lou_force_free/index.html#parameters",
    "href": "posts/low_lou_force_free/index.html#parameters",
    "title": "Low and Lou (1990) force free magnetic fields",
    "section": "Parameters",
    "text": "Parameters\n\nbounds\nbounds=[x_min, x_max, y_min, y_max, z_min, z_max]\n\n\nresolutions\nresolutions=[Nx, Ny, Nz] where Nx, Ny, Nz respectively mean that the number of points in x-, y-, z-axis.\n\n\nn & m\nP_{n,m}(\\mu) & a^2 _{n,m} are eigenfunction and eigenvalues for Low-Lou ODE with fixed n. And m is just used for denoting differenct eigenfunction and eigenvalues.\n\n\\displaystyle (1-\\mu^2)\\frac{d^2 P_{n,m}}{d\\mu^2} + n(n+1)P_{n,m} + a^2 _{n,m} \\frac{1+n}{n}P_{n,m}^{1 + \\frac{2}{n}} = 0\n\n\n\nl & \\Phi\nSee Figure 2 by Low and Lou (1990)"
  },
  {
    "objectID": "posts/low_lou_force_free/index.html#algorithm",
    "href": "posts/low_lou_force_free/index.html#algorithm",
    "title": "Low and Lou (1990) force free magnetic fields",
    "section": "Algorithm",
    "text": "Algorithm\nFor each physical coordinate (x, y, z),\nCalculate corresponding\n\nlocal Cartesian coordinate (X, Y, Z)\nlocal spherical coordinate (r, \\theta, \\phi)\n\\mu = \\cos\\theta\nP'_{n,m}(\\mu) and P_{n,m}(\\mu) by solving Low-Lou ODE\n(B_r, B_\\theta, B_\\phi)\n(B_X, B_Y, B_Z)\n(B_x, B_y, B_z)\n\nThen, we get a vector (B_x, B_y, B_z) at the point (x, y, z)\nThe local spherical coordinates are\nr = \\sqrt{X^2 + Y^2 + Z^2}\n\\theta= \\arccos\\frac{Z}{r}\n\\phi = \\arctan2\\frac{Y}{X}\nS refers to \\mathbf{S}_{n,m}(\\mu) and a2 refers to a^2 _{n,m}\n\n\\mathbf{S}_{n,m}(\\mu) = \\begin{bmatrix}\n                     P_{n,m}(\\mu) \\\\\n                     P'_{n,m}(\\mu)\n                 \\end{bmatrix}\n\nThe magnetic field is\n\n\\mathbf{B}(r, \\theta, \\phi) = B_r \\hat{r} + B_\\theta \\hat{\\theta} + B_\\phi \\hat{\\phi}\n\nwhere\n\nB_r = \\frac{1}{r^2 \\sin\\theta} \\frac{\\partial A}{\\partial \\theta}\n\n\nB_\\theta = -\\frac{1}{r \\sin\\theta} \\frac{\\partial A}{\\partial r}\n\n\nB_\\phi = \\frac{Q}{r \\sin\\theta}\n\nHere A is\n\nA = (r^{-n})P_{n,m}(\\mu)\n\n\n\\frac{\\partial A}{\\partial \\theta} = (- r^{-n}\\sin\\theta) P'_{n,m}(\\mu)\n\n\n\\frac{\\partial A}{\\partial r} = (-n r^{-n-1}) P_{n,m}(\\mu)\n\nFor n=1,\n\nQ(A) = \\sqrt{a^2 _{n,m}} A^{1 + \\frac{1}{n}}\n\n\n\\alpha = \\sqrt{a^2 _{n,m}} \\left(1 + \\frac{1}{n} \\right) A^{\\frac{1}{n}}\n\n\nimport pyvista as pv\npv.set_jupyter_backend('static')\npv.global_theme.notebook = True\npv.start_xvfb()\n\n\nclass LowLouMag:\n    \"A Low and Lou (1990) NLFFF\"\n\n    \n    def __init__(self, \n                 bounds=[-1,1,-1,1,0,2],\n                 resolutions=[64,64,64],\n                 n=1, m=1,\n                 l=0.3, Phi=np.pi/2):\n        self.bounds = bounds\n        self.resolutions = resolutions\n        self.n = n\n        self.m = m\n        self.l = l\n        self.Phi = Phi\n        \n\n    def __str__(self): \n        return (\n            \"### Low and Lou (1990) NLFFF\\n\"\n            f\"bounds = {self.bounds}&lt;br&gt;\\n\"\n            f\"resolutions = {self.resolutions}&lt;br&gt;\\n\"\n            f\"n = {self.n}&lt;br&gt;\\n\"\n            f\"m = {self.m}&lt;br&gt;\\n\"\n            f\"l = {self.l}&lt;br&gt;\\n\"\n            f\"Phi = {self.Phi/np.pi}Ï€&lt;br&gt;\\n\"\n        )\n    _repr_markdown_ = __str__\n\n\n    def create_physical_coordinates(self):\n        x_1D = np.linspace(self.bounds[0], self.bounds[1], self.resolutions[0])\n        y_1D = np.linspace(self.bounds[2], self.bounds[3], self.resolutions[1])\n        z_1D = np.linspace(self.bounds[4], self.bounds[5], self.resolutions[2])\n        x_spacing = np.diff(x_1D)[0]\n        y_spacing = np.diff(y_1D)[0]\n        z_spacing = np.diff(z_1D)[0]\n        spacing = (x_spacing, y_spacing, z_spacing)\n        origin = (x_1D[0], y_1D[0], z_1D[0]) # The bottom left corner of the data set\n        self.grid = pv.ImageData(dimensions=self.resolutions, spacing=spacing, origin=origin)\n        self.x_1D = x_1D\n        self.y_1D = y_1D\n        self.z_1D = z_1D\n        return self.grid\n    \n\n    def calculate_local_Cartesian_coordinates(self):\n        # information of point source & Z-axis\n        l = self.l\n        Phi = self.Phi\n        \n        # physical coordinates (x, y, z)\n        x = self.grid.x\n        y = self.grid.y\n        z = self.grid.z\n\n        # local Cartesian coordinates (X, Y, Z)\n        X = x*np.cos(Phi) - (z+l)*np.sin(Phi)\n        Y = y\n        Z = x*np.sin(Phi) + (z+l)*np.cos(Phi)\n\n        self.X, self.Y, self.Z = X, Y, Z\n\n\n    def calculate_local_spherical_coordinates(self):\n        # local Cartesian coordinates (X, Y, Z)\n        X = self.X\n        Y = self.Y\n        Z = self.Z\n\n        # local spherical coordinates (r, theta, phi)\n        r = np.sqrt(X**2 + Y**2 + Z**2)\n        theta = np.arccos(Z/r)\n        phi = np.arctan2(Y, X) \n\n        self.r, self.theta, self.phi = r, theta, phi\n\n\n    def calculate_eigenfunctions(self):\n        # calculate mu=cos(theta)\n        mu = np.cos(self.theta)\n\n        # eigenfunction parameter n, m\n        n = self.n\n        m = self.m\n\n        # calculate eigenfunction & its derivates and eigenvalues\n        # S = [P, dP]\n        S, a2 = find_P_and_a2(n, m)\n        P, dP = S(mu)\n\n        self.P, self.dP, self.a2 = P, dP, a2\n\n\n    def calculate_local_spherical_magnetic_fields(self):\n        # eigenfunctions and eigenvalue\n        n, m = self.n, self.m\n        P, dP, a2 = self.P, self.dP, self.a2\n\n        # r, theta info\n        r, theta = self.r, self.theta\n        \n        A = (r**(-n)) * P\n        dA_dtheta = -(r**(-n)) * np.sin(theta) * dP\n        dA_dr = -(n*(r**(-n-1))) * P\n        Q = np.sqrt(a2) * A * np.abs(A)**(1/n)\n        \n        alpha = np.sqrt(a2) * (1 + 1/n) * A**(1/n)\n        \n        Br = (r**2 * np.sin(theta))**(-1) * dA_dtheta\n        Btheta = -1 * (r*np.sin(theta))**(-1) * dA_dr\n        Bphi = (r*np.sin(theta))**(-1) * Q\n        \n        self.Br, self.Btheta, self.Bphi, self.alpha = Br, Btheta, Bphi, alpha\n\n\n    def calculate_local_Cartesian_magnetic_fields(self):\n        Br, Btheta, Bphi = self.Br, self.Btheta, self.Bphi\n        r, theta, phi = self.r, self.theta, self.phi\n        \n        BX = Br * np.sin(theta) * np.cos(phi) + Btheta * np.cos(theta) * np.cos(phi) - Bphi * np.sin(phi)\n        BY = Br * np.sin(theta) * np.sin(phi) + Btheta * np.cos(theta) * np.sin(phi) + Bphi * np.cos(phi)\n        BZ = Br * np.cos(theta) - Bphi * np.sin(theta)\n        \n        self.BX, self.BY, self.BZ = BX, BY, BZ\n\n\n    def calculate_physical_magnetic_fields(self):\n        BX, BY, BZ = self.BX, self.BY, self.BZ\n        Phi = self.Phi\n\n        Bx = BX * np.cos(Phi) + BZ * np.sin(Phi)\n        By = BY\n        Bz = - BX * np.sin(Phi) + BZ * np.cos(Phi)\n        \n        self.Bx, self.By, self.Bz = Bx, By, Bz\n\n    def calculate_final_magnetic_fields(self):\n        bx = self.Bx.reshape(self.resolutions).transpose(2, 1, 0)\n        by = self.By.reshape(self.resolutions).transpose(2, 1, 0)\n        bz = self.Bz.reshape(self.resolutions).transpose(2, 1, 0)\n        return bx, by, bz\n\n    ##------ All in one ------##\n    def calculate(self):\n        self.create_physical_coordinates()\n        self.calculate_local_Cartesian_coordinates()\n        self.calculate_local_spherical_coordinates()\n        self.calculate_eigenfunctions()\n        self.calculate_local_spherical_magnetic_fields()\n        self.calculate_local_Cartesian_magnetic_fields()\n        self.calculate_physical_magnetic_fields()\n        bx, by, bz = self.calculate_final_magnetic_fields()\n        return bx, by, bz\n\n\nb = LowLouMag()\nb\n\nLow and Lou (1990) NLFFF\nbounds = [-1, 1, -1, 1, 0, 2] resolutions = [64, 64, 64] n = 1 m = 1 l = 0.3 Phi = 0.5Ï€\n\n\n\nb.create_physical_coordinates()\n\n\n\n\nImageData\nInformation\n\n\nN Cells\n250047\n\n\nN Points\n262144\n\n\nX Bounds\n-1.000e+00, 1.000e+00\n\n\nY Bounds\n-1.000e+00, 1.000e+00\n\n\nZ Bounds\n0.000e+00, 2.000e+00\n\n\nDimensions\n64, 64, 64\n\n\nSpacing\n3.175e-02, 3.175e-02, 3.175e-02\n\n\nN Arrays\n0\n\n\n\n\n\n\nb.calculate_local_Cartesian_coordinates()\n\n\nb.grid.x[0], b.grid.y[0], b.grid.z[0]\n\n(-1.0, -1.0, 0.0)\n\n\n\nb.X[0], b.Y[0], b.Z[0]\n\n(-0.30000000000000004, -1.0, -1.0)\n\n\n\nb.calculate_local_spherical_coordinates()\n\n\nb.r[0], b.theta[0], b.phi[0]\n\n(1.445683229480096, 2.3346567297775978, -1.8622531212727638)\n\n\n\nb.calculate_eigenfunctions()\n\n\nb.P[0], b.dP[0], b.a2\n\n(2.3671821639686197, 4.145376627987454, 0.4274037235234833)\n\n\n\nb.calculate_local_spherical_magnetic_fields()\n\n\nb.Br[0], b.Btheta[0], b.Bphi[0], b.alpha[0]\n\n(-1.3719698429432043,\n 1.0848561237109233,\n 1.6788928338597737,\n 2.140955710310132)\n\n\n\nb.calculate_local_Cartesian_magnetic_fields()\n\n\nb.BX[0], b.BY[0], b.BZ[0]\n\n(2.108420021547058, 1.185348144787035, -0.26343650351723624)\n\n\n\nb.calculate_physical_magnetic_fields()\n\n\nb.Bx[0], b.By[0], b.Bz[0]\n\n(-0.26343650351723613, 1.185348144787035, -2.108420021547058)\n\n\n\nbx, by, bz = b.calculate_final_magnetic_fields()\n\n\n!pip install -q git+https://github.com/mgjeon/magnetic_field_line.git\n\n\nfrom magplot.base import create_mesh, mag_plotter\n\n\nmesh = create_mesh(bx, by, bz)\n\n\nb_plot = mag_plotter(mesh)\nb_tube, b_bottom, b_dargs = b_plot.create_mesh(i_siz=32, j_siz=32, \n                                               i_resolution=8, j_resolution=8, \n                                               vmin=-100, vmax=100, \n                                               max_time=10000)\n\n\np = pv.Plotter()\np.add_mesh(b_plot.grid.outline())\np.add_mesh(b_bottom, cmap='gray', **b_dargs)\np.add_mesh(b_tube, lighting=False, color='blue')\np.camera_position = 'xy'\np.show_bounds()\np.show()\n\n\n\n\n\n\n\n\n\np = pv.Plotter(off_screen=False)\np.add_mesh(b_plot.grid.outline())\np.add_mesh(pv.Plane(center=(mesh.center[0], mesh.center[1], -1), direction=(0, 0, 1), i_size=64, j_size=64), color='gray')\np.add_mesh(b_bottom.contour(scalars=b_bottom['vector'][:, 2]), cmap='bwr', **b_dargs)\np.add_mesh(b_tube, lighting=False, color='black')\np.camera_position = 'xy'\np.show_bounds()\np.show()\n\n\n\n\n\n\n\n\nIt seems to correspond to Figure 8, not Figure 3. I donâ€™t know why.\n\nmesh_new = create_mesh(*LowLouMag(Phi=np.pi/4).calculate()).reflect((0, 1, 0))\n\nb_plot_new = mag_plotter(mesh_new)\nb_tube_new, b_bottom_new, b_dargs_new = b_plot_new.create_mesh(i_siz=32, j_siz=32, \n                                                   i_resolution=8, j_resolution=8, \n                                                   vmin=-100, vmax=100, \n                                                   max_time=10000)\n\np = pv.Plotter(off_screen=False)\np.add_mesh(b_plot_new.grid.outline())\np.add_mesh(pv.Plane(center=(mesh_new.center[0], mesh_new.center[1], -1), direction=(0, 0, 1), i_size=64, j_size=64), color='gray')\np.add_mesh(b_bottom_new.contour(scalars=b_bottom_new['vector'][:, 2]), cmap='bwr', **b_dargs_new)\np.add_mesh(b_tube_new, lighting=False, color='black')\np.camera_position = 'xy'\np.show_bounds()\np.show()\n\n\n\n\n\n\n\n\n\nmesh_new = create_mesh(*LowLouMag(Phi=0.47).calculate()).reflect((0, 1, 0))\n\nb_plot_new = mag_plotter(mesh_new)\nb_tube_new, b_bottom_new, b_dargs_new = b_plot_new.create_mesh(i_siz=40, j_siz=40, \n                                                   i_resolution=8, j_resolution=8, \n                                                   vmin=-100, vmax=100, \n                                                   max_time=10000)\n\np = pv.Plotter(off_screen=False)\np.add_mesh(b_plot_new.grid.outline())\np.add_mesh(pv.Plane(center=(mesh_new.center[0], mesh_new.center[1], -1), direction=(0, 0, 1), i_size=64, j_size=64), color='gray')\np.add_mesh(b_bottom_new.contour(scalars=b_bottom_new['vector'][:, 2]), cmap='bwr', **b_dargs_new)\np.add_mesh(b_tube_new, lighting=False, color='black')\np.camera_position = 'xy'\np.show_bounds()\np.show()\n\n\n\n\n\n\n\n\n\nmesh_new = create_mesh(*LowLouMag(Phi=0.27).calculate()).reflect((0, 1, 0))\n\nb_plot_new = mag_plotter(mesh_new)\nb_tube_new, b_bottom_new, b_dargs_new = b_plot_new.create_mesh(i_siz=40, j_siz=40, \n                                                   i_resolution=8, j_resolution=8, \n                                                   vmin=-100, vmax=100, \n                                                   max_time=10000)\n\np = pv.Plotter(off_screen=False)\np.add_mesh(b_plot_new.grid.outline())\np.add_mesh(pv.Plane(center=(mesh_new.center[0], mesh_new.center[1], -1), direction=(0, 0, 1), i_size=64, j_size=64), color='gray')\np.add_mesh(b_bottom_new.contour(scalars=b_bottom_new['vector'][:, 2]), cmap='bwr', **b_dargs_new)\np.add_mesh(b_tube_new, lighting=False, color='black')\np.camera_position = 'xy'\np.show_bounds()\np.show()\n\n\n\n\n\n\n\n\nWith reflect((0, 1, 0)), these seems to correspond to Figure 4, 5, and 6, respectively. However, I donâ€™t know why I need to use reflect((0, 1, 0))."
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "",
    "text": "In this post, I perform binary semantic segmentation in PyTorch using a Fully Convolutional Network (FCN) with a ResNet-50 backbone. The model is pre-trained on a subset of COCO using only the 20 categories from the Pascal VOC dataset, and I fine-tune it on the balloon dataset from the Mask R-CNN repository.\nI referred to the code for balloon dataset of Mask R-CNN repository and the colab tutorial of detectron2 for the balloon dataset; and the torchvision semantic segmentaion reference training scripts for the overall code structure."
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#semantic-segmentation",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#semantic-segmentation",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "",
    "text": "In this post, I perform binary semantic segmentation in PyTorch using a Fully Convolutional Network (FCN) with a ResNet-50 backbone. The model is pre-trained on a subset of COCO using only the 20 categories from the Pascal VOC dataset, and I fine-tune it on the balloon dataset from the Mask R-CNN repository.\nI referred to the code for balloon dataset of Mask R-CNN repository and the colab tutorial of detectron2 for the balloon dataset; and the torchvision semantic segmentaion reference training scripts for the overall code structure."
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#balloon-dataset",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#balloon-dataset",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "Balloon dataset",
    "text": "Balloon dataset\nDownload the balloon dataset from Mask R-CNN repository and transform it into a format that is compatible with the binary semantic segmentation task.\ndataset\nâ”œâ”€â”€ train\nâ”‚   â”œâ”€â”€ images\nâ”‚   â”‚   â”œâ”€â”€ &lt;file1&gt;.png\nâ”‚   â”‚   â”œâ”€â”€ &lt;file2&gt;.png\nâ”‚   â”‚   â””â”€â”€ ...\nâ”‚   â””â”€â”€ masks\nâ”‚       â”œâ”€â”€ &lt;file1&gt;.png\nâ”‚       â”œâ”€â”€ &lt;file2&gt;.png\nâ”‚       â””â”€â”€ ...\nâ””â”€â”€ val\n    â”œâ”€â”€ images\n    â”‚   â”œâ”€â”€ &lt;file1&gt;.png\n    â”‚   â”œâ”€â”€ &lt;file2&gt;.png\n    â”‚   â””â”€â”€ ...\n    â””â”€â”€ masks\n        â”œâ”€â”€ &lt;file1&gt;.png\n        â”œâ”€â”€ &lt;file2&gt;.png\n        â””â”€â”€ ...\nDownload the dataset as an zip file.\n\nimport requests\n\nurl = \"https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\"\nfilename = \"balloon_dataset.zip\"\n\nresponse = requests.get(url)\nwith open(filename, \"wb\") as file:\n    file.write(response.content)\n\nExtract the zip file.\n\nimport zipfile\n\nwith zipfile.ZipFile(filename, \"r\") as file:\n    file.extractall()\n\nRemove the unnecessary folder.\n\nimport shutil\n\nshutil.rmtree(\"__MACOSX\")\n\nConvert the dataset into the binary semantic segmentation format.\n\nimport json\nfrom pathlib import Path\nimport numpy as np\nimport skimage\n\ndef create_mask(dataset_dir, new_dataset_dir):\n    dataset_dir = Path(dataset_dir)\n\n    img_dir = Path(new_dataset_dir) / \"images\"\n    mask_dir = Path(new_dataset_dir) / \"masks\"\n    img_dir.mkdir(parents=True, exist_ok=True)\n    mask_dir.mkdir(parents=True, exist_ok=True)\n\n    with open(dataset_dir / \"via_region_data.json\") as file:\n        annotations = json.load(file)\n\n    for idx, v in enumerate(annotations.values()):\n        img = skimage.io.imread(dataset_dir / v[\"filename\"])\n        height, width = img.shape[:2]\n\n        regions = v[\"regions\"]\n\n        mask = np.zeros([height, width], dtype=np.uint8)\n        for region in regions.values():\n            anno = region[\"shape_attributes\"]\n            px = anno[\"all_points_x\"]\n            py = anno[\"all_points_y\"]\n            poly = np.array([[y, x] for x, y in zip(px, py)])\n            mask += skimage.draw.polygon2mask((height, width), poly)\n        mask = mask.astype(np.bool).astype(np.uint8)\n\n        skimage.io.imsave(img_dir / (v[\"filename\"][:-4] + \".png\"), img)\n        skimage.io.imsave(mask_dir / (v[\"filename\"][:-4] + \".png\"), mask)\n\n\ncreate_mask(\"balloon/train\", \"dataset/train\")\ncreate_mask(\"balloon/val\", \"dataset/val\")"
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#dataset",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#dataset",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "Dataset",
    "text": "Dataset\n\nfrom pathlib import Path\n\nfrom torch.utils.data import Dataset\nfrom torchvision import tv_tensors\nfrom torchvision.io import read_image\n\nclass BalloonDataset(Dataset):\n    def __init__(self, dataset_dir, transform=None):\n\n        self.dataset_dir = Path(dataset_dir)\n        self.transform = transform\n\n        self.img_dir = self.dataset_dir / \"images\"\n        self.mask_dir = self.dataset_dir / \"masks\"\n\n        self.imgs = list(self.img_dir.glob(\"*.png\"))\n\n\n    def __len__(self):\n        return len(self.imgs)\n\n\n    def __getitem__(self, idx):\n        img_path = self.imgs[idx]\n        mask_path = self.mask_dir / img_path.name\n\n        img = read_image(img_path)\n        mask = read_image(mask_path)[0]\n\n        img = tv_tensors.Image(img)\n        mask = tv_tensors.Mask(mask)\n\n        sample = {\n            \"image\": img,\n            \"mask\": mask\n        }\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\ncmp = ListedColormap(['black','white'])\n\n\ndataset = BalloonDataset(\"dataset/train\")\n\nsample = dataset[0]\n\nprint(type(sample[\"image\"]))\nprint(sample[\"image\"].shape)\nprint(sample[\"image\"].min(), sample[\"image\"].max())\n\nprint()\n\nprint(type(sample[\"mask\"]))\nprint(sample[\"mask\"].shape)\nprint(sample[\"mask\"].min(), sample[\"mask\"].max())\n\nplt.subplot(1,2,1)\nplt.imshow(sample[\"image\"].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.imshow(sample[\"mask\"], cmap=cmp)\nplt.title(\"Mask\")\nplt.axis(\"off\")\nplt.show()\n\n&lt;class 'torchvision.tv_tensors._image.Image'&gt;\ntorch.Size([3, 1365, 2048])\ntensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n\n&lt;class 'torchvision.tv_tensors._mask.Mask'&gt;\ntorch.Size([1365, 2048])\ntensor(0, dtype=torch.uint8) tensor(1, dtype=torch.uint8)\n\n\n\n\n\n\n\n\n\n\ndataset = BalloonDataset(\"dataset/val\")\n\nsample = dataset[0]\n\nprint(type(sample[\"image\"]))\nprint(sample[\"image\"].shape)\nprint(sample[\"image\"].min(), sample[\"image\"].max())\n\nprint()\n\nprint(type(sample[\"mask\"]))\nprint(sample[\"mask\"].shape)\nprint(sample[\"mask\"].min(), sample[\"mask\"].max())\n\nplt.subplot(1,2,1)\nplt.imshow(sample[\"image\"].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.imshow(sample[\"mask\"], cmap=cmp)\nplt.title(\"Mask\")\nplt.axis(\"off\")\nplt.show()\n\n&lt;class 'torchvision.tv_tensors._image.Image'&gt;\ntorch.Size([3, 1536, 2048])\ntensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n\n&lt;class 'torchvision.tv_tensors._mask.Mask'&gt;\ntorch.Size([1536, 2048])\ntensor(0, dtype=torch.uint8) tensor(1, dtype=torch.uint8)"
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#transforms",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#transforms",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "Transforms",
    "text": "Transforms\n\nimport torch\nfrom torchvision.transforms import v2\n\n\nmean = (0.485, 0.456, 0.406) # ImageNet\nstd = (0.229, 0.224, 0.225) # ImageNet\n\nbase_size = 520\n\ncrop_size = 480\nhflip_prob = 0.5\n\ntransform_train = v2.Compose(\n    [\n        v2.ToImage(),\n        v2.Resize(size=(base_size, base_size)),\n        v2.RandomHorizontalFlip(p=hflip_prob),\n        v2.RandomCrop(size=(crop_size, crop_size)),\n        v2.ToDtype(dtype={tv_tensors.Image:torch.float32, tv_tensors.Mask:torch.int64, \"others\":None}, scale=True),\n        v2.Normalize(mean=mean, std=std), \n        v2.ToPureTensor()\n    ]\n)\n\ntransform_val = v2.Compose(\n    [\n        v2.ToImage(),\n        v2.Resize(size=base_size),\n        v2.ToDtype(dtype={tv_tensors.Image:torch.float32, tv_tensors.Mask:torch.int64, \"others\":None}, scale=True),\n        v2.Normalize(mean=mean, std=std), # ImageNet mean and std\n        v2.ToPureTensor()\n    ]\n)\n\n\ndataset = BalloonDataset(\"dataset/train\", transform=transform_train)\ndataset_val = BalloonDataset(\"dataset/val\", transform=transform_val)\n\n\nsample = dataset[0]\n\nprint(type(sample[\"image\"]))\nprint(sample[\"image\"].shape)\nprint(sample[\"image\"].min(), sample[\"image\"].max())\n\nprint()\n\nprint(type(sample[\"mask\"]))\nprint(sample[\"mask\"].shape)\nprint(sample[\"mask\"].min(), sample[\"mask\"].max())\n\nplt.subplot(1,2,1)\nplt.imshow(sample[\"image\"].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.imshow(sample[\"mask\"], cmap=cmp)\nplt.title(\"Mask\")\nplt.axis(\"off\")\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.9295317..2.622571].\n\n\n&lt;class 'torch.Tensor'&gt;\ntorch.Size([3, 480, 480])\ntensor(-1.9295) tensor(2.6226)\n\n&lt;class 'torch.Tensor'&gt;\ntorch.Size([480, 480])\ntensor(0) tensor(1)\n\n\n\n\n\n\n\n\n\n\nsample = dataset_val[0]\n\nprint(type(sample[\"image\"]))\nprint(sample[\"image\"].shape)\nprint(sample[\"image\"].min(), sample[\"image\"].max())\n\nprint()\n\nprint(type(sample[\"mask\"]))\nprint(sample[\"mask\"].shape)\nprint(sample[\"mask\"].min(), sample[\"mask\"].max())\n\nplt.subplot(1,2,1)\nplt.imshow(sample[\"image\"].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.imshow(sample[\"mask\"], cmap=cmp)\nplt.title(\"Mask\")\nplt.axis(\"off\")\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7870152..2.4285715].\n\n\n&lt;class 'torch.Tensor'&gt;\ntorch.Size([3, 520, 693])\ntensor(-1.7870) tensor(2.4286)\n\n&lt;class 'torch.Tensor'&gt;\ntorch.Size([520, 693])\ntensor(0) tensor(1)"
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#dataloader",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#dataloader",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "DataLoader",
    "text": "DataLoader\n\nnum_workers = 0\nbatch_size = 2\n\n\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\ndef collate_fn(batch):\n    images = torch.stack([sample[\"image\"] for sample in batch])\n    masks = torch.stack([sample[\"mask\"] for sample in batch])\n    return images, masks\n\ndata_loader = DataLoader(dataset, \n                         batch_size=batch_size, \n                         sampler=RandomSampler(dataset),\n                         num_workers=num_workers, \n                         drop_last=True,\n                         collate_fn=collate_fn)\n\ndata_loader_val = DataLoader(dataset_val,\n                             batch_size=1,\n                             sampler=SequentialSampler(dataset_val),\n                             num_workers=num_workers,\n                             drop_last=False,\n                             collate_fn=collate_fn)\n\n\nbatch = next(iter(data_loader))\nprint(batch[0].shape, batch[1].shape)\nprint(batch[0].dtype, batch[1].dtype)\nprint(torch.unique(batch[1]))\n\nplt.subplot(1,2,1)\nplt.imshow(batch[0][0].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.imshow(batch[1][0], cmap=cmp)\nplt.title(\"Mask\")\nplt.axis(\"off\")\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.64].\n\n\ntorch.Size([2, 3, 480, 480]) torch.Size([2, 480, 480])\ntorch.float32 torch.int64\ntensor([0, 1])\n\n\n\n\n\n\n\n\n\n\nbatch = next(iter(data_loader_val))\nprint(batch[0].shape, batch[1].shape)\nprint(batch[0].dtype, batch[1].dtype)\nprint(torch.unique(batch[1]))\n\nplt.subplot(1,2,1)\nplt.imshow(batch[0][0].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.imshow(batch[1][0], cmap=cmp)\nplt.title(\"Mask\")\nplt.axis(\"off\")\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7870152..2.4285715].\n\n\ntorch.Size([1, 3, 520, 693]) torch.Size([1, 520, 693])\ntorch.float32 torch.int64\ntensor([0, 1])"
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#model",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#model",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "Model",
    "text": "Model\n\nimport torchvision\nfrom torch.nn import Conv2d\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnum_classes = 2\n\nmodel_name = \"fcn_resnet50\"\nmodel_weights = \"COCO_WITH_VOC_LABELS_V1\"\naux_loss = True\n\n\nmodel = torchvision.models.get_model(\n    name=model_name,\n    weights=model_weights,\n    aux_loss=aux_loss,\n)\n\nout_in_channels = model.classifier[4].in_channels\nmodel.classifier[4] = Conv2d(out_in_channels, num_classes, kernel_size=(1, 1), stride=(1, 1))\n\naux_in_channels = model.aux_classifier[4].in_channels\nmodel.aux_classifier[4] = Conv2d(aux_in_channels, num_classes, kernel_size=(1, 1), stride=(1, 1))\n\nmodel = model.to(device)\n\n\nmodel\n\nFCN(\n  (backbone): IntermediateLayerGetter(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  (classifier): FCNHead(\n    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (aux_classifier): FCNHead(\n    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n  )\n)\n\n\n\nwith torch.inference_mode():\n    image, target = next(iter(data_loader))\n    image, target = image.to(device), target.to(device)\n    output = model(image)\n\n    print(output.keys())\n\n    print(output[\"out\"].shape)\n    print(output[\"aux\"].shape)\n\n    output = output[\"out\"]\n\n    image = image.detach().cpu()\n    true_mask = target.detach().cpu()\n    pred_mask = output.argmax(1).detach().cpu()\n    probs = output.softmax(1).detach().cpu()\n\nprint(image.shape, target.shape)\nprint(true_mask.shape, pred_mask.shape)\nprint(output.shape, probs.shape)\n\np = 0.5\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1,5,1)\nplt.imshow(image[0].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,2)\nplt.imshow(true_mask[0], cmap=cmp)\nplt.title(\"True Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,3)\nplt.imshow(pred_mask[0], cmap=cmp)\nplt.title(\"Predicted Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,4)\nplt.imshow(probs[0, 1], clim=(0, 1))\nplt.title(\"Probability of class 1\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,5)\nplt.imshow((probs[0, 1] &gt; p).to(torch.bool), cmap=cmp)\nplt.title(f\"Probability of class 1 &gt; {p}\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.0836544..2.64].\n\n\nodict_keys(['out', 'aux'])\ntorch.Size([2, 2, 480, 480])\ntorch.Size([2, 2, 480, 480])\ntorch.Size([2, 3, 480, 480]) torch.Size([2, 480, 480])\ntorch.Size([2, 480, 480]) torch.Size([2, 480, 480])\ntorch.Size([2, 2, 480, 480]) torch.Size([2, 2, 480, 480])\n\n\n\n\n\n\n\n\n\n\nwith torch.inference_mode():\n    image, target = next(iter(data_loader_val))\n    image, target = image.to(device), target.to(device)\n    output = model(image)\n    output = output[\"out\"]\n\n    image = image.detach().cpu()\n    true_mask = target.detach().cpu()\n    pred_mask = output.argmax(1).detach().cpu()\n    probs = output.softmax(1).detach().cpu()\n\nprint(image.shape, target.shape)\nprint(true_mask.shape, pred_mask.shape)\nprint(output.shape, probs.shape)\n\np = 0.5\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1,5,1)\nplt.imshow(image[0].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,2)\nplt.imshow(true_mask[0], cmap=cmp)\nplt.title(\"True Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,3)\nplt.imshow(pred_mask[0], cmap=cmp)\nplt.title(\"Predicted Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,4)\nplt.imshow(probs[0, 1], clim=(0, 1))\nplt.title(\"Probability of class 1\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,5)\nplt.imshow((probs[0, 1] &gt; p).to(torch.bool), cmap=cmp)\nplt.title(f\"Probability of class 1 &gt; {p}\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7870152..2.4285715].\n\n\ntorch.Size([1, 3, 520, 693]) torch.Size([1, 520, 693])\ntorch.Size([1, 520, 693]) torch.Size([1, 520, 693])\ntorch.Size([1, 2, 520, 693]) torch.Size([1, 2, 520, 693])"
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#preparing-training",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#preparing-training",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "Preparing Training",
    "text": "Preparing Training\n\nlr = 0.01\nmomentum = 0.9\nweight_decay = 1e-4\n\nepochs = 10\nprint_freq = 5\n\n\nparams = [\n    {\"params\": [p for p in model.backbone.parameters() if p.requires_grad]},\n    {\"params\": [p for p in model.classifier.parameters() if p.requires_grad]},\n    {\"params\": [p for p in model.aux_classifier.parameters() if p.requires_grad]},\n]\n\n\noptimizer = torch.optim.SGD(params, \n                            lr=lr, \n                            momentum=momentum, \n                            weight_decay=weight_decay)\n\n\niters_per_epoch = len(data_loader)\niters_per_epoch\n\n30\n\n\n\nlr_scheduler = torch.optim.lr_scheduler.PolynomialLR(\n    optimizer, \n    total_iters=iters_per_epoch * epochs, \n    power=0.9\n)\n\n\nclass ConfusionMatrix:\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n        self.mat = None\n\n    def update(self, true, pred):\n        n = self.num_classes\n        if self.mat is None:\n            self.mat = torch.zeros((n, n), dtype=torch.int64, device=true.device)\n\n        with torch.inference_mode():\n            # T, P\n            # 0, 0 =&gt; 2*0 + 0 = 0 True Negative\n            # 0, 1 =&gt; 2*0 + 1 = 1 False Positive\n            # 1, 0 =&gt; 2*1 + 0 = 2 False Negative\n            # 1, 1 =&gt; 2*1 + 1 = 3 True Positive\n            k = (true &gt;= 0) & (true &lt; n)\n            inds = n * true[k].to(torch.int64) + pred[k]\n            self.mat += torch.bincount(inds, minlength=n**2).reshape(n, n)\n\n    def compute(self):\n        # Confusion Matrix\n        # [[TN, FP],\n        #  [FN, TP]]\n        h = self.mat.float()\n\n        # TN, TP\n        # TN -&gt; Correctly predicted as class 0\n        # TP -&gt; Correctly predicted as class 1\n        diag = torch.diag(h)\n\n        # Overall accuracy\n        # (TN + TP) / (TN + FP + FN + TP)\n        acc_global = diag.sum() / h.sum()\n\n        # Actual Negative, Actual Positive\n        # (TN + FP) -&gt; Actual Negative -&gt; # of pixels that are class 0\n        # (FN + TP) -&gt; Actual Positive -&gt; # of pixels that are class 1\n        hsum1 = h.sum(1)\n\n        # Predicted Negative, Predicted Positive\n        # (TN + FN) -&gt; Predicted Negative -&gt; # of pixels predicted as class 0\n        # (FP + TP) -&gt; Predicted Positive -&gt; # of pixels predicted as class 1\n        hsum0 = h.sum(0)\n\n        # Accuracy of class 0, Accuracy of class 1\n        # (TN) / (TN + FP) -&gt; Accuracy of class 0 \n        # (TN + FP = Actual Negative -&gt; # of pixels that are class 0)\n        #\n        # (TP) / (FN + TP) -&gt; Accuracy of class 1  \n        # (FN + TP = Actual Positive -&gt; # of pixels that are class 1)\n        acc = diag / hsum1\n\n        # IoU for class 0, IoU for class 1\n        # (TN) / ((TN + FP) + (TN + FN) - TN) =&gt; TN / (TN + FP + FN) -&gt; IoU for class 0\n        # (TP) / ((FN + TP) + (FP + TP) - TP) =&gt; TP / (FN + FP + TP) -&gt; IoU for class 1\n        iou = diag / (hsum1 + hsum0 - diag)\n        return acc_global, acc, iou\n\n\ndef evaluate(model, data_loader, device, num_classes):\n    model.eval()\n    \n    confmat = ConfusionMatrix(num_classes)\n\n    with torch.inference_mode():\n        for image, target in data_loader:\n            image, target = image.to(device), target.to(device)\n            output = model(image)\n            output = output[\"out\"]\n\n            true_mask = target.flatten()\n            pred_mask = output.argmax(1).flatten()\n\n            confmat.update(true_mask, pred_mask)\n\n    acc_global, acc, iou = confmat.compute()\n    return acc_global, acc, iou\n\n\ndef criterion(outputs, target):\n    \"\"\"\n    outputs: {\"out\": [batch_size, num_classes, H, W], \"aux\": [batch_size, num_classes, H, W]}\n    target : [batch_size, M, M]\n    \"\"\"\n    losses = {}\n    for name, output in outputs.items():\n        losses[name] = torch.nn.functional.cross_entropy(output, target, ignore_index=255)\n\n    return losses[\"out\"] + 0.5 * losses[\"aux\"]\n\n\ndef train_one_epoch(model, criterion, optimizer, data_loader, lr_scheduler, device, print_freq):\n    model.train()\n    \n    for idx, (image, target) in enumerate(data_loader):\n        image, target = image.to(device), target.to(device)\n\n        output = model(image)\n        loss = criterion(output, target)\n    \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        lr_scheduler.step()\n\n        if idx % print_freq == 0:\n            print(f\"iteration: {idx}, loss: {loss.item()}, lr: {optimizer.param_groups[0]['lr']}\")\n\n\nimport datetime\nfrom time import perf_counter\n\n\noutput_dir = Path(\"output\")\noutput_dir.mkdir(exist_ok=True, parents=True)"
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#training-loop",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#training-loop",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "Training Loop",
    "text": "Training Loop\n\nstart_time = perf_counter()\n\nmean_iou_best = 0\n\nfor epoch in range(epochs):\n    print(f\"epoch: {epoch}\")\n    \n    train_one_epoch(model, criterion, optimizer, data_loader, lr_scheduler, device, print_freq)\n    acc_global, acc, iou = evaluate(model, data_loader_val, device, num_classes)\n\n    print(\"overall accuracy: {:.1f}\".format(acc_global.item() * 100))\n    print(\"per-class accuracy: {}\".format([f\"{i:.1f}\" for i in (acc * 100).tolist()]))\n    print(\"per-class IoU: {}\".format([f\"{i:.1f}\" for i in (iou * 100).tolist()]))\n    mean_iou = iou.mean().item() * 100\n    print(\"mean IoU: {:.1f}\".format(mean_iou))\n\n    checkpoint = {\n        \"model\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n        \"lr_scheduler\": lr_scheduler.state_dict(),\n        \"epoch\": epoch,\n    }\n    torch.save(model.state_dict(), output_dir / f\"model_{epoch}.pth\")\n    torch.save(checkpoint, output_dir / \"checkpoint.pth\")\n\n    if mean_iou &gt; mean_iou_best:\n        mean_iou_best = mean_iou\n        torch.save(model.state_dict(), output_dir / \"model_best.pth\")\n\ntotal_time = perf_counter() - start_time\ntotal_time_str = str(datetime.timedelta(seconds=int(total_time)))\nprint(f\"Training time {total_time_str}\")\n\nepoch: 0\niteration: 0, loss: 1.01277494430542, lr: 0.009969994993878174\niteration: 5, loss: 0.7877825498580933, lr: 0.009819818665965752\niteration: 10, loss: 0.5762972831726074, lr: 0.009669386705882587\niteration: 15, loss: 1.0311238765716553, lr: 0.009518694243963476\niteration: 20, loss: 0.2171248197555542, lr: 0.009367736230317173\niteration: 25, loss: 0.176581472158432, lr: 0.009216507424802825\noverall accuracy: 96.6\nper-class accuracy: ['96.5', '98.0']\nper-class IoU: ['96.3', '69.3']\nmean IoU: 82.8\nepoch: 1\niteration: 0, loss: 0.3303796052932739, lr: 0.009065002386255556\niteration: 5, loss: 0.49728652834892273, lr: 0.00891321546089\niteration: 10, loss: 0.14698544144630432, lr: 0.008761140769802247\niteration: 15, loss: 0.25900280475616455, lr: 0.008608772195481283\niteration: 20, loss: 0.23461148142814636, lr: 0.008456103367230421\niteration: 25, loss: 0.15549582242965698, lr: 0.008303127645386885\noverall accuracy: 99.1\nper-class accuracy: ['99.7', '92.5']\nper-class IoU: ['99.0', '89.1']\nmean IoU: 94.1\nepoch: 2\niteration: 0, loss: 0.18801620602607727, lr: 0.008149838104213793\niteration: 5, loss: 0.49533677101135254, lr: 0.007996227513322691\niteration: 10, loss: 0.1928689032793045, lr: 0.00784228831746623\niteration: 15, loss: 0.32615792751312256, lr: 0.007688012614519259\niteration: 20, loss: 0.0866878479719162, lr: 0.007533392131441786\niteration: 25, loss: 0.19141457974910736, lr: 0.007378418197988367\noverall accuracy: 98.7\nper-class accuracy: ['99.0', '94.9']\nper-class IoU: ['98.6', '84.7']\nmean IoU: 91.6\nepoch: 3\niteration: 0, loss: 0.2648457884788513, lr: 0.007223081717895036\niteration: 5, loss: 0.11991502344608307, lr: 0.0070673731372354115\niteration: 10, loss: 0.23792551457881927, lr: 0.006911282409591538\niteration: 15, loss: 0.18067464232444763, lr: 0.006754798957630521\niteration: 20, loss: 0.1413581818342209, lr: 0.006597911630613654\niteration: 25, loss: 0.3505668342113495, lr: 0.006440608657288157\noverall accuracy: 99.1\nper-class accuracy: ['99.6', '92.4']\nper-class IoU: ['99.0', '88.7']\nmean IoU: 93.8\nepoch: 4\niteration: 0, loss: 0.11682246625423431, lr: 0.00628287759352032\niteration: 5, loss: 0.5209360718727112, lr: 0.006124705263919317\niteration: 10, loss: 0.11417791247367859, lr: 0.005966077696569146\niteration: 15, loss: 0.16387423872947693, lr: 0.005806980049826368\niteration: 20, loss: 0.13538804650306702, lr: 0.005647396529947093\niteration: 25, loss: 0.05533313378691673, lr: 0.005487310298068799\noverall accuracy: 99.5\nper-class accuracy: ['99.8', '95.0']\nper-class IoU: ['99.4', '93.1']\nmean IoU: 96.3\nepoch: 5\niteration: 0, loss: 0.10098870098590851, lr: 0.005326703364779764\niteration: 5, loss: 0.047345079481601715, lr: 0.005165556470146127\niteration: 10, loss: 0.06248948723077774, lr: 0.00500384894661411\niteration: 15, loss: 0.07856252789497375, lr: 0.004841558561636509\niteration: 20, loss: 0.09252874553203583, lr: 0.004678661336152997\niteration: 25, loss: 0.05078906565904617, lr: 0.004515131334135518\noverall accuracy: 99.3\nper-class accuracy: ['99.8', '93.2']\nper-class IoU: ['99.2', '91.1']\nmean IoU: 95.2\nepoch: 6\niteration: 0, loss: 0.05498559772968292, lr: 0.004350940417227879\niteration: 5, loss: 0.10427920520305634, lr: 0.00418605795697228\niteration: 10, loss: 0.05495597422122955, lr: 0.004020450495098764\niteration: 15, loss: 0.033951517194509506, lr: 0.0038540813396768115\niteration: 20, loss: 0.21207734942436218, lr: 0.0036869100813333193\niteration: 25, loss: 0.08376838266849518, lr: 0.0035188920088502548\noverall accuracy: 99.4\nper-class accuracy: ['99.7', '94.9']\nper-class IoU: ['99.3', '92.1']\nmean IoU: 95.7\nepoch: 7\niteration: 0, loss: 0.08038052916526794, lr: 0.0033499773967063965\niteration: 5, loss: 0.032610610127449036, lr: 0.003180110627669994\niteration: 10, loss: 0.025917738676071167, lr: 0.003009229100067209\niteration: 15, loss: 0.0338129997253418, lr: 0.0028372618497656244\niteration: 20, loss: 0.03268418461084366, lr: 0.002664127787853039\niteration: 25, loss: 0.04463454335927963, lr: 0.002489733410844936\noverall accuracy: 99.4\nper-class accuracy: ['99.8', '95.3']\nper-class IoU: ['99.4', '92.6']\nmean IoU: 96.0\nepoch: 8\niteration: 0, loss: 0.035370051860809326, lr: 0.002313969771367498\niteration: 5, loss: 0.026227110996842384, lr: 0.0021367083864453854\niteration: 10, loss: 0.05721791461110115, lr: 0.0019577955758817893\niteration: 15, loss: 0.17568983137607574, lr: 0.00177704440273342\niteration: 20, loss: 0.060686126351356506, lr: 0.0015942228040916459\niteration: 25, loss: 0.04033160209655762, lr: 0.0014090353734474502\noverall accuracy: 99.4\nper-class accuracy: ['99.8', '93.6']\nper-class IoU: ['99.3', '91.9']\nmean IoU: 95.6\nepoch: 9\niteration: 0, loss: 0.04921840876340866, lr: 0.001221093920078196\niteration: 5, loss: 0.03143635392189026, lr: 0.0010298666348361786\niteration: 10, loss: 0.06234569475054741, lr: 0.0008345821880550068\niteration: 15, loss: 0.04337213188409805, lr: 0.0006340245914362474\niteration: 20, loss: 0.12797394394874573, lr: 0.0004259995391188707\niteration: 25, loss: 0.03848736360669136, lr: 0.00020532643320784173\noverall accuracy: 99.4\nper-class accuracy: ['99.8', '95.0']\nper-class IoU: ['99.3', '92.4']\nmean IoU: 95.8\nTraining time 0:00:47\n\n\n\nprint(\"Best mean IoU: {:.1f}\".format(mean_iou_best))\n\nBest mean IoU: 96.3"
  },
  {
    "objectID": "posts/semantic-segmentation-fcn-resnet50/index.html#evaluation",
    "href": "posts/semantic-segmentation-fcn-resnet50/index.html#evaluation",
    "title": "Semantic Segmentation in PyTorch Using an FCN with a ResNet-50 Backbone",
    "section": "Evaluation",
    "text": "Evaluation\n\nmodel = torchvision.models.get_model(\n    name=model_name,\n    weights=model_weights,\n    aux_loss=aux_loss,\n)\n\nout_in_channels = model.classifier[4].in_channels\nmodel.classifier[4] = Conv2d(out_in_channels, num_classes, kernel_size=(1, 1), stride=(1, 1))\n\naux_in_channels = model.aux_classifier[4].in_channels\nmodel.aux_classifier[4] = Conv2d(aux_in_channels, num_classes, kernel_size=(1, 1), stride=(1, 1))\n\nmodel = model.to(device)\nmodel.load_state_dict(torch.load(output_dir / \"model_best.pth\", map_location=device, weights_only=True))\n\n&lt;All keys matched successfully&gt;\n\n\n\nwith torch.inference_mode():\n    image, target = next(iter(data_loader))\n    image, target = image.to(device), target.to(device)\n    output = model(image)\n    output = output[\"out\"]\n\n    image = image.detach().cpu()\n    true_mask = target.detach().cpu()\n    pred_mask = output.argmax(1).detach().cpu()\n    probs = output.softmax(1).detach().cpu()\n\nprint(image.shape, target.shape)\nprint(true_mask.shape, pred_mask.shape)\nprint(output.shape, probs.shape)\n\np = 0.9\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1,5,1)\nplt.imshow(image[0].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,2)\nplt.imshow(true_mask[0], cmap=cmp)\nplt.title(\"True Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,3)\nplt.imshow(pred_mask[0], cmap=cmp)\nplt.title(\"Predicted Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,4)\nplt.imshow(probs[0, 1], clim=(0, 1))\nplt.title(\"Probability of class 1\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,5)\nplt.imshow((probs[0, 1] &gt; p).to(torch.bool), cmap=cmp)\nplt.title(f\"Probability of class 1 &gt; {p}\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.0494049..2.500567].\n\n\ntorch.Size([2, 3, 480, 480]) torch.Size([2, 480, 480])\ntorch.Size([2, 480, 480]) torch.Size([2, 480, 480])\ntorch.Size([2, 2, 480, 480]) torch.Size([2, 2, 480, 480])\n\n\n\n\n\n\n\n\n\n\nidx = 4\n\nwith torch.inference_mode():\n    data_loader_val_iter = iter(data_loader_val)\n    for _ in range(idx):\n        image, target = next(data_loader_val_iter)\n    image, target = image.to(device), target.to(device)\n    output = model(image)\n    output = output[\"out\"]\n\n    image = image.detach().cpu()\n    true_mask = target.detach().cpu()\n    pred_mask = output.argmax(1).detach().cpu()\n    probs = output.softmax(1).detach().cpu()\n\nprint(image.shape, target.shape)\nprint(true_mask.shape, pred_mask.shape)\nprint(output.shape, probs.shape)\n\np = 0.9\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1,5,1)\nplt.imshow(image[0].permute(1,2,0))\nplt.title(\"Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,2)\nplt.imshow(true_mask[0], cmap=cmp)\nplt.title(\"True Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,3)\nplt.imshow(pred_mask[0], cmap=cmp)\nplt.title(\"Predicted Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,4)\nplt.imshow(probs[0, 1], clim=(0, 1))\nplt.title(\"Probability of class 1\")\nplt.axis(\"off\")\n\nplt.subplot(1,5,5)\nplt.imshow((probs[0, 1] &gt; p).to(torch.bool), cmap=cmp)\nplt.title(f\"Probability of class 1 &gt; {p}\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.0665298..2.64].\n\n\ntorch.Size([1, 3, 804, 520]) torch.Size([1, 804, 520])\ntorch.Size([1, 804, 520]) torch.Size([1, 804, 520])\ntorch.Size([1, 2, 804, 520]) torch.Size([1, 2, 804, 520])"
  },
  {
    "objectID": "posts/spherical-astronomy/index.html",
    "href": "posts/spherical-astronomy/index.html",
    "title": "Spherical Astronomy",
    "section": "",
    "text": "This post is based on the project report from the â€œAstronomical Observationâ€ lecture in 2019 by Professor Soojong Park at Kyung Hee University."
  },
  {
    "objectID": "posts/spherical-astronomy/index.html#introduction",
    "href": "posts/spherical-astronomy/index.html#introduction",
    "title": "Spherical Astronomy",
    "section": "Introduction",
    "text": "Introduction\n\nWhat is the purpose of this post?\nThe purpose of this post is to help you grasp the concept of the celestial sphere and the motions of celestial objects by utilizing the celestial sphere model. In detail, you will learn and understand that diurnal motion is the result of Earthâ€™s rotation, and annual motion is the result of Earthâ€™s revolution. Furthermore, you will gain insights into solar time, sidereal time, the celestial coordinate system (horizontal and equatorial), and coordinate conversion.\n\n\nWhy do you learn this?\nAll astronomical studies are based on the results of astronomical observations. The majority of these observations are conducted on Earth, with some exceptions. However, Earth is not an inertial frame of reference because it both rotates on its axis and orbits the Sun. Consequently, when we observe celestial objects from Earth, we inevitably observe apparent motion due to Earthâ€™s own movements. Therefore, it is essential to identify the apparent motion in the motion of celestial objects. Additionally, all celestial objects are projected onto the celestial sphere, and as a result, their movements occur on the surface of this sphere. For these reasons, learning spherical astronomy is crucial for astronomers."
  },
  {
    "objectID": "posts/spherical-astronomy/index.html#celestial-sphere-model",
    "href": "posts/spherical-astronomy/index.html#celestial-sphere-model",
    "title": "Spherical Astronomy",
    "section": "Celestial Sphere Model",
    "text": "Celestial Sphere Model\n\nCelestial Sphere\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Celestial Sphere is an imaginary sphere with an infinite radius centered at the Earthâ€™s center. While most motions of celestial objects are a result of Earthâ€™s motion, for the sake of convenience, we assume that the Earth is fixed, and all celetial objects are embedded on the surface of the Celetial Sphere. We attribute the motions of celestial objects to the motion of the Celestial Sphere.\nSince the Celestial Sphere is a sphere defined by a set of points equidistant from its center, we designate certain special points or circles for convenience. There are various methods for naming these points and circles, but we typically use Earthâ€™s Rotation, Earthâ€™s Revolution, and Observer. For each of them, we begin by selecting a reference axis and a reference plane that is perpendicular to the axis. We then extend the axis and plane infinitely, resulting in three intersections (two points and one circle), each of which is given a specific name. If additional points or circles on the Celestial Sphere are required, we can refer to 9 intersections (6 points and 3 circles) for reference.\n\nEarthâ€™s Rotation\n\nReference axis: Earthâ€™s rotation axis\nReference plane: The plane containing Earthâ€™s equator\n\n\nTwo points on the Celestial Sphere\n\nCelestial North Pole: The point near Earthâ€™s North Pole\nCelestial South Pole: The point near Earthâ€™s South Pole\n\n\n\nOne circle on the Celestial Sphere\n\nCelestial Equator: The great circle determined by the reference plane of Earthâ€™s Rotation\n\n\n\n\nEarthâ€™s Revolution\n\nReference axis: The axis parallel to Earthâ€™s revolution axis and passing through Earthâ€™s center\nReference plane: The plane containing Earthâ€™s orbital path around the Sun\n\n\nTwo points on the Celestial Sphere\n\nEcliptic North Pole: The point near Earthâ€™s North Pole\nEcliptic South Pole: The point near Earthâ€™s South Pole\n\n\n\nOne circle on the Celestial Sphere\n\nEcliptic: The great circle determined by the reference plane of Earthâ€™s Revolution\n\n\n\n\nObserver\n\nReference axis: The line perpendicular to the reference plane at the observerâ€™s location\nReference plane: The plane parallel to the tangent plane of the Earth at the observerâ€™s location and passing though Earthâ€™s center\n\n\nTwo points on the Celestial Sphere\n\nZenith: The point near observerâ€™s head\nNadir: The point near observerâ€™s feet\n\n\n\nOne circle on the Celestial Sphere\n\nHorizon: The great circle determined by the reference plane of observer\n\n\n\n\nAdditional Points and Circles\n\nCircle on the Celestial Sphere\n\nMeridian: The great circle passing though the Celestial North Pole, the Celestial South Pole, the Zenith, and the Nadir\n\n\n\n4 points on the Ecliptic\n\nVernal Equinox : The point of intersection of the Ecliptic and the Celestial Equator, where the Sun moves from the celestial southern hemisphere to the celestial northern hemisphere\nSummer Solsticeâ€‹ : The point on the Ecliptic nearest to the Celestial North Pole\nAutumnal Equinox : The point of intersection of the Ecliptic and the Celestial Equator, where the Sun moves from the celestial northern hemisphere to the celestial southern hemisphere\nWinter Solsticeâ€‹ : The point on the Ecliptic nearest to the Celestial South Pole\n\n\n\n4 points on the Horizon\n\nNorth pointâ€‹ : The point of intersection of the Horizon and the Meridian near the Celestial North Pole\nEast point : The point on the Horizon located 90 degree clockwise from the North point\nSouth pointâ€‹ : The point of intersection of the Horizon and the Meridian near the Celestial South Pole\nWest point : The point on the Horizon located 90 degree clockwise from the South point\n\n\n\n\nAltitude of Celestial Poles\n\n\n\n\n\n\n\n\n\n\n\n(a) Northern hemisphere observer\n\n\n\n\n\n\n\n\n\n\n\n(b) Southern hemisphere observer\n\n\n\n\n\n\n\nFigureÂ 1: Schematic illustrations explaining the altitude of celestial poles\n\n\n\nFigureÂ 1 (a) represents a situation in which the observer is located in the northern hemisphere, while FigureÂ 1 (b) depicts a case in the southern hemisphere. In these diagrams, the blue line represents the horizon, the red line signifies the celestial equator, the black line is perpendicular to the horizon, the green line is perpendicular to the celestial equator, the orange point represents the observer, the green point represents Polaris, and \\phi denotes the observerâ€™s latitude. From these figures, we can conclude that the altitude of celestial poles is equal to the observerâ€™s latitude.\n\n\n\nEarthâ€™s Rotation\nFirst, letâ€™s review the following concept for convenience.\n\n\n\n\n\n\n\n\n\n\n\n(a) Left-hand screw rule\n\n\n\n\n\n\n\n\n\n\n\n(b) Right-hand screw rule\n\n\n\n\n\n\n\nFigureÂ 2: Illustrations explaining the rotation direction\n\n\n\nFigureÂ 2 (a) illustrates the left-hand screw rule, while FigureÂ 2 (b) illustrates the right-hand screw rule. Imagine youâ€™re directly looking at your thumbs and curling your other fingers. If you focus on your left thumb, the rotation direction is clockwise. Conversely, if you focus on your right thumb, the rotation direction is counterclockwise. To determine the rotation direction, simply observe your thumbs, curl your other fingers, and match the fingerâ€™s rotation direction with the given rotation direction: clockwise for the left hand and counterclockwise for the right hand.\n\n\n\n\n\nIn 3D space, the direction of a rotation vector is uniqe, but the rotation direction is not. Therefore, when describing a rotation, it is necessary to specify the viewpoint or indicate the direction of the rotation vector.\n\n\n\n\n\nIf your right thumb points in the direction of (Celestial) North Pole, then the Earthâ€™s rotation follows right-hand screw rule. In other words, if you were to observe Earthâ€™s North Pole from space, you would see that it rotates counterclockwise. Therefore, the direction of the Earthâ€™s rotation vector is from South Pole to North Pole. Due to relative motion, the celestial sphere appears to rotate in the opposite direction around the Earth.\nWhen you rotate the celestial sphere model, you can observe that the Sun and all celestial objects rise in the east and set in the west in all hemispheres. Furthermore, youâ€™ll notice that at the Sunâ€™s upper culmination (its highest point), it appears in the southern sky in the northern hemisphere and in the northern sky in the southern hemisphere. At the poles, the Sun either remains either continuously visible or permanently hidden.\n\n\nSidereal Time\n\n\n\n\n\nThe (Local) Hour Angle is the inversely measured right ascension from the intersection of the celestial equator and the meridian above horizon. When the hour angle of a celestial object is zero, we call that the celestial object is at its upper culmination.\nThe (Local) Sidereal Time is the hour angle of the vernal equinox. By definition, sidereal time \\Theta of a celestial object is equal to H+\\alpha, where H is hour angle, and \\alpha is right ascension of the celestial object.\n\n\\begin{align*}\n\\text{Sidereal time} = \\Theta & = H_{\\text{vernal equinox}} \\\\\n& = H + \\alpha \\\\\n& = \\alpha_{\\text{celestial object at its upper culmination}}\n\\end{align*}\n\nThe (Local) Solar Time is calculated by adding the hour angle of the Sun to 12 hours.\n\n\\text{Solar time} = S = H_{\\odot} + \\text{12 h}\n\nTherefore, we get the following equation.\n\n\\begin{align*}\n\\text{Sidereal time} = \\Theta & = H_{\\odot} + \\alpha_{\\odot} \\\\\n& = S - \\text{12 h} + \\alpha_{\\odot}\n\\end{align*}\n\nThe right ascension of the Sun \\alpha_{\\odot} increases about +\\text{4 min} per day.\n\n\n\nTime\n\\alpha_{\\odot}\n\n\n\n\nVernal Equinox\n\\text{0 h}\n\n\nSummer Solstice\n\\text{6 h}\n\n\nAutumnal Equinox\n\\text{12 h}\n\n\nWinter Solstice\n\\text{18 h}\n\n\n\nThis solar time is actually local solar time. In Korea, the local solar time of Seoul is that of 127Â° E but our clock uses the local solar time of 135Â° E (UTC+9). As a result, there is a difference of about 8Â° (equivalent to 32 minutes). Therefore, in Seoul, the Sun is at its upper culmination at approximately 12:32 KST."
  },
  {
    "objectID": "posts/spherical-astronomy/index.html#spherical-coordinate-system",
    "href": "posts/spherical-astronomy/index.html#spherical-coordinate-system",
    "title": "Spherical Astronomy",
    "section": "Spherical Coordinate System",
    "text": "Spherical Coordinate System\n\nHorizontal System vs.Â Equatorial System\n\nDefinition of (Az, Alt) in Horizontal System\nAzimuth (Az, A) of a celestial object is the angle (or angular distance) measured commonly clockwise from the south point along the horizon. Azimuth values are typically within the range of [0Â°, 360Â°].\nAltitude (Alt, a) of a celestial object is the angle (or angular distance) measured from the horizon along the great circle passing through the celestial object and the zenith. Altitude values fall within the range [-90Â°, +90Â°]. A positive altitude indicates that the object is above the horizon, while a negative altitude indicates that the object is below the horizon.\n\n\nDefinition of (RA, Dec) in Equatorial System\nRight Ascension (RA, \\alpha) is a celestial longitude, equivalent to Earthâ€™s longtiude, except that it is measured from the vernal equinox instead of Greenwich. It is measured only in the eartward direction.\nDeclination (Dec, \\delta) is a celestial latitude, equivalent to Earthâ€™s latitude, except that N and S are respectively replaced by + and -.\n\n\nA formula to convert (RA, Dec) to (Az, Alt)\n\n\n\n\n\nIn the figure above, the point â€‹P has coordinates (x, y, z) in xyz Cartesian coordinates system, and (x', y', z') in x'y'z' Cartesian coordinates system. Each of these coordinates has the following relations with spherical coordinates in its respective frame.\n\n\\begin{align*}\nx & = \\cos \\theta \\cos \\psi \\\\\ny & = \\cos \\theta \\sin \\psi \\\\\nz & = \\sin \\theta\n\\end{align*}\n\n\n\\begin{align*}\nx' & = \\cos \\theta' \\cos \\psi' \\\\\ny' & = \\cos \\theta' \\sin \\psi' \\\\\nz' & = \\sin \\theta'\n\\end{align*}\n\nThe primed coordinates are related to the unprimed coordinates by the following equations.\n\n\\begin{bmatrix}\nx \\\\\ny \\\\\nz\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & \\cos \\chi & -\\sin \\chi \\\\\n0 & \\sin \\chi & \\cos \\chi\n\\end{bmatrix}\n\\begin{bmatrix}\nx' \\\\\ny' \\\\\nz'\n\\end{bmatrix}\n\n\n\\begin{bmatrix}\nx' \\\\\ny' \\\\\nz'\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & \\cos \\chi & \\sin \\chi \\\\\n0 & -\\sin \\chi & \\cos \\chi\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\\ny \\\\\nz\n\\end{bmatrix}\n\n\n\n\n\n\nIn the figure above, we have \\chi = 90^{\\circ} - \\psi. The values of (x, y, z) and (x', y', z') are determined by the following equations.\n\n\\begin{align*}\nx & = \\cos a \\cos(90^{\\circ} - A) \\\\\n& = \\cos a \\sin A \\\\\ny & = \\cos a \\sin(90^{\\circ} - A) \\\\\n& = \\cos a \\cos A \\\\\nz & = \\sin a\n\\end{align*}\n\n\n\\begin{align*}\nx' & = \\cos \\delta \\cos(90^{\\circ} - H) \\\\\n& = \\cos \\delta \\sin H \\\\\ny' & = \\cos \\delta \\sin(90^{\\circ} - H) \\\\\n& = \\cos \\delta \\cos H \\\\\nz' & = \\sin \\delta\n\\end{align*}\n\nThus, we get the following equations.\n\n\\begin{align*}\n\\begin{bmatrix}\nx \\\\\ny \\\\\nz\n\\end{bmatrix}\n& =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & \\cos (90^{\\circ} - \\phi) & -\\sin (90^{\\circ} - \\phi) \\\\\n0 & \\sin (90^{\\circ} - \\phi) & \\cos (90^{\\circ} - \\phi)\n\\end{bmatrix}\n\\begin{bmatrix}\nx' \\\\\ny' \\\\\nz'\n\\end{bmatrix} \\\\\n& =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & \\sin \\phi & -\\cos \\phi \\\\\n0 & \\cos \\phi & \\sin \\phi\n\\end{bmatrix}\n\\begin{bmatrix}\nx' \\\\\ny' \\\\\nz'\n\\end{bmatrix}\n\\end{align*}\n\n\n\\begin{align*}\n\\begin{bmatrix}\nx' \\\\\ny' \\\\\nz'\n\\end{bmatrix}\n& =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & \\cos (90^{\\circ} - \\phi) & \\sin (90^{\\circ} - \\phi) \\\\\n0 & -\\sin (90^{\\circ} - \\phi) & \\cos (90^{\\circ} - \\phi)\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\\ny \\\\\nz\n\\end{bmatrix} \\\\\n& =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & \\sin \\phi & \\cos \\phi \\\\\n0 & -\\cos \\phi & \\sin \\phi\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\\ny \\\\\nz\n\\end{bmatrix}\n\\end{align*}\n\nIn conclusion, we get the following two conversion fomulas.\nWhen we know (\\alpha=\\Theta-H, \\delta, \\phi), we can obtain (A, a) by using following equations.\n\n\\begin{align*}\n\\cos a \\sin A & = \\cos \\delta \\sin H \\\\\n\\cos a \\cos A & = \\sin \\phi \\cos \\delta \\cos H - \\cos \\phi \\sin \\delta \\\\\n\\sin a & = \\cos \\phi \\cos \\delta \\cos H + \\sin \\phi \\sin \\delta\n\\end{align*}\n\nWhen we know (A, a, \\phi), we can obtain (\\alpha=\\Theta-H, \\delta) by using following equations.\n\n\\begin{align*}\n\\cos \\delta \\sin H & = \\cos a \\sin A \\\\\n\\cos \\delta \\cos H & = \\sin \\phi \\cos a \\cos A + \\cos \\phi \\sin a \\\\\n\\sin \\delta & = - \\cos \\phi \\cos a \\cos A + \\sin \\phi \\sin a\n\\end{align*}\n\nTherefore, we can conclude that we need to know sidereal time and latitude when performing conversions between (RA, Dec) and (Az, Alt).\n\n\n\nTargets on Meridian\nLet \\alpha' be the right ascension of celestial object at its upper culmination. By definition of sidereal time, the following equation holds.\n\n\\begin{align*}\n\\Theta & = S - \\text{12 h} + \\alpha_\\odot \\\\\n& = \\alpha'\n\\end{align*}\n\nThus we get the following equation.\n\nS = \\text{12 h} - \\alpha_\\odot + \\alpha'\n\n\n\nHour Angle of Targets\nBy definition of sidereal time, the following equation holds.\n\n\\begin{align*}\n\\Theta & = S - \\text{12 h} + \\alpha_\\odot \\\\\n& = H + \\alpha\n\\end{align*}\n\nThus we get the following equation.\n\nH = S - \\text{12 h} + \\alpha_\\odot - \\alpha"
  },
  {
    "objectID": "posts/spherical-astronomy/index.html#references",
    "href": "posts/spherical-astronomy/index.html#references",
    "title": "Spherical Astronomy",
    "section": "References",
    "text": "References\n\nIntroductory Astronomy: The Celestial Sphere, http://astro.wsu.edu/worthey/astro/html/lec-celestial-sph.html\nMeridian (astronomy), https://en.wikipedia.org/wiki/Meridian_(astronomy)\nRight hand screw rule, https://www3.eng.cam.ac.uk/~hemh1/gyroscopes/screwrule.html\nRotation Vs. Revolution: What Are The Differences?, https://differencecamp.com/rotation-vs-revolution\nSUPPLEMENT: MOTIONS IN THE SKY & COORDINATE SYSTEMS, https://rwoconne.github.io/rwoclass/astr1230/motions-coords.html\nHannu Karttunen et al.Â â€‹Fundamental Astronomyâ€‹. Sixth Edition. Springer (2016)"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html",
    "title": "Stable Diffusion Inference with Diffusers (low-level)",
    "section": "",
    "text": "Create an image using Diffusers library.\n\n\n\n!pip install -qq diffusers transformers scipy ftfy accelerate\n\n\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\n'cuda'\n\n\n\nprompt = [\"a photograph of an astronaut riding a horse\"]\n\nheight = 512  # default height of Stable Diffusion\nwidth = 512  # default width of Stable Diffusion\n\nnum_inference_steps = 50  # Number of denoising steps\n\nguidance_scale = 7.5  # Scale for classifier-free guidance\n\ngenerator = torch.manual_seed(256)  # Seed generator to create the inital latent noise\n\nbatch_size = 2\n\n\nfrom diffusers import LMSDiscreteScheduler, StableDiffusionPipeline\n\nscheduler = LMSDiscreteScheduler.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\"\n)\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", scheduler=scheduler\n)\n\n\npipe\n\nStableDiffusionPipeline {\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.20.2\",\n  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPImageProcessor\"\n  ],\n  \"requires_safety_checker\": true,\n  \"safety_checker\": [\n    \"stable_diffusion\",\n    \"StableDiffusionSafetyChecker\"\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"LMSDiscreteScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n\n\n\npipe = pipe.to(device)\n\n\n\n\n\n# 1. Load the autoencoder model which will be used to decode the latents into image space.\nvae = pipe.vae\n\n# 2. Load the tokenizer and text encoder to tokenize and encode the text.\ntokenizer = pipe.tokenizer\ntext_encoder = pipe.text_encoder\n\n# 3. The UNet model for generating the latents.\nunet = pipe.unet\n\n\n\n\nvae\n\nAutoencoderKL(\n  (encoder): Encoder(\n    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (down_blocks): ModuleList(\n      (0): DownEncoderBlock2D(\n        (resnets): ModuleList(\n          (0-1): 2 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (downsamplers): ModuleList(\n          (0): Downsample2D(\n            (conv): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(2, 2))\n          )\n        )\n      )\n      (1): DownEncoderBlock2D(\n        (resnets): ModuleList(\n          (0): ResnetBlock2D(\n            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n            (conv_shortcut): LoRACompatibleConv(128, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): ResnetBlock2D(\n            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (downsamplers): ModuleList(\n          (0): Downsample2D(\n            (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(2, 2))\n          )\n        )\n      )\n      (2): DownEncoderBlock2D(\n        (resnets): ModuleList(\n          (0): ResnetBlock2D(\n            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n            (conv_shortcut): LoRACompatibleConv(256, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): ResnetBlock2D(\n            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (downsamplers): ModuleList(\n          (0): Downsample2D(\n            (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(2, 2))\n          )\n        )\n      )\n      (3): DownEncoderBlock2D(\n        (resnets): ModuleList(\n          (0-1): 2 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n      )\n    )\n    (mid_block): UNetMidBlock2D(\n      (attentions): ModuleList(\n        (0): Attention(\n          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (to_q): Linear(in_features=512, out_features=512, bias=True)\n          (to_k): Linear(in_features=512, out_features=512, bias=True)\n          (to_v): Linear(in_features=512, out_features=512, bias=True)\n          (to_out): ModuleList(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n    (conv_act): SiLU()\n    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (decoder): Decoder(\n    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (up_blocks): ModuleList(\n      (0-1): 2 x UpDecoderBlock2D(\n        (resnets): ModuleList(\n          (0-2): 3 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (upsamplers): ModuleList(\n          (0): Upsample2D(\n            (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n        )\n      )\n      (2): UpDecoderBlock2D(\n        (resnets): ModuleList(\n          (0): ResnetBlock2D(\n            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n            (conv_shortcut): LoRACompatibleConv(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1-2): 2 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (upsamplers): ModuleList(\n          (0): Upsample2D(\n            (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n        )\n      )\n      (3): UpDecoderBlock2D(\n        (resnets): ModuleList(\n          (0): ResnetBlock2D(\n            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n            (conv_shortcut): LoRACompatibleConv(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1-2): 2 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n      )\n    )\n    (mid_block): UNetMidBlock2D(\n      (attentions): ModuleList(\n        (0): Attention(\n          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (to_q): Linear(in_features=512, out_features=512, bias=True)\n          (to_k): Linear(in_features=512, out_features=512, bias=True)\n          (to_v): Linear(in_features=512, out_features=512, bias=True)\n          (to_out): ModuleList(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n    (conv_act): SiLU()\n    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n)\n\n\n\ntokenizer\n\nCLIPTokenizer(name_or_path='/root/.cache/huggingface/hub/models--CompVis--stable-diffusion-v1-4/snapshots/133a221b8aa7292a167afc5127cb63fb5005638b/tokenizer', vocab_size=49408, model_max_length=77, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"&lt;|startoftext|&gt;\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"&lt;|endoftext|&gt;\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"&lt;|endoftext|&gt;\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '&lt;|endoftext|&gt;'}, clean_up_tokenization_spaces=True)\n\n\n\ntext_encoder\n\nCLIPTextModel(\n  (text_model): CLIPTextTransformer(\n    (embeddings): CLIPTextEmbeddings(\n      (token_embedding): Embedding(49408, 768)\n      (position_embedding): Embedding(77, 768)\n    )\n    (encoder): CLIPEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x CLIPEncoderLayer(\n          (self_attn): CLIPAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): CLIPMLP(\n            (activation_fn): QuickGELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n)\n\n\n\nunet\n\nUNet2DConditionModel(\n  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (time_proj): Timesteps()\n  (time_embedding): TimestepEmbedding(\n    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n    (act): SiLU()\n    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n  )\n  (down_blocks): ModuleList(\n    (0): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=320, out_features=320, bias=False)\n                (to_k): Linear(in_features=320, out_features=320, bias=False)\n                (to_v): Linear(in_features=320, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=320, out_features=320, bias=False)\n                (to_k): Linear(in_features=768, out_features=320, bias=False)\n                (to_v): Linear(in_features=768, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (1): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=640, out_features=640, bias=False)\n                (to_k): Linear(in_features=640, out_features=640, bias=False)\n                (to_v): Linear(in_features=640, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=640, out_features=640, bias=False)\n                (to_k): Linear(in_features=768, out_features=640, bias=False)\n                (to_v): Linear(in_features=768, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (2): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (3): DownBlock2D(\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n  )\n  (up_blocks): ModuleList(\n    (0): UpBlock2D(\n      (resnets): ModuleList(\n        (0-2): 3 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (1): CrossAttnUpBlock2D(\n      (attentions): ModuleList(\n        (0-2): 3 x Transformer2DModel(\n          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (2): CrossAttnUpBlock2D(\n      (attentions): ModuleList(\n        (0-2): 3 x Transformer2DModel(\n          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=640, out_features=640, bias=False)\n                (to_k): Linear(in_features=640, out_features=640, bias=False)\n                (to_v): Linear(in_features=640, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=640, out_features=640, bias=False)\n                (to_k): Linear(in_features=768, out_features=640, bias=False)\n                (to_v): Linear(in_features=768, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(960, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (3): CrossAttnUpBlock2D(\n      (attentions): ModuleList(\n        (0-2): 3 x Transformer2DModel(\n          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=320, out_features=320, bias=False)\n                (to_k): Linear(in_features=320, out_features=320, bias=False)\n                (to_v): Linear(in_features=320, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=320, out_features=320, bias=False)\n                (to_k): Linear(in_features=768, out_features=320, bias=False)\n                (to_v): Linear(in_features=768, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(960, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1-2): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(640, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n  )\n  (mid_block): UNetMidBlock2DCrossAttn(\n    (attentions): ModuleList(\n      (0): Transformer2DModel(\n        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n        (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        (transformer_blocks): ModuleList(\n          (0): BasicTransformerBlock(\n            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn1): Attention(\n              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n              (to_out): ModuleList(\n                (0): Linear(in_features=1280, out_features=1280, bias=True)\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn2): Attention(\n              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n              (to_out): ModuleList(\n                (0): Linear(in_features=1280, out_features=1280, bias=True)\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (ff): FeedForward(\n              (net): ModuleList(\n                (0): GEGLU(\n                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                )\n                (1): Dropout(p=0.0, inplace=False)\n                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n              )\n            )\n          )\n        )\n        (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (resnets): ModuleList(\n      (0-1): 2 x ResnetBlock2D(\n        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n        (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (nonlinearity): SiLU()\n      )\n    )\n  )\n  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n  (conv_act): SiLU()\n  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)\n\n\n\n\n\n\ntext_input = tokenizer(\n    prompt * batch_size,\n    padding=\"max_length\",\n    max_length=tokenizer.model_max_length,\n    truncation=True,\n    return_tensors=\"pt\",\n).input_ids.to(device)\n\ntext_input.shape, text_input\n\n(torch.Size([2, 77]),\n tensor([[49406,   320,  8853,   539,   550, 18376,  6765,   320,  4558, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407],\n         [49406,   320,  8853,   539,   550, 18376,  6765,   320,  4558, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407]], device='cuda:0'))\n\n\n\nwith torch.no_grad():\n    text_embeddings = text_encoder(text_input)[0]\n\ntext_embeddings.shape, text_embeddings\n\n(torch.Size([2, 77, 768]),\n tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [ 0.0290, -1.3258,  0.3085,  ..., -0.5257,  0.9768,  0.6652],\n          [ 0.4595,  0.5617,  1.6663,  ..., -1.9515, -1.2307,  0.0104],\n          ...,\n          [-3.0421, -0.0656, -0.1793,  ...,  0.3943, -0.0190,  0.7664],\n          [-3.0551, -0.1036, -0.1936,  ...,  0.4236, -0.0190,  0.7575],\n          [-2.9854, -0.0832, -0.1715,  ...,  0.4355,  0.0095,  0.7485]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [ 0.0290, -1.3258,  0.3085,  ..., -0.5257,  0.9768,  0.6652],\n          [ 0.4595,  0.5617,  1.6663,  ..., -1.9515, -1.2307,  0.0104],\n          ...,\n          [-3.0421, -0.0656, -0.1793,  ...,  0.3943, -0.0190,  0.7664],\n          [-3.0551, -0.1036, -0.1936,  ...,  0.4236, -0.0190,  0.7575],\n          [-2.9854, -0.0832, -0.1715,  ...,  0.4355,  0.0095,  0.7485]]],\n        device='cuda:0'))\n\n\n\nuncond_input = tokenizer(\n    [\"\"] * batch_size,\n    padding=\"max_length\",\n    max_length=text_input.shape[-1],\n    return_tensors=\"pt\",\n).input_ids.to(device)\n\nuncond_input.shape, uncond_input\n\n(torch.Size([2, 77]),\n tensor([[49406, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407],\n         [49406, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407]], device='cuda:0'))\n\n\n\nwith torch.no_grad():\n    uncond_embeddings = text_encoder(uncond_input)[0]\n\nuncond_embeddings.shape, uncond_embeddings\n\n(torch.Size([2, 77, 768]),\n tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],\n          [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],\n          ...,\n          [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],\n          [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],\n          [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],\n          [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],\n          ...,\n          [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],\n          [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],\n          [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]]],\n        device='cuda:0'))\n\n\n\ntext_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n\ntext_embeddings.shape, text_embeddings\n\n(torch.Size([4, 77, 768]),\n tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],\n          [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],\n          ...,\n          [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],\n          [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],\n          [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],\n          [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],\n          ...,\n          [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],\n          [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],\n          [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [ 0.0290, -1.3258,  0.3085,  ..., -0.5257,  0.9768,  0.6652],\n          [ 0.4595,  0.5617,  1.6663,  ..., -1.9515, -1.2307,  0.0104],\n          ...,\n          [-3.0421, -0.0656, -0.1793,  ...,  0.3943, -0.0190,  0.7664],\n          [-3.0551, -0.1036, -0.1936,  ...,  0.4236, -0.0190,  0.7575],\n          [-2.9854, -0.0832, -0.1715,  ...,  0.4355,  0.0095,  0.7485]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [ 0.0290, -1.3258,  0.3085,  ..., -0.5257,  0.9768,  0.6652],\n          [ 0.4595,  0.5617,  1.6663,  ..., -1.9515, -1.2307,  0.0104],\n          ...,\n          [-3.0421, -0.0656, -0.1793,  ...,  0.3943, -0.0190,  0.7664],\n          [-3.0551, -0.1036, -0.1936,  ...,  0.4236, -0.0190,  0.7575],\n          [-2.9854, -0.0832, -0.1715,  ...,  0.4355,  0.0095,  0.7485]]],\n        device='cuda:0'))\n\n\n\nlatents = torch.randn(\n    (batch_size, unet.in_channels, height // 8, width // 8),\n    generator=generator,\n).to(device)\n\nlatents.shape, latents\n\n(torch.Size([2, 4, 64, 64]),\n tensor([[[[ 0.1884, -0.6394,  0.1089,  ..., -0.9887, -0.7133, -1.1545],\n           [ 0.4124,  1.5587, -0.3407,  ...,  2.1968, -0.0356, -0.0810],\n           [-1.8912,  0.0528, -0.4425,  ...,  1.3110,  0.7100,  0.6802],\n           ...,\n           [-1.3443, -0.1747, -0.6298,  ...,  0.4572, -0.8584, -0.1284],\n           [-1.7920, -0.6554, -0.0439,  ...,  0.5436,  2.2266, -0.5003],\n           [ 0.6213, -1.3155,  0.7470,  ..., -0.2354,  0.7097,  0.6170]],\n \n          [[-0.5007, -1.4418,  0.2598,  ..., -0.2586,  2.3239, -1.3245],\n           [ 0.8540, -0.4135,  0.5658,  ..., -1.9556,  2.0454, -0.2454],\n           [-0.3212, -1.9329, -1.1598,  ...,  0.7156, -0.7228, -0.6992],\n           ...,\n           [ 0.0180, -0.7993,  2.3330,  ...,  0.2594, -0.0333, -0.0826],\n           [-1.2569, -0.8219,  1.3467,  ...,  0.4792,  1.8265, -0.6156],\n           [-1.9367, -0.0949,  0.0720,  ...,  0.0806,  0.2966, -1.0284]],\n \n          [[ 0.2291, -0.0936, -1.3283,  ...,  1.4995, -0.1965, -0.2879],\n           [-1.0226, -1.2896,  1.6202,  ..., -0.3910, -0.3834,  0.5519],\n           [ 0.5424,  0.2685,  0.4912,  ...,  0.9773, -0.8260,  1.1552],\n           ...,\n           [-1.5280, -0.2530, -1.3748,  ..., -1.4948,  1.3661, -1.1294],\n           [ 0.4241, -0.2996,  1.8231,  ...,  0.6968,  0.8247, -0.0279],\n           [-3.3711, -0.7468, -1.3212,  ..., -0.4128,  0.4621,  2.6297]],\n \n          [[-0.7510, -0.7452, -0.8998,  ..., -1.6957, -0.4004, -0.2596],\n           [-1.2092, -1.8881, -0.5828,  ..., -1.0428, -0.6500,  0.3601],\n           [-0.4254,  0.9478,  1.3083,  ..., -0.0259, -0.4542,  0.4353],\n           ...,\n           [-0.1918,  0.4858,  0.0666,  ...,  0.8505, -0.6606, -0.3193],\n           [ 1.3620,  0.2283,  0.6292,  ..., -0.9271,  1.7018,  0.2161],\n           [-0.3891, -1.8911, -0.7501,  ..., -0.2330, -1.0460,  0.4121]]],\n \n \n         [[[ 0.3649, -1.3183, -1.3308,  ..., -0.5548, -1.3610, -1.9329],\n           [-0.0071,  0.1977,  1.5517,  ..., -1.6664,  1.6551,  0.1798],\n           [-1.0404,  0.6524,  0.4654,  ..., -0.5947, -1.0871,  2.2230],\n           ...,\n           [-0.6844,  0.1692, -0.2559,  ...,  0.5511,  0.9734,  0.7936],\n           [-1.1951,  0.5016,  0.8089,  ...,  0.2337, -0.2213, -1.1724],\n           [-0.5055, -0.7491, -1.4940,  ..., -2.1332,  0.9120,  0.2057]],\n \n          [[ 1.3668, -1.1680, -0.8574,  ..., -0.0635, -1.9132, -0.6023],\n           [ 1.0974, -0.9654,  1.2987,  ...,  1.3187, -0.0241, -0.5427],\n           [-2.0427, -1.4358, -0.7115,  ...,  0.1088,  0.0764,  0.7254],\n           ...,\n           [ 1.0957,  1.4058, -0.0178,  ...,  0.5748,  0.0953,  0.7550],\n           [ 0.4080,  0.8792,  0.6801,  ..., -0.7215,  1.1261,  0.0551],\n           [-0.3183, -2.3306,  0.7155,  ...,  0.4291, -0.2074, -1.1237]],\n \n          [[-0.2401,  0.9229,  0.0212,  ...,  0.2128, -0.4705, -0.3262],\n           [ 0.1108,  0.8909,  0.5309,  ..., -1.7175, -1.6657, -1.7706],\n           [-0.1654, -0.4582, -1.2832,  ...,  0.5297, -0.8363,  1.0293],\n           ...,\n           [-1.3526,  2.1482,  0.5417,  ..., -2.2156, -1.9940, -0.9745],\n           [-0.5821,  0.0492,  0.6693,  ..., -0.8610,  0.5864, -0.6040],\n           [ 1.0180,  1.4447,  0.9563,  ...,  0.9034,  0.7988, -1.7119]],\n \n          [[-1.6146,  0.0868,  0.6415,  ...,  0.2083,  0.4058,  0.2813],\n           [ 0.1969, -0.3334, -0.6526,  ..., -1.4639, -1.6302, -0.6036],\n           [ 0.1556, -0.0859, -0.0230,  ..., -0.7900, -0.3481,  0.8767],\n           ...,\n           [ 0.6056,  0.8374, -0.3834,  ..., -0.6636, -0.4814,  0.8244],\n           [ 0.6982, -0.4884, -1.3777,  ...,  0.5876, -2.0944,  0.0853],\n           [ 0.0388, -0.5761, -0.5116,  ..., -1.6645,  0.1752, -0.1923]]]],\n        device='cuda:0'))\n\n\n\nscheduler.set_timesteps(num_inference_steps)\n\nscheduler.timesteps.shape, pipe.scheduler.timesteps\n\n(torch.Size([50]),\n tensor([999.0000, 978.6122, 958.2245, 937.8367, 917.4490, 897.0612, 876.6735,\n         856.2857, 835.8980, 815.5102, 795.1224, 774.7347, 754.3469, 733.9592,\n         713.5714, 693.1837, 672.7959, 652.4082, 632.0204, 611.6327, 591.2449,\n         570.8571, 550.4694, 530.0816, 509.6939, 489.3061, 468.9184, 448.5306,\n         428.1429, 407.7551, 387.3673, 366.9796, 346.5918, 326.2041, 305.8163,\n         285.4286, 265.0408, 244.6531, 224.2653, 203.8776, 183.4898, 163.1020,\n         142.7143, 122.3265, 101.9388,  81.5510,  61.1633,  40.7755,  20.3878,\n           0.0000], dtype=torch.float64))\n\n\n\n\n\n\n\\tilde{\\boldsymbol{\\epsilon}}_\\theta(\\mathbf{z}_t, \\mathbf{c}) = w\\boldsymbol{\\epsilon}_\\theta(\\mathbf{z}_t, \\mathbf{c}) + (1-w)\\boldsymbol{\\epsilon}_{\\theta}(\\mathbf{z}_t).\n\nHere, \\boldsymbol{\\epsilon}_\\theta(\\mathbf{z}_t, \\mathbf{c}) and \\boldsymbol{\\epsilon}_{\\theta}(\\mathbf{z}_t) are conditional and unconditional \\boldsymbol{\\epsilon}-predictions, given by \\boldsymbol{\\epsilon}_\\theta := (\\mathbf{z}_t - \\alpha_t\\hat{\\mathbf{x}}_\\theta)/\\sigma_t, and w is the guidance weight. Setting w = 1 disables classifier-free guidance, while increasing w &gt; 1 strengthens the effect of guidance.1\n\nfrom tqdm.auto import tqdm\n\nlatents = latents * scheduler.init_noise_sigma\n\nfor t in tqdm(scheduler.timesteps):\n    # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n    latent_model_input = torch.cat([latents] * 2)\n\n    latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n\n    # predict the noise residual\n    with torch.no_grad():\n        noise_pred = unet(\n            latent_model_input, t, encoder_hidden_states=text_embeddings\n        ).sample\n\n    # perform guidance\n    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n    noise_pred = (\n        guidance_scale * noise_pred_text + (1 - guidance_scale) * noise_pred_uncond\n    )\n\n    # compute the previous noisy sample x_t -&gt; x_t-1\n    latents = scheduler.step(noise_pred, t, latents).prev_sample\n\n\n# scale and decode the image latents with vae\nlatents = 1 / 0.18215 * latents\n\nwith torch.no_grad():\n    image = vae.decode(latents).sample\n\n\nfrom PIL import Image\n\nimage = (image / 2 + 0.5).clamp(0, 1)\nimage = image.detach().cpu().permute(0, 2, 3, 1).numpy()\nimages = (image * 255).round().astype(\"uint8\")\npil_images = [Image.fromarray(image) for image in images]\n\n\nfor pil_image in pil_images:\n    display(pil_image)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatil et al.Â (2022) Stable Diffusion with ðŸ§¨ Diffusers, https://huggingface.co/blog/stable_diffusion"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html#install-and-import-libraries",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html#install-and-import-libraries",
    "title": "Stable Diffusion Inference with Diffusers (low-level)",
    "section": "",
    "text": "!pip install -qq diffusers transformers scipy ftfy accelerate\n\n\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\n'cuda'\n\n\n\nprompt = [\"a photograph of an astronaut riding a horse\"]\n\nheight = 512  # default height of Stable Diffusion\nwidth = 512  # default width of Stable Diffusion\n\nnum_inference_steps = 50  # Number of denoising steps\n\nguidance_scale = 7.5  # Scale for classifier-free guidance\n\ngenerator = torch.manual_seed(256)  # Seed generator to create the inital latent noise\n\nbatch_size = 2\n\n\nfrom diffusers import LMSDiscreteScheduler, StableDiffusionPipeline\n\nscheduler = LMSDiscreteScheduler.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\"\n)\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\", scheduler=scheduler\n)\n\n\npipe\n\nStableDiffusionPipeline {\n  \"_class_name\": \"StableDiffusionPipeline\",\n  \"_diffusers_version\": \"0.20.2\",\n  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n  \"feature_extractor\": [\n    \"transformers\",\n    \"CLIPImageProcessor\"\n  ],\n  \"requires_safety_checker\": true,\n  \"safety_checker\": [\n    \"stable_diffusion\",\n    \"StableDiffusionSafetyChecker\"\n  ],\n  \"scheduler\": [\n    \"diffusers\",\n    \"LMSDiscreteScheduler\"\n  ],\n  \"text_encoder\": [\n    \"transformers\",\n    \"CLIPTextModel\"\n  ],\n  \"tokenizer\": [\n    \"transformers\",\n    \"CLIPTokenizer\"\n  ],\n  \"unet\": [\n    \"diffusers\",\n    \"UNet2DConditionModel\"\n  ],\n  \"vae\": [\n    \"diffusers\",\n    \"AutoencoderKL\"\n  ]\n}\n\n\n\npipe = pipe.to(device)"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html#low-level",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html#low-level",
    "title": "Stable Diffusion Inference with Diffusers (low-level)",
    "section": "",
    "text": "# 1. Load the autoencoder model which will be used to decode the latents into image space.\nvae = pipe.vae\n\n# 2. Load the tokenizer and text encoder to tokenize and encode the text.\ntokenizer = pipe.tokenizer\ntext_encoder = pipe.text_encoder\n\n# 3. The UNet model for generating the latents.\nunet = pipe.unet\n\n\n\n\nvae\n\nAutoencoderKL(\n  (encoder): Encoder(\n    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (down_blocks): ModuleList(\n      (0): DownEncoderBlock2D(\n        (resnets): ModuleList(\n          (0-1): 2 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (downsamplers): ModuleList(\n          (0): Downsample2D(\n            (conv): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(2, 2))\n          )\n        )\n      )\n      (1): DownEncoderBlock2D(\n        (resnets): ModuleList(\n          (0): ResnetBlock2D(\n            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n            (conv_shortcut): LoRACompatibleConv(128, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): ResnetBlock2D(\n            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (downsamplers): ModuleList(\n          (0): Downsample2D(\n            (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(2, 2))\n          )\n        )\n      )\n      (2): DownEncoderBlock2D(\n        (resnets): ModuleList(\n          (0): ResnetBlock2D(\n            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n            (conv_shortcut): LoRACompatibleConv(256, 512, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): ResnetBlock2D(\n            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (downsamplers): ModuleList(\n          (0): Downsample2D(\n            (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(2, 2))\n          )\n        )\n      )\n      (3): DownEncoderBlock2D(\n        (resnets): ModuleList(\n          (0-1): 2 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n      )\n    )\n    (mid_block): UNetMidBlock2D(\n      (attentions): ModuleList(\n        (0): Attention(\n          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (to_q): Linear(in_features=512, out_features=512, bias=True)\n          (to_k): Linear(in_features=512, out_features=512, bias=True)\n          (to_v): Linear(in_features=512, out_features=512, bias=True)\n          (to_out): ModuleList(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n    (conv_act): SiLU()\n    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (decoder): Decoder(\n    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (up_blocks): ModuleList(\n      (0-1): 2 x UpDecoderBlock2D(\n        (resnets): ModuleList(\n          (0-2): 3 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (upsamplers): ModuleList(\n          (0): Upsample2D(\n            (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n        )\n      )\n      (2): UpDecoderBlock2D(\n        (resnets): ModuleList(\n          (0): ResnetBlock2D(\n            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n            (conv_shortcut): LoRACompatibleConv(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1-2): 2 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n        (upsamplers): ModuleList(\n          (0): Upsample2D(\n            (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          )\n        )\n      )\n      (3): UpDecoderBlock2D(\n        (resnets): ModuleList(\n          (0): ResnetBlock2D(\n            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n            (conv_shortcut): LoRACompatibleConv(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1-2): 2 x ResnetBlock2D(\n            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (nonlinearity): SiLU()\n          )\n        )\n      )\n    )\n    (mid_block): UNetMidBlock2D(\n      (attentions): ModuleList(\n        (0): Attention(\n          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (to_q): Linear(in_features=512, out_features=512, bias=True)\n          (to_k): Linear(in_features=512, out_features=512, bias=True)\n          (to_v): Linear(in_features=512, out_features=512, bias=True)\n          (to_out): ModuleList(\n            (0): Linear(in_features=512, out_features=512, bias=True)\n            (1): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n    (conv_act): SiLU()\n    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n)\n\n\n\ntokenizer\n\nCLIPTokenizer(name_or_path='/root/.cache/huggingface/hub/models--CompVis--stable-diffusion-v1-4/snapshots/133a221b8aa7292a167afc5127cb63fb5005638b/tokenizer', vocab_size=49408, model_max_length=77, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"&lt;|startoftext|&gt;\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"&lt;|endoftext|&gt;\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"&lt;|endoftext|&gt;\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '&lt;|endoftext|&gt;'}, clean_up_tokenization_spaces=True)\n\n\n\ntext_encoder\n\nCLIPTextModel(\n  (text_model): CLIPTextTransformer(\n    (embeddings): CLIPTextEmbeddings(\n      (token_embedding): Embedding(49408, 768)\n      (position_embedding): Embedding(77, 768)\n    )\n    (encoder): CLIPEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x CLIPEncoderLayer(\n          (self_attn): CLIPAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): CLIPMLP(\n            (activation_fn): QuickGELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n)\n\n\n\nunet\n\nUNet2DConditionModel(\n  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (time_proj): Timesteps()\n  (time_embedding): TimestepEmbedding(\n    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n    (act): SiLU()\n    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n  )\n  (down_blocks): ModuleList(\n    (0): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=320, out_features=320, bias=False)\n                (to_k): Linear(in_features=320, out_features=320, bias=False)\n                (to_v): Linear(in_features=320, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=320, out_features=320, bias=False)\n                (to_k): Linear(in_features=768, out_features=320, bias=False)\n                (to_v): Linear(in_features=768, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (1): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=640, out_features=640, bias=False)\n                (to_k): Linear(in_features=640, out_features=640, bias=False)\n                (to_v): Linear(in_features=640, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=640, out_features=640, bias=False)\n                (to_k): Linear(in_features=768, out_features=640, bias=False)\n                (to_v): Linear(in_features=768, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (2): CrossAttnDownBlock2D(\n      (attentions): ModuleList(\n        (0-1): 2 x Transformer2DModel(\n          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n      (downsamplers): ModuleList(\n        (0): Downsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        )\n      )\n    )\n    (3): DownBlock2D(\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n        )\n      )\n    )\n  )\n  (up_blocks): ModuleList(\n    (0): UpBlock2D(\n      (resnets): ModuleList(\n        (0-2): 3 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (1): CrossAttnUpBlock2D(\n      (attentions): ModuleList(\n        (0-2): 3 x Transformer2DModel(\n          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0-1): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (2): CrossAttnUpBlock2D(\n      (attentions): ModuleList(\n        (0-2): 3 x Transformer2DModel(\n          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=640, out_features=640, bias=False)\n                (to_k): Linear(in_features=640, out_features=640, bias=False)\n                (to_v): Linear(in_features=640, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=640, out_features=640, bias=False)\n                (to_k): Linear(in_features=768, out_features=640, bias=False)\n                (to_v): Linear(in_features=768, out_features=640, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=640, out_features=640, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): ResnetBlock2D(\n          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): ResnetBlock2D(\n          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(960, 640, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (upsamplers): ModuleList(\n        (0): Upsample2D(\n          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (3): CrossAttnUpBlock2D(\n      (attentions): ModuleList(\n        (0-2): 3 x Transformer2DModel(\n          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n          (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n          (transformer_blocks): ModuleList(\n            (0): BasicTransformerBlock(\n              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn1): Attention(\n                (to_q): Linear(in_features=320, out_features=320, bias=False)\n                (to_k): Linear(in_features=320, out_features=320, bias=False)\n                (to_v): Linear(in_features=320, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (attn2): Attention(\n                (to_q): Linear(in_features=320, out_features=320, bias=False)\n                (to_k): Linear(in_features=768, out_features=320, bias=False)\n                (to_v): Linear(in_features=768, out_features=320, bias=False)\n                (to_out): ModuleList(\n                  (0): Linear(in_features=320, out_features=320, bias=True)\n                  (1): Dropout(p=0.0, inplace=False)\n                )\n              )\n              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n              (ff): FeedForward(\n                (net): ModuleList(\n                  (0): GEGLU(\n                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n                  )\n                  (1): Dropout(p=0.0, inplace=False)\n                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n                )\n              )\n            )\n          )\n          (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (resnets): ModuleList(\n        (0): ResnetBlock2D(\n          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(960, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1-2): 2 x ResnetBlock2D(\n          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n          (conv1): LoRACompatibleConv(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (nonlinearity): SiLU()\n          (conv_shortcut): LoRACompatibleConv(640, 320, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n  )\n  (mid_block): UNetMidBlock2DCrossAttn(\n    (attentions): ModuleList(\n      (0): Transformer2DModel(\n        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n        (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n        (transformer_blocks): ModuleList(\n          (0): BasicTransformerBlock(\n            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn1): Attention(\n              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n              (to_out): ModuleList(\n                (0): Linear(in_features=1280, out_features=1280, bias=True)\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (attn2): Attention(\n              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n              (to_out): ModuleList(\n                (0): Linear(in_features=1280, out_features=1280, bias=True)\n                (1): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n            (ff): FeedForward(\n              (net): ModuleList(\n                (0): GEGLU(\n                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n                )\n                (1): Dropout(p=0.0, inplace=False)\n                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n              )\n            )\n          )\n        )\n        (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (resnets): ModuleList(\n      (0-1): 2 x ResnetBlock2D(\n        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n        (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (nonlinearity): SiLU()\n      )\n    )\n  )\n  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n  (conv_act): SiLU()\n  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n)\n\n\n\n\n\n\ntext_input = tokenizer(\n    prompt * batch_size,\n    padding=\"max_length\",\n    max_length=tokenizer.model_max_length,\n    truncation=True,\n    return_tensors=\"pt\",\n).input_ids.to(device)\n\ntext_input.shape, text_input\n\n(torch.Size([2, 77]),\n tensor([[49406,   320,  8853,   539,   550, 18376,  6765,   320,  4558, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407],\n         [49406,   320,  8853,   539,   550, 18376,  6765,   320,  4558, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407]], device='cuda:0'))\n\n\n\nwith torch.no_grad():\n    text_embeddings = text_encoder(text_input)[0]\n\ntext_embeddings.shape, text_embeddings\n\n(torch.Size([2, 77, 768]),\n tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [ 0.0290, -1.3258,  0.3085,  ..., -0.5257,  0.9768,  0.6652],\n          [ 0.4595,  0.5617,  1.6663,  ..., -1.9515, -1.2307,  0.0104],\n          ...,\n          [-3.0421, -0.0656, -0.1793,  ...,  0.3943, -0.0190,  0.7664],\n          [-3.0551, -0.1036, -0.1936,  ...,  0.4236, -0.0190,  0.7575],\n          [-2.9854, -0.0832, -0.1715,  ...,  0.4355,  0.0095,  0.7485]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [ 0.0290, -1.3258,  0.3085,  ..., -0.5257,  0.9768,  0.6652],\n          [ 0.4595,  0.5617,  1.6663,  ..., -1.9515, -1.2307,  0.0104],\n          ...,\n          [-3.0421, -0.0656, -0.1793,  ...,  0.3943, -0.0190,  0.7664],\n          [-3.0551, -0.1036, -0.1936,  ...,  0.4236, -0.0190,  0.7575],\n          [-2.9854, -0.0832, -0.1715,  ...,  0.4355,  0.0095,  0.7485]]],\n        device='cuda:0'))\n\n\n\nuncond_input = tokenizer(\n    [\"\"] * batch_size,\n    padding=\"max_length\",\n    max_length=text_input.shape[-1],\n    return_tensors=\"pt\",\n).input_ids.to(device)\n\nuncond_input.shape, uncond_input\n\n(torch.Size([2, 77]),\n tensor([[49406, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407],\n         [49406, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n          49407, 49407, 49407, 49407, 49407, 49407, 49407]], device='cuda:0'))\n\n\n\nwith torch.no_grad():\n    uncond_embeddings = text_encoder(uncond_input)[0]\n\nuncond_embeddings.shape, uncond_embeddings\n\n(torch.Size([2, 77, 768]),\n tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],\n          [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],\n          ...,\n          [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],\n          [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],\n          [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],\n          [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],\n          ...,\n          [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],\n          [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],\n          [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]]],\n        device='cuda:0'))\n\n\n\ntext_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n\ntext_embeddings.shape, text_embeddings\n\n(torch.Size([4, 77, 768]),\n tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],\n          [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],\n          ...,\n          [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],\n          [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],\n          [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],\n          [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],\n          ...,\n          [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],\n          [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],\n          [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [ 0.0290, -1.3258,  0.3085,  ..., -0.5257,  0.9768,  0.6652],\n          [ 0.4595,  0.5617,  1.6663,  ..., -1.9515, -1.2307,  0.0104],\n          ...,\n          [-3.0421, -0.0656, -0.1793,  ...,  0.3943, -0.0190,  0.7664],\n          [-3.0551, -0.1036, -0.1936,  ...,  0.4236, -0.0190,  0.7575],\n          [-2.9854, -0.0832, -0.1715,  ...,  0.4355,  0.0095,  0.7485]],\n \n         [[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n          [ 0.0290, -1.3258,  0.3085,  ..., -0.5257,  0.9768,  0.6652],\n          [ 0.4595,  0.5617,  1.6663,  ..., -1.9515, -1.2307,  0.0104],\n          ...,\n          [-3.0421, -0.0656, -0.1793,  ...,  0.3943, -0.0190,  0.7664],\n          [-3.0551, -0.1036, -0.1936,  ...,  0.4236, -0.0190,  0.7575],\n          [-2.9854, -0.0832, -0.1715,  ...,  0.4355,  0.0095,  0.7485]]],\n        device='cuda:0'))\n\n\n\nlatents = torch.randn(\n    (batch_size, unet.in_channels, height // 8, width // 8),\n    generator=generator,\n).to(device)\n\nlatents.shape, latents\n\n(torch.Size([2, 4, 64, 64]),\n tensor([[[[ 0.1884, -0.6394,  0.1089,  ..., -0.9887, -0.7133, -1.1545],\n           [ 0.4124,  1.5587, -0.3407,  ...,  2.1968, -0.0356, -0.0810],\n           [-1.8912,  0.0528, -0.4425,  ...,  1.3110,  0.7100,  0.6802],\n           ...,\n           [-1.3443, -0.1747, -0.6298,  ...,  0.4572, -0.8584, -0.1284],\n           [-1.7920, -0.6554, -0.0439,  ...,  0.5436,  2.2266, -0.5003],\n           [ 0.6213, -1.3155,  0.7470,  ..., -0.2354,  0.7097,  0.6170]],\n \n          [[-0.5007, -1.4418,  0.2598,  ..., -0.2586,  2.3239, -1.3245],\n           [ 0.8540, -0.4135,  0.5658,  ..., -1.9556,  2.0454, -0.2454],\n           [-0.3212, -1.9329, -1.1598,  ...,  0.7156, -0.7228, -0.6992],\n           ...,\n           [ 0.0180, -0.7993,  2.3330,  ...,  0.2594, -0.0333, -0.0826],\n           [-1.2569, -0.8219,  1.3467,  ...,  0.4792,  1.8265, -0.6156],\n           [-1.9367, -0.0949,  0.0720,  ...,  0.0806,  0.2966, -1.0284]],\n \n          [[ 0.2291, -0.0936, -1.3283,  ...,  1.4995, -0.1965, -0.2879],\n           [-1.0226, -1.2896,  1.6202,  ..., -0.3910, -0.3834,  0.5519],\n           [ 0.5424,  0.2685,  0.4912,  ...,  0.9773, -0.8260,  1.1552],\n           ...,\n           [-1.5280, -0.2530, -1.3748,  ..., -1.4948,  1.3661, -1.1294],\n           [ 0.4241, -0.2996,  1.8231,  ...,  0.6968,  0.8247, -0.0279],\n           [-3.3711, -0.7468, -1.3212,  ..., -0.4128,  0.4621,  2.6297]],\n \n          [[-0.7510, -0.7452, -0.8998,  ..., -1.6957, -0.4004, -0.2596],\n           [-1.2092, -1.8881, -0.5828,  ..., -1.0428, -0.6500,  0.3601],\n           [-0.4254,  0.9478,  1.3083,  ..., -0.0259, -0.4542,  0.4353],\n           ...,\n           [-0.1918,  0.4858,  0.0666,  ...,  0.8505, -0.6606, -0.3193],\n           [ 1.3620,  0.2283,  0.6292,  ..., -0.9271,  1.7018,  0.2161],\n           [-0.3891, -1.8911, -0.7501,  ..., -0.2330, -1.0460,  0.4121]]],\n \n \n         [[[ 0.3649, -1.3183, -1.3308,  ..., -0.5548, -1.3610, -1.9329],\n           [-0.0071,  0.1977,  1.5517,  ..., -1.6664,  1.6551,  0.1798],\n           [-1.0404,  0.6524,  0.4654,  ..., -0.5947, -1.0871,  2.2230],\n           ...,\n           [-0.6844,  0.1692, -0.2559,  ...,  0.5511,  0.9734,  0.7936],\n           [-1.1951,  0.5016,  0.8089,  ...,  0.2337, -0.2213, -1.1724],\n           [-0.5055, -0.7491, -1.4940,  ..., -2.1332,  0.9120,  0.2057]],\n \n          [[ 1.3668, -1.1680, -0.8574,  ..., -0.0635, -1.9132, -0.6023],\n           [ 1.0974, -0.9654,  1.2987,  ...,  1.3187, -0.0241, -0.5427],\n           [-2.0427, -1.4358, -0.7115,  ...,  0.1088,  0.0764,  0.7254],\n           ...,\n           [ 1.0957,  1.4058, -0.0178,  ...,  0.5748,  0.0953,  0.7550],\n           [ 0.4080,  0.8792,  0.6801,  ..., -0.7215,  1.1261,  0.0551],\n           [-0.3183, -2.3306,  0.7155,  ...,  0.4291, -0.2074, -1.1237]],\n \n          [[-0.2401,  0.9229,  0.0212,  ...,  0.2128, -0.4705, -0.3262],\n           [ 0.1108,  0.8909,  0.5309,  ..., -1.7175, -1.6657, -1.7706],\n           [-0.1654, -0.4582, -1.2832,  ...,  0.5297, -0.8363,  1.0293],\n           ...,\n           [-1.3526,  2.1482,  0.5417,  ..., -2.2156, -1.9940, -0.9745],\n           [-0.5821,  0.0492,  0.6693,  ..., -0.8610,  0.5864, -0.6040],\n           [ 1.0180,  1.4447,  0.9563,  ...,  0.9034,  0.7988, -1.7119]],\n \n          [[-1.6146,  0.0868,  0.6415,  ...,  0.2083,  0.4058,  0.2813],\n           [ 0.1969, -0.3334, -0.6526,  ..., -1.4639, -1.6302, -0.6036],\n           [ 0.1556, -0.0859, -0.0230,  ..., -0.7900, -0.3481,  0.8767],\n           ...,\n           [ 0.6056,  0.8374, -0.3834,  ..., -0.6636, -0.4814,  0.8244],\n           [ 0.6982, -0.4884, -1.3777,  ...,  0.5876, -2.0944,  0.0853],\n           [ 0.0388, -0.5761, -0.5116,  ..., -1.6645,  0.1752, -0.1923]]]],\n        device='cuda:0'))\n\n\n\nscheduler.set_timesteps(num_inference_steps)\n\nscheduler.timesteps.shape, pipe.scheduler.timesteps\n\n(torch.Size([50]),\n tensor([999.0000, 978.6122, 958.2245, 937.8367, 917.4490, 897.0612, 876.6735,\n         856.2857, 835.8980, 815.5102, 795.1224, 774.7347, 754.3469, 733.9592,\n         713.5714, 693.1837, 672.7959, 652.4082, 632.0204, 611.6327, 591.2449,\n         570.8571, 550.4694, 530.0816, 509.6939, 489.3061, 468.9184, 448.5306,\n         428.1429, 407.7551, 387.3673, 366.9796, 346.5918, 326.2041, 305.8163,\n         285.4286, 265.0408, 244.6531, 224.2653, 203.8776, 183.4898, 163.1020,\n         142.7143, 122.3265, 101.9388,  81.5510,  61.1633,  40.7755,  20.3878,\n           0.0000], dtype=torch.float64))\n\n\n\n\n\n\n\\tilde{\\boldsymbol{\\epsilon}}_\\theta(\\mathbf{z}_t, \\mathbf{c}) = w\\boldsymbol{\\epsilon}_\\theta(\\mathbf{z}_t, \\mathbf{c}) + (1-w)\\boldsymbol{\\epsilon}_{\\theta}(\\mathbf{z}_t).\n\nHere, \\boldsymbol{\\epsilon}_\\theta(\\mathbf{z}_t, \\mathbf{c}) and \\boldsymbol{\\epsilon}_{\\theta}(\\mathbf{z}_t) are conditional and unconditional \\boldsymbol{\\epsilon}-predictions, given by \\boldsymbol{\\epsilon}_\\theta := (\\mathbf{z}_t - \\alpha_t\\hat{\\mathbf{x}}_\\theta)/\\sigma_t, and w is the guidance weight. Setting w = 1 disables classifier-free guidance, while increasing w &gt; 1 strengthens the effect of guidance.1\n\nfrom tqdm.auto import tqdm\n\nlatents = latents * scheduler.init_noise_sigma\n\nfor t in tqdm(scheduler.timesteps):\n    # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n    latent_model_input = torch.cat([latents] * 2)\n\n    latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n\n    # predict the noise residual\n    with torch.no_grad():\n        noise_pred = unet(\n            latent_model_input, t, encoder_hidden_states=text_embeddings\n        ).sample\n\n    # perform guidance\n    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n    noise_pred = (\n        guidance_scale * noise_pred_text + (1 - guidance_scale) * noise_pred_uncond\n    )\n\n    # compute the previous noisy sample x_t -&gt; x_t-1\n    latents = scheduler.step(noise_pred, t, latents).prev_sample\n\n\n# scale and decode the image latents with vae\nlatents = 1 / 0.18215 * latents\n\nwith torch.no_grad():\n    image = vae.decode(latents).sample\n\n\nfrom PIL import Image\n\nimage = (image / 2 + 0.5).clamp(0, 1)\nimage = image.detach().cpu().permute(0, 2, 3, 1).numpy()\nimages = (image * 255).round().astype(\"uint8\")\npil_images = [Image.fromarray(image) for image in images]\n\n\nfor pil_image in pil_images:\n    display(pil_image)"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html#references",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html#references",
    "title": "Stable Diffusion Inference with Diffusers (low-level)",
    "section": "",
    "text": "Patil et al.Â (2022) Stable Diffusion with ðŸ§¨ Diffusers, https://huggingface.co/blog/stable_diffusion"
  },
  {
    "objectID": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html#footnotes",
    "href": "posts/stable-diffusion-inference/Stable_Diffusion_Inference_low_level.html#footnotes",
    "title": "Stable Diffusion Inference with Diffusers (low-level)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSaharia et al.Â (2022) Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding, https://arxiv.org/abs/2205.11487â†©ï¸Ž"
  }
]